{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d167b9ef-8f5d-49fa-a2c9-c212b85bb44d",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f0c27dc-1d1c-4940-ac0a-835f717bebd1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
      "     |████████████████████████████████| 308 kB 2.7 MB/s            \n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.31-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "     |████████████████████████████████| 1.6 MB 11.0 MB/s            \n",
      "\u001b[?25hCollecting alembic\n",
      "  Downloading alembic-1.7.5-py3-none-any.whl (209 kB)\n",
      "     |████████████████████████████████| 209 kB 8.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from optuna) (20.9)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from optuna) (1.20.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from optuna) (4.53.0)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.10.0-py3-none-any.whl (80 kB)\n",
      "     |████████████████████████████████| 80 kB 6.5 MB/s             \n",
      "\u001b[?25hCollecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /opt/conda/lib/python3.8/site-packages (from optuna) (1.6.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "     |████████████████████████████████| 156 kB 9.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: Mako in /opt/conda/lib/python3.8/site-packages (from alembic->optuna) (1.1.4)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.10.1-py3-none-any.whl (17 kB)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
      "     |████████████████████████████████| 149 kB 13.3 MB/s            \n",
      "\u001b[?25hCollecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "     |████████████████████████████████| 49 kB 7.7 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /opt/conda/lib/python3.8/site-packages (from cliff->optuna) (2.1.0)\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.8.0-py2.py3-none-any.whl (112 kB)\n",
      "     |████████████████████████████████| 112 kB 9.2 MB/s            \n",
      "\u001b[?25hCollecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /opt/conda/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.7.0-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.8/site-packages (from Mako->alembic->optuna) (2.0.1)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=ad4cf075705055ccb63e1c60fe30b8786ca947565aa31cb34354ff959a56d60a\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: zipp, pyperclip, pbr, greenlet, stevedore, sqlalchemy, importlib-resources, importlib-metadata, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
      "Successfully installed alembic-1.7.5 autopage-0.5.0 cliff-3.10.0 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 greenlet-1.1.2 importlib-metadata-4.10.1 importlib-resources-5.4.0 optuna-2.10.0 pbr-5.8.0 pyperclip-1.8.2 sqlalchemy-1.4.31 stevedore-3.5.0 zipp-3.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828e5fbb-8dfa-4f3c-8b08-8637e559d414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.9.0a0+c3d40fd\n",
      "Torchvision Version:  0.10.0a0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import optuna\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fb424b-e661-40e1-a50e-fc59312f570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"imagewoof2\"\n",
    "model_name = \"resnet\"\n",
    "num_classes = 10\n",
    "batch_size = 16\n",
    "num_epochs = 300\n",
    "use_pretrained = False\n",
    "feature_extract = False\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd0c34-b69f-4f77-8799-317330858e3e",
   "metadata": {},
   "source": [
    "## Train function for optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fa32e2b-fb78-4525-8534-055385aebe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1679cf-53c1-4b48-b7ff-19cc01c93f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0dbf569-aaf2-4e56-8940-ef6470a41e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7445ca2e-d590-417f-ae0e-8985af27b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=10) for x in ['train', 'val']}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849dbcb7-93cf-411b-9277-5646c705f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87693372-9a7b-4b4d-95ee-78fc73bc79cf",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b78ed2d-20a4-4164-8c90-cb8fc158170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d93e3c26-1420-4429-bc4e-760d20de81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model = define_model(trial).to(device)\n",
    "\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-1)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    accuracy = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=200)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a8c10-61ff-4bd4-90d0-4afd75df4d28",
   "metadata": {},
   "source": [
    "## Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d1d7ba2-3ce7-41ed-a09d-c01aab4ce140",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-27 17:00:16,455]\u001b[0m A new study created in memory with name: no-name-0ed9ac22-76f9-4a6a-8c73-8e3b118f00fe\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 5.8761 Acc: 0.1278\n",
      "val Loss: 712.9957 Acc: 0.1064\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 2.3154 Acc: 0.1534\n",
      "val Loss: 19.2550 Acc: 0.1250\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 2.3438 Acc: 0.1567\n",
      "val Loss: 2.1834 Acc: 0.1924\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 2.2679 Acc: 0.1516\n",
      "val Loss: 2.2280 Acc: 0.1792\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 2.2228 Acc: 0.1611\n",
      "val Loss: 2.1807 Acc: 0.1754\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 2.2022 Acc: 0.1683\n",
      "val Loss: 2.8004 Acc: 0.1074\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 2.2846 Acc: 0.1756\n",
      "val Loss: 2.1515 Acc: 0.1812\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 2.1984 Acc: 0.1675\n",
      "val Loss: 2.8160 Acc: 0.1234\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 2.1887 Acc: 0.1730\n",
      "val Loss: 2.1837 Acc: 0.1774\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 2.1734 Acc: 0.1784\n",
      "val Loss: 2.2389 Acc: 0.1726\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 2.1577 Acc: 0.1754\n",
      "val Loss: 2.1372 Acc: 0.1960\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 2.1503 Acc: 0.1883\n",
      "val Loss: 2.3200 Acc: 0.1522\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 2.1097 Acc: 0.2088\n",
      "val Loss: 2.0090 Acc: 0.2573\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 2.0870 Acc: 0.2168\n",
      "val Loss: 2.1477 Acc: 0.1929\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 2.0703 Acc: 0.2257\n",
      "val Loss: 2.1543 Acc: 0.2018\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 2.0523 Acc: 0.2319\n",
      "val Loss: 2.1561 Acc: 0.1957\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 2.0448 Acc: 0.2254\n",
      "val Loss: 2.0739 Acc: 0.2107\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 2.0285 Acc: 0.2369\n",
      "val Loss: 2.2465 Acc: 0.1924\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 2.0004 Acc: 0.2478\n",
      "val Loss: 1.9952 Acc: 0.2207\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 1.9901 Acc: 0.2551\n",
      "val Loss: 1.9499 Acc: 0.2377\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 1.9839 Acc: 0.2655\n",
      "val Loss: 3.0955 Acc: 0.1667\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 1.9509 Acc: 0.2834\n",
      "val Loss: 2.2602 Acc: 0.2275\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 1.9261 Acc: 0.2902\n",
      "val Loss: 2.1019 Acc: 0.2660\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 1.9146 Acc: 0.2943\n",
      "val Loss: 2.3848 Acc: 0.2319\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 1.8692 Acc: 0.3099\n",
      "val Loss: 3.5752 Acc: 0.1827\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 1.8715 Acc: 0.3206\n",
      "val Loss: 2.2104 Acc: 0.2489\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 1.8529 Acc: 0.3248\n",
      "val Loss: 2.0269 Acc: 0.2991\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 1.8178 Acc: 0.3382\n",
      "val Loss: 2.4395 Acc: 0.2316\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 1.8142 Acc: 0.3428\n",
      "val Loss: 1.9414 Acc: 0.3039\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 1.7996 Acc: 0.3485\n",
      "val Loss: 1.9412 Acc: 0.3118\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 1.7868 Acc: 0.3543\n",
      "val Loss: 1.9718 Acc: 0.3400\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 1.7800 Acc: 0.3530\n",
      "val Loss: 4.0965 Acc: 0.1863\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 1.7718 Acc: 0.3548\n",
      "val Loss: 2.2729 Acc: 0.2227\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 1.7522 Acc: 0.3713\n",
      "val Loss: 2.5842 Acc: 0.1822\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 1.7424 Acc: 0.3715\n",
      "val Loss: 2.9485 Acc: 0.2044\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 1.7333 Acc: 0.3786\n",
      "val Loss: 2.6880 Acc: 0.2510\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 1.7207 Acc: 0.3818\n",
      "val Loss: 1.7914 Acc: 0.3640\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 1.7141 Acc: 0.3870\n",
      "val Loss: 2.2858 Acc: 0.2471\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 1.6977 Acc: 0.3941\n",
      "val Loss: 2.1326 Acc: 0.3047\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 1.6825 Acc: 0.4016\n",
      "val Loss: 1.9725 Acc: 0.3120\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 1.6835 Acc: 0.3962\n",
      "val Loss: 2.1971 Acc: 0.3019\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 1.6553 Acc: 0.4109\n",
      "val Loss: 1.6551 Acc: 0.4133\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 1.6475 Acc: 0.4111\n",
      "val Loss: 2.1365 Acc: 0.3166\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 1.6512 Acc: 0.4114\n",
      "val Loss: 2.3478 Acc: 0.2996\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 1.6310 Acc: 0.4177\n",
      "val Loss: 1.9422 Acc: 0.3688\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 1.6263 Acc: 0.4220\n",
      "val Loss: 2.3859 Acc: 0.2764\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 1.6145 Acc: 0.4250\n",
      "val Loss: 2.8861 Acc: 0.2319\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 1.6018 Acc: 0.4269\n",
      "val Loss: 2.0301 Acc: 0.3535\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 1.6065 Acc: 0.4334\n",
      "val Loss: 1.4632 Acc: 0.4714\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 1.5938 Acc: 0.4329\n",
      "val Loss: 4.1337 Acc: 0.1680\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 1.5898 Acc: 0.4355\n",
      "val Loss: 1.5725 Acc: 0.4536\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 1.5721 Acc: 0.4387\n",
      "val Loss: 1.8946 Acc: 0.3683\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 1.5633 Acc: 0.4484\n",
      "val Loss: 1.5231 Acc: 0.4495\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 1.5596 Acc: 0.4486\n",
      "val Loss: 2.5862 Acc: 0.3064\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 1.5498 Acc: 0.4560\n",
      "val Loss: 1.5535 Acc: 0.4342\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 1.5370 Acc: 0.4629\n",
      "val Loss: 1.7273 Acc: 0.4238\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 1.5233 Acc: 0.4589\n",
      "val Loss: 1.7638 Acc: 0.3767\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 1.5356 Acc: 0.4608\n",
      "val Loss: 2.8920 Acc: 0.2678\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 1.5058 Acc: 0.4678\n",
      "val Loss: 1.7081 Acc: 0.4543\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 1.5204 Acc: 0.4647\n",
      "val Loss: 1.8490 Acc: 0.3830\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 1.4902 Acc: 0.4768\n",
      "val Loss: 3.3608 Acc: 0.2510\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 1.4945 Acc: 0.4750\n",
      "val Loss: 1.7349 Acc: 0.4243\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 1.5035 Acc: 0.4782\n",
      "val Loss: 1.4793 Acc: 0.4917\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 1.4825 Acc: 0.4806\n",
      "val Loss: 2.2786 Acc: 0.3411\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 1.4776 Acc: 0.4784\n",
      "val Loss: 1.7236 Acc: 0.4360\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 1.4569 Acc: 0.4858\n",
      "val Loss: 3.2016 Acc: 0.2815\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 1.4582 Acc: 0.4868\n",
      "val Loss: 3.1086 Acc: 0.2629\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 1.4444 Acc: 0.4936\n",
      "val Loss: 1.8521 Acc: 0.4108\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 1.4239 Acc: 0.5007\n",
      "val Loss: 2.3321 Acc: 0.3556\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 1.4450 Acc: 0.4913\n",
      "val Loss: 5.1880 Acc: 0.1917\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 1.4333 Acc: 0.5030\n",
      "val Loss: 1.6357 Acc: 0.4444\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 1.4188 Acc: 0.5050\n",
      "val Loss: 2.6136 Acc: 0.3309\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 1.4134 Acc: 0.5088\n",
      "val Loss: 4.4820 Acc: 0.1677\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 1.4144 Acc: 0.5034\n",
      "val Loss: 1.8262 Acc: 0.4238\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 1.3777 Acc: 0.5128\n",
      "val Loss: 1.4959 Acc: 0.5014\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 1.3800 Acc: 0.5190\n",
      "val Loss: 5.3251 Acc: 0.2324\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 1.3613 Acc: 0.5268\n",
      "val Loss: 2.3054 Acc: 0.3006\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 1.3709 Acc: 0.5157\n",
      "val Loss: 2.5018 Acc: 0.3428\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 1.3420 Acc: 0.5344\n",
      "val Loss: 1.6554 Acc: 0.4607\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 1.3439 Acc: 0.5404\n",
      "val Loss: 1.8056 Acc: 0.4179\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 1.3313 Acc: 0.5398\n",
      "val Loss: 1.9393 Acc: 0.3904\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 1.3377 Acc: 0.5330\n",
      "val Loss: 3.9364 Acc: 0.2922\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 1.3055 Acc: 0.5532\n",
      "val Loss: 2.0968 Acc: 0.4337\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 1.3223 Acc: 0.5362\n",
      "val Loss: 2.3208 Acc: 0.4238\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 1.3115 Acc: 0.5476\n",
      "val Loss: 2.7467 Acc: 0.2876\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 1.2914 Acc: 0.5507\n",
      "val Loss: 2.6796 Acc: 0.2512\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 1.2992 Acc: 0.5470\n",
      "val Loss: 3.1027 Acc: 0.2039\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 1.2873 Acc: 0.5516\n",
      "val Loss: 2.3041 Acc: 0.2932\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 1.2917 Acc: 0.5548\n",
      "val Loss: 4.7368 Acc: 0.2558\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 1.2807 Acc: 0.5540\n",
      "val Loss: 6.1005 Acc: 0.2420\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 1.2592 Acc: 0.5600\n",
      "val Loss: 1.3346 Acc: 0.5566\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 1.2663 Acc: 0.5611\n",
      "val Loss: 2.0597 Acc: 0.3711\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 1.2391 Acc: 0.5698\n",
      "val Loss: 1.0934 Acc: 0.6322\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 1.2234 Acc: 0.5773\n",
      "val Loss: 1.6152 Acc: 0.4681\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 1.2355 Acc: 0.5688\n",
      "val Loss: 1.6808 Acc: 0.4836\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 1.2310 Acc: 0.5707\n",
      "val Loss: 2.2983 Acc: 0.3556\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 1.2151 Acc: 0.5822\n",
      "val Loss: 2.9328 Acc: 0.4136\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 1.2136 Acc: 0.5777\n",
      "val Loss: 1.4876 Acc: 0.5724\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 1.2151 Acc: 0.5839\n",
      "val Loss: 3.2353 Acc: 0.3075\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 1.2022 Acc: 0.5818\n",
      "val Loss: 1.5668 Acc: 0.5299\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 1.1945 Acc: 0.5844\n",
      "val Loss: 2.1530 Acc: 0.4388\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 1.1920 Acc: 0.5806\n",
      "val Loss: 1.3857 Acc: 0.5263\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 1.2051 Acc: 0.5859\n",
      "val Loss: 2.2860 Acc: 0.4080\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 1.1970 Acc: 0.5918\n",
      "val Loss: 1.0794 Acc: 0.6096\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 1.1666 Acc: 0.5948\n",
      "val Loss: 1.4210 Acc: 0.5490\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 1.1622 Acc: 0.6023\n",
      "val Loss: 3.5520 Acc: 0.3774\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 1.1615 Acc: 0.6018\n",
      "val Loss: 1.6767 Acc: 0.5139\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 1.1566 Acc: 0.5946\n",
      "val Loss: 1.3362 Acc: 0.5625\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 1.1449 Acc: 0.6008\n",
      "val Loss: 1.3082 Acc: 0.5551\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 1.1520 Acc: 0.6055\n",
      "val Loss: 2.0419 Acc: 0.5017\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 1.1426 Acc: 0.6030\n",
      "val Loss: 1.0172 Acc: 0.6732\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 1.1253 Acc: 0.6130\n",
      "val Loss: 1.6537 Acc: 0.4961\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 1.1313 Acc: 0.6106\n",
      "val Loss: 1.1610 Acc: 0.6213\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 1.1255 Acc: 0.6123\n",
      "val Loss: 1.4028 Acc: 0.5396\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 1.1094 Acc: 0.6214\n",
      "val Loss: 1.4391 Acc: 0.5666\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 1.1182 Acc: 0.6137\n",
      "val Loss: 1.1513 Acc: 0.6340\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 1.1118 Acc: 0.6170\n",
      "val Loss: 1.7294 Acc: 0.5340\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 1.1066 Acc: 0.6197\n",
      "val Loss: 1.1339 Acc: 0.6223\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 1.0925 Acc: 0.6189\n",
      "val Loss: 1.1167 Acc: 0.6164\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 1.0986 Acc: 0.6245\n",
      "val Loss: 1.4984 Acc: 0.5505\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 1.0937 Acc: 0.6234\n",
      "val Loss: 2.1149 Acc: 0.4131\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 1.0817 Acc: 0.6338\n",
      "val Loss: 1.1657 Acc: 0.6154\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 1.0824 Acc: 0.6278\n",
      "val Loss: 1.1781 Acc: 0.6322\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 1.0709 Acc: 0.6340\n",
      "val Loss: 1.6149 Acc: 0.5520\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 1.0614 Acc: 0.6350\n",
      "val Loss: 0.8519 Acc: 0.7205\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 1.0749 Acc: 0.6316\n",
      "val Loss: 1.5300 Acc: 0.5335\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 1.0678 Acc: 0.6306\n",
      "val Loss: 1.9911 Acc: 0.4355\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 1.0490 Acc: 0.6378\n",
      "val Loss: 1.0774 Acc: 0.6447\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 1.0642 Acc: 0.6309\n",
      "val Loss: 1.0046 Acc: 0.6414\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 1.0411 Acc: 0.6430\n",
      "val Loss: 2.7151 Acc: 0.3993\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 1.0235 Acc: 0.6520\n",
      "val Loss: 2.7237 Acc: 0.3530\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 1.0327 Acc: 0.6451\n",
      "val Loss: 1.0319 Acc: 0.6735\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 1.0248 Acc: 0.6455\n",
      "val Loss: 1.3422 Acc: 0.5627\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 1.0314 Acc: 0.6486\n",
      "val Loss: 1.8661 Acc: 0.4935\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 1.0040 Acc: 0.6587\n",
      "val Loss: 0.7852 Acc: 0.7394\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 1.0125 Acc: 0.6557\n",
      "val Loss: 1.3561 Acc: 0.5706\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 1.0202 Acc: 0.6472\n",
      "val Loss: 1.2504 Acc: 0.6414\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.9964 Acc: 0.6539\n",
      "val Loss: 1.9432 Acc: 0.5251\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 1.0043 Acc: 0.6539\n",
      "val Loss: 1.2487 Acc: 0.6175\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 1.0063 Acc: 0.6545\n",
      "val Loss: 1.4771 Acc: 0.5235\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 1.0001 Acc: 0.6612\n",
      "val Loss: 2.3422 Acc: 0.3998\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.9736 Acc: 0.6702\n",
      "val Loss: 1.4623 Acc: 0.5859\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.9938 Acc: 0.6650\n",
      "val Loss: 2.4725 Acc: 0.4584\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.9704 Acc: 0.6659\n",
      "val Loss: 0.7709 Acc: 0.7465\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.9760 Acc: 0.6711\n",
      "val Loss: 1.1649 Acc: 0.6154\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.9693 Acc: 0.6729\n",
      "val Loss: 1.2626 Acc: 0.6279\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.9610 Acc: 0.6696\n",
      "val Loss: 2.9389 Acc: 0.2929\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.9478 Acc: 0.6792\n",
      "val Loss: 1.9125 Acc: 0.5419\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.9590 Acc: 0.6751\n",
      "val Loss: 2.0119 Acc: 0.4933\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.9488 Acc: 0.6708\n",
      "val Loss: 4.6940 Acc: 0.2876\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.9568 Acc: 0.6731\n",
      "val Loss: 2.4964 Acc: 0.4250\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.9517 Acc: 0.6732\n",
      "val Loss: 1.5860 Acc: 0.5780\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.9480 Acc: 0.6757\n",
      "val Loss: 2.6089 Acc: 0.3757\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.9368 Acc: 0.6814\n",
      "val Loss: 1.8303 Acc: 0.5381\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.9493 Acc: 0.6823\n",
      "val Loss: 0.8238 Acc: 0.7434\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.9426 Acc: 0.6772\n",
      "val Loss: 1.1706 Acc: 0.6373\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.9425 Acc: 0.6765\n",
      "val Loss: 1.1415 Acc: 0.6584\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.9363 Acc: 0.6755\n",
      "val Loss: 1.3819 Acc: 0.6142\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.9266 Acc: 0.6861\n",
      "val Loss: 1.3963 Acc: 0.5492\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.9313 Acc: 0.6847\n",
      "val Loss: 1.1273 Acc: 0.6167\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.8878 Acc: 0.6975\n",
      "val Loss: 5.4858 Acc: 0.1792\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.9171 Acc: 0.6932\n",
      "val Loss: 2.2343 Acc: 0.4276\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.9244 Acc: 0.6898\n",
      "val Loss: 0.8496 Acc: 0.7198\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.9146 Acc: 0.6865\n",
      "val Loss: 1.1864 Acc: 0.6541\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.9346 Acc: 0.6807\n",
      "val Loss: 0.8602 Acc: 0.7315\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.9306 Acc: 0.6852\n",
      "val Loss: 2.5568 Acc: 0.4961\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.9073 Acc: 0.6879\n",
      "val Loss: 1.7666 Acc: 0.5867\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.9052 Acc: 0.6932\n",
      "val Loss: 1.9172 Acc: 0.4431\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.8984 Acc: 0.6951\n",
      "val Loss: 0.8881 Acc: 0.7389\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.8992 Acc: 0.6968\n",
      "val Loss: 0.9020 Acc: 0.7335\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.8898 Acc: 0.6960\n",
      "val Loss: 1.3306 Acc: 0.5986\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.9050 Acc: 0.6929\n",
      "val Loss: 1.0981 Acc: 0.6676\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.8985 Acc: 0.6934\n",
      "val Loss: 1.7008 Acc: 0.5676\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.8857 Acc: 0.6994\n",
      "val Loss: 1.1755 Acc: 0.6847\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.8853 Acc: 0.6980\n",
      "val Loss: 0.9640 Acc: 0.6976\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.8856 Acc: 0.7027\n",
      "val Loss: 1.1862 Acc: 0.6327\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.8754 Acc: 0.7009\n",
      "val Loss: 0.8402 Acc: 0.7343\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.8722 Acc: 0.7028\n",
      "val Loss: 1.4116 Acc: 0.6226\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.8840 Acc: 0.6976\n",
      "val Loss: 1.1524 Acc: 0.6691\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.8779 Acc: 0.7018\n",
      "val Loss: 1.0322 Acc: 0.6757\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.8604 Acc: 0.7085\n",
      "val Loss: 1.5549 Acc: 0.6098\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.8645 Acc: 0.7039\n",
      "val Loss: 1.0776 Acc: 0.6755\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.8665 Acc: 0.7050\n",
      "val Loss: 1.3816 Acc: 0.6190\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.8627 Acc: 0.7095\n",
      "val Loss: 1.0445 Acc: 0.6852\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.8612 Acc: 0.7101\n",
      "val Loss: 5.5193 Acc: 0.3006\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.8442 Acc: 0.7157\n",
      "val Loss: 1.0595 Acc: 0.6785\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.8558 Acc: 0.7064\n",
      "val Loss: 1.8205 Acc: 0.5492\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.8218 Acc: 0.7210\n",
      "val Loss: 1.6694 Acc: 0.5566\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.8501 Acc: 0.7109\n",
      "val Loss: 1.0441 Acc: 0.6539\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.8591 Acc: 0.7086\n",
      "val Loss: 1.3364 Acc: 0.6340\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.8467 Acc: 0.7176\n",
      "val Loss: 2.2297 Acc: 0.4543\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.8278 Acc: 0.7148\n",
      "val Loss: 0.9617 Acc: 0.7007\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "train Loss: 0.8413 Acc: 0.7120\n",
      "val Loss: 1.0530 Acc: 0.6890\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.8320 Acc: 0.7204\n",
      "val Loss: 1.3259 Acc: 0.6399\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.8307 Acc: 0.7212\n",
      "val Loss: 0.9219 Acc: 0.7175\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.8040 Acc: 0.7283\n",
      "val Loss: 1.0197 Acc: 0.7340\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.8215 Acc: 0.7218\n",
      "val Loss: 0.8478 Acc: 0.7549\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.8322 Acc: 0.7191\n",
      "val Loss: 1.1387 Acc: 0.6765\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.8207 Acc: 0.7187\n",
      "val Loss: 2.0717 Acc: 0.5001\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.8176 Acc: 0.7234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-27 21:06:31,139]\u001b[0m Trial 0 finished with value: 0.7548994655128531 and parameters: {'optimizer': 'RMSprop', 'lr': 0.04366056970214902}. Best is trial 0 with value: 0.7548994655128531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.8996 Acc: 0.3668\n",
      "\n",
      "Training complete in 246m 13s\n",
      "Best val Acc: 0.754899\n",
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 2.3512 Acc: 0.1569\n",
      "val Loss: 2.6536 Acc: 0.1542\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 2.1979 Acc: 0.1685\n",
      "val Loss: 3.4213 Acc: 0.1586\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 2.1753 Acc: 0.1781\n",
      "val Loss: 2.1355 Acc: 0.1889\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 2.1402 Acc: 0.1965\n",
      "val Loss: 2.1914 Acc: 0.1932\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 2.1158 Acc: 0.2064\n",
      "val Loss: 2.0893 Acc: 0.2194\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 2.0883 Acc: 0.2213\n",
      "val Loss: 2.0332 Acc: 0.2301\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 2.0760 Acc: 0.2240\n",
      "val Loss: 2.0802 Acc: 0.2339\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 2.0509 Acc: 0.2335\n",
      "val Loss: 2.0218 Acc: 0.2522\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 2.0260 Acc: 0.2486\n",
      "val Loss: 1.9450 Acc: 0.2907\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 1.9916 Acc: 0.2620\n",
      "val Loss: 1.9310 Acc: 0.2975\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 1.9676 Acc: 0.2728\n",
      "val Loss: 1.9120 Acc: 0.2853\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 1.9203 Acc: 0.2910\n",
      "val Loss: 1.7609 Acc: 0.3668\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 1.8899 Acc: 0.3168\n",
      "val Loss: 1.9144 Acc: 0.3235\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 1.8452 Acc: 0.3316\n",
      "val Loss: 1.7222 Acc: 0.3777\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 1.8110 Acc: 0.3490\n",
      "val Loss: 1.8942 Acc: 0.3286\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 1.7634 Acc: 0.3638\n",
      "val Loss: 1.7013 Acc: 0.3797\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 1.7437 Acc: 0.3761\n",
      "val Loss: 1.5636 Acc: 0.4373\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 1.7001 Acc: 0.4009\n",
      "val Loss: 1.5445 Acc: 0.4543\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 1.6697 Acc: 0.4024\n",
      "val Loss: 1.5096 Acc: 0.4665\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 1.6511 Acc: 0.4151\n",
      "val Loss: 1.5223 Acc: 0.4495\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 1.6306 Acc: 0.4170\n",
      "val Loss: 1.4662 Acc: 0.4915\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 1.5990 Acc: 0.4348\n",
      "val Loss: 1.4445 Acc: 0.4907\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 1.5776 Acc: 0.4443\n",
      "val Loss: 1.4190 Acc: 0.5093\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 1.5372 Acc: 0.4643\n",
      "val Loss: 1.4029 Acc: 0.5200\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 1.5173 Acc: 0.4659\n",
      "val Loss: 1.4837 Acc: 0.4739\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 1.4870 Acc: 0.4811\n",
      "val Loss: 1.3204 Acc: 0.5401\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 1.4742 Acc: 0.4830\n",
      "val Loss: 1.3475 Acc: 0.5322\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 1.4773 Acc: 0.4830\n",
      "val Loss: 1.5890 Acc: 0.4747\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 1.4389 Acc: 0.5020\n",
      "val Loss: 1.1964 Acc: 0.5862\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 1.4250 Acc: 0.5011\n",
      "val Loss: 1.3285 Acc: 0.5510\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 1.4007 Acc: 0.5124\n",
      "val Loss: 1.4590 Acc: 0.4981\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 1.3437 Acc: 0.5348\n",
      "val Loss: 1.3416 Acc: 0.5378\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 1.3542 Acc: 0.5228\n",
      "val Loss: 1.1012 Acc: 0.6315\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 1.3296 Acc: 0.5368\n",
      "val Loss: 1.1166 Acc: 0.6223\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 1.2885 Acc: 0.5560\n",
      "val Loss: 1.0966 Acc: 0.6358\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 1.2631 Acc: 0.5639\n",
      "val Loss: 1.0504 Acc: 0.6480\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 1.2530 Acc: 0.5693\n",
      "val Loss: 1.1534 Acc: 0.6218\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 1.2234 Acc: 0.5819\n",
      "val Loss: 1.1075 Acc: 0.6427\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 1.1929 Acc: 0.5937\n",
      "val Loss: 1.0723 Acc: 0.6411\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 1.2064 Acc: 0.5842\n",
      "val Loss: 1.0219 Acc: 0.6554\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 1.1793 Acc: 0.5953\n",
      "val Loss: 1.0023 Acc: 0.6607\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 1.1441 Acc: 0.6051\n",
      "val Loss: 0.9600 Acc: 0.6696\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 1.1230 Acc: 0.6104\n",
      "val Loss: 0.9344 Acc: 0.6852\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 1.1088 Acc: 0.6155\n",
      "val Loss: 0.8744 Acc: 0.7027\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 1.0825 Acc: 0.6269\n",
      "val Loss: 1.0171 Acc: 0.6617\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 1.0787 Acc: 0.6361\n",
      "val Loss: 1.0069 Acc: 0.6755\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 1.0731 Acc: 0.6324\n",
      "val Loss: 1.0010 Acc: 0.6623\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 1.0314 Acc: 0.6463\n",
      "val Loss: 0.8661 Acc: 0.7116\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 1.0228 Acc: 0.6479\n",
      "val Loss: 0.9442 Acc: 0.6829\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 1.0118 Acc: 0.6499\n",
      "val Loss: 0.8633 Acc: 0.7111\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 0.9980 Acc: 0.6623\n",
      "val Loss: 0.8972 Acc: 0.7109\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 0.9683 Acc: 0.6734\n",
      "val Loss: 0.8602 Acc: 0.7154\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 0.9715 Acc: 0.6659\n",
      "val Loss: 0.8405 Acc: 0.7210\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 0.9538 Acc: 0.6756\n",
      "val Loss: 0.7721 Acc: 0.7483\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 0.9444 Acc: 0.6770\n",
      "val Loss: 0.8794 Acc: 0.7055\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 0.9427 Acc: 0.6755\n",
      "val Loss: 0.9134 Acc: 0.6920\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 0.9170 Acc: 0.6847\n",
      "val Loss: 0.8609 Acc: 0.7147\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 0.9282 Acc: 0.6852\n",
      "val Loss: 0.9496 Acc: 0.7004\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 0.8813 Acc: 0.6943\n",
      "val Loss: 0.8575 Acc: 0.7277\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 0.8824 Acc: 0.7003\n",
      "val Loss: 0.8539 Acc: 0.7221\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 0.8712 Acc: 0.7013\n",
      "val Loss: 0.8811 Acc: 0.7394\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 0.8712 Acc: 0.7017\n",
      "val Loss: 0.8276 Acc: 0.7277\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 0.8603 Acc: 0.7055\n",
      "val Loss: 0.8334 Acc: 0.7325\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 0.8459 Acc: 0.7078\n",
      "val Loss: 0.7814 Acc: 0.7457\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 0.8414 Acc: 0.7117\n",
      "val Loss: 0.7782 Acc: 0.7412\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 0.8309 Acc: 0.7157\n",
      "val Loss: 0.7585 Acc: 0.7478\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 0.8268 Acc: 0.7156\n",
      "val Loss: 0.7766 Acc: 0.7541\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 0.8138 Acc: 0.7208\n",
      "val Loss: 0.7525 Acc: 0.7699\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 0.7957 Acc: 0.7250\n",
      "val Loss: 0.7412 Acc: 0.7585\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 0.7995 Acc: 0.7261\n",
      "val Loss: 0.7517 Acc: 0.7539\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 0.7990 Acc: 0.7275\n",
      "val Loss: 0.6816 Acc: 0.7793\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 0.7859 Acc: 0.7341\n",
      "val Loss: 0.7614 Acc: 0.7587\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 0.7747 Acc: 0.7345\n",
      "val Loss: 0.7505 Acc: 0.7521\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 0.7621 Acc: 0.7397\n",
      "val Loss: 0.8289 Acc: 0.7399\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 0.7663 Acc: 0.7383\n",
      "val Loss: 0.6997 Acc: 0.7765\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 0.7462 Acc: 0.7453\n",
      "val Loss: 0.6689 Acc: 0.7821\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 0.7426 Acc: 0.7464\n",
      "val Loss: 0.7314 Acc: 0.7709\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 0.7451 Acc: 0.7459\n",
      "val Loss: 0.6933 Acc: 0.7781\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 0.7418 Acc: 0.7453\n",
      "val Loss: 0.7195 Acc: 0.7742\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 0.7232 Acc: 0.7616\n",
      "val Loss: 0.6848 Acc: 0.7796\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 0.7349 Acc: 0.7511\n",
      "val Loss: 0.7640 Acc: 0.7567\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 0.7041 Acc: 0.7642\n",
      "val Loss: 0.6806 Acc: 0.7882\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 0.7136 Acc: 0.7590\n",
      "val Loss: 0.7146 Acc: 0.7717\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 0.6988 Acc: 0.7631\n",
      "val Loss: 0.6668 Acc: 0.7832\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 0.7076 Acc: 0.7579\n",
      "val Loss: 0.6528 Acc: 0.7905\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 0.6659 Acc: 0.7694\n",
      "val Loss: 0.7222 Acc: 0.7748\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 0.6896 Acc: 0.7639\n",
      "val Loss: 0.6792 Acc: 0.7834\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 0.6783 Acc: 0.7707\n",
      "val Loss: 0.6770 Acc: 0.7849\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 0.6854 Acc: 0.7652\n",
      "val Loss: 0.6522 Acc: 0.7875\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 0.6806 Acc: 0.7716\n",
      "val Loss: 0.7438 Acc: 0.7689\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 0.6618 Acc: 0.7707\n",
      "val Loss: 0.6735 Acc: 0.7842\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 0.6690 Acc: 0.7721\n",
      "val Loss: 0.6693 Acc: 0.7928\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 0.6453 Acc: 0.7824\n",
      "val Loss: 0.6625 Acc: 0.7946\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.6552 Acc: 0.7792\n",
      "val Loss: 0.7179 Acc: 0.7760\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.6346 Acc: 0.7840\n",
      "val Loss: 0.6641 Acc: 0.7992\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.6428 Acc: 0.7848\n",
      "val Loss: 0.7220 Acc: 0.7954\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.6265 Acc: 0.7856\n",
      "val Loss: 0.6615 Acc: 0.7987\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.6222 Acc: 0.7881\n",
      "val Loss: 0.6830 Acc: 0.7776\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.6200 Acc: 0.7879\n",
      "val Loss: 0.6808 Acc: 0.7966\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.6290 Acc: 0.7883\n",
      "val Loss: 0.6582 Acc: 0.7903\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.6206 Acc: 0.7880\n",
      "val Loss: 0.6711 Acc: 0.8020\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.6121 Acc: 0.7920\n",
      "val Loss: 0.6499 Acc: 0.7951\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.6023 Acc: 0.7987\n",
      "val Loss: 0.6808 Acc: 0.7966\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.6010 Acc: 0.7960\n",
      "val Loss: 0.7189 Acc: 0.7788\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.5940 Acc: 0.7943\n",
      "val Loss: 0.6633 Acc: 0.8005\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.6062 Acc: 0.7984\n",
      "val Loss: 0.6220 Acc: 0.8017\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.5937 Acc: 0.8034\n",
      "val Loss: 0.7058 Acc: 0.7898\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.5917 Acc: 0.8000\n",
      "val Loss: 0.6867 Acc: 0.7882\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.5652 Acc: 0.8068\n",
      "val Loss: 0.7388 Acc: 0.7796\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.6322 Acc: 0.7865\n",
      "val Loss: 0.6413 Acc: 0.8038\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.5709 Acc: 0.8094\n",
      "val Loss: 0.6875 Acc: 0.7908\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.5504 Acc: 0.8132\n",
      "val Loss: 0.7037 Acc: 0.7956\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.5597 Acc: 0.8089\n",
      "val Loss: 0.6553 Acc: 0.7997\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.5662 Acc: 0.8089\n",
      "val Loss: 0.6511 Acc: 0.7956\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.5443 Acc: 0.8122\n",
      "val Loss: 0.6727 Acc: 0.8061\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.5469 Acc: 0.8148\n",
      "val Loss: 0.7431 Acc: 0.7844\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.5387 Acc: 0.8178\n",
      "val Loss: 0.6318 Acc: 0.8066\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.5633 Acc: 0.8084\n",
      "val Loss: 0.6434 Acc: 0.8119\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.5498 Acc: 0.8158\n",
      "val Loss: 0.6796 Acc: 0.7946\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.5393 Acc: 0.8178\n",
      "val Loss: 0.6874 Acc: 0.7954\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.5794 Acc: 0.8053\n",
      "val Loss: 0.6901 Acc: 0.7997\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.5333 Acc: 0.8197\n",
      "val Loss: 0.6172 Acc: 0.8193\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.5282 Acc: 0.8225\n",
      "val Loss: 0.5952 Acc: 0.8137\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.5338 Acc: 0.8151\n",
      "val Loss: 0.7339 Acc: 0.7689\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.5357 Acc: 0.8165\n",
      "val Loss: 0.6368 Acc: 0.8053\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.5203 Acc: 0.8259\n",
      "val Loss: 0.6331 Acc: 0.8122\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.5224 Acc: 0.8206\n",
      "val Loss: 0.6415 Acc: 0.8053\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.5056 Acc: 0.8307\n",
      "val Loss: 0.6862 Acc: 0.7928\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.5191 Acc: 0.8240\n",
      "val Loss: 0.7112 Acc: 0.8043\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.5203 Acc: 0.8258\n",
      "val Loss: 0.6325 Acc: 0.8160\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.4871 Acc: 0.8340\n",
      "val Loss: 0.7020 Acc: 0.7933\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.4968 Acc: 0.8320\n",
      "val Loss: 0.6540 Acc: 0.8089\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.4917 Acc: 0.8322\n",
      "val Loss: 0.6290 Acc: 0.8195\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.4864 Acc: 0.8368\n",
      "val Loss: 0.6783 Acc: 0.8063\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.4867 Acc: 0.8348\n",
      "val Loss: 0.7278 Acc: 0.7956\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.4890 Acc: 0.8361\n",
      "val Loss: 0.6423 Acc: 0.8132\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.4993 Acc: 0.8306\n",
      "val Loss: 0.6738 Acc: 0.8127\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.4835 Acc: 0.8398\n",
      "val Loss: 0.6950 Acc: 0.7941\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.4978 Acc: 0.8321\n",
      "val Loss: 0.7011 Acc: 0.8099\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.4861 Acc: 0.8334\n",
      "val Loss: 0.6557 Acc: 0.8109\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.4987 Acc: 0.8290\n",
      "val Loss: 0.6481 Acc: 0.8106\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.4732 Acc: 0.8421\n",
      "val Loss: 0.7153 Acc: 0.8017\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.4825 Acc: 0.8359\n",
      "val Loss: 0.6248 Acc: 0.8254\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.4649 Acc: 0.8412\n",
      "val Loss: 0.7389 Acc: 0.8076\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.4564 Acc: 0.8462\n",
      "val Loss: 0.6133 Acc: 0.8257\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.4532 Acc: 0.8501\n",
      "val Loss: 0.6735 Acc: 0.8117\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.4678 Acc: 0.8429\n",
      "val Loss: 0.8130 Acc: 0.7717\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.4865 Acc: 0.8338\n",
      "val Loss: 0.7801 Acc: 0.7890\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.4594 Acc: 0.8444\n",
      "val Loss: 0.6502 Acc: 0.8073\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.4526 Acc: 0.8492\n",
      "val Loss: 0.6883 Acc: 0.8096\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.4658 Acc: 0.8433\n",
      "val Loss: 0.6707 Acc: 0.8096\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.4525 Acc: 0.8525\n",
      "val Loss: 0.7178 Acc: 0.8124\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.4564 Acc: 0.8522\n",
      "val Loss: 0.7245 Acc: 0.8053\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.4380 Acc: 0.8535\n",
      "val Loss: 0.6481 Acc: 0.8142\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.4516 Acc: 0.8491\n",
      "val Loss: 0.6996 Acc: 0.8139\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.4584 Acc: 0.8455\n",
      "val Loss: 0.6732 Acc: 0.8134\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.4549 Acc: 0.8465\n",
      "val Loss: 0.6398 Acc: 0.8139\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.4418 Acc: 0.8475\n",
      "val Loss: 0.6741 Acc: 0.8201\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.4445 Acc: 0.8523\n",
      "val Loss: 0.6901 Acc: 0.8073\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.4235 Acc: 0.8570\n",
      "val Loss: 0.6673 Acc: 0.8211\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.4438 Acc: 0.8496\n",
      "val Loss: 0.6418 Acc: 0.8178\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.4463 Acc: 0.8473\n",
      "val Loss: 0.6956 Acc: 0.8157\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.4246 Acc: 0.8580\n",
      "val Loss: 0.7084 Acc: 0.8089\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.4404 Acc: 0.8523\n",
      "val Loss: 0.6773 Acc: 0.8089\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.4320 Acc: 0.8575\n",
      "val Loss: 0.6800 Acc: 0.8241\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.4158 Acc: 0.8614\n",
      "val Loss: 0.6946 Acc: 0.8071\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.4325 Acc: 0.8533\n",
      "val Loss: 0.6477 Acc: 0.8236\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.4096 Acc: 0.8625\n",
      "val Loss: 0.6432 Acc: 0.8287\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.4079 Acc: 0.8639\n",
      "val Loss: 0.6847 Acc: 0.8170\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.4164 Acc: 0.8578\n",
      "val Loss: 0.7341 Acc: 0.8178\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.4226 Acc: 0.8586\n",
      "val Loss: 0.7605 Acc: 0.8147\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.4091 Acc: 0.8656\n",
      "val Loss: 0.7324 Acc: 0.8058\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.4126 Acc: 0.8654\n",
      "val Loss: 0.7127 Acc: 0.8129\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.4090 Acc: 0.8627\n",
      "val Loss: 0.6825 Acc: 0.8246\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.4242 Acc: 0.8595\n",
      "val Loss: 0.6733 Acc: 0.8124\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.4173 Acc: 0.8608\n",
      "val Loss: 0.6975 Acc: 0.8165\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.4127 Acc: 0.8601\n",
      "val Loss: 0.7090 Acc: 0.8040\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.4035 Acc: 0.8659\n",
      "val Loss: 0.6763 Acc: 0.8193\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.3872 Acc: 0.8742\n",
      "val Loss: 0.7197 Acc: 0.8203\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.4136 Acc: 0.8639\n",
      "val Loss: 0.7194 Acc: 0.8071\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.4055 Acc: 0.8633\n",
      "val Loss: 0.6960 Acc: 0.8137\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.4145 Acc: 0.8601\n",
      "val Loss: 0.6959 Acc: 0.8287\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.3895 Acc: 0.8712\n",
      "val Loss: 0.6787 Acc: 0.8249\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.3836 Acc: 0.8729\n",
      "val Loss: 0.6881 Acc: 0.8162\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.4091 Acc: 0.8626\n",
      "val Loss: 0.7009 Acc: 0.8221\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.3866 Acc: 0.8726\n",
      "val Loss: 0.6547 Acc: 0.8262\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.3842 Acc: 0.8712\n",
      "val Loss: 0.7167 Acc: 0.8106\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.3892 Acc: 0.8697\n",
      "val Loss: 0.6985 Acc: 0.8295\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.3813 Acc: 0.8732\n",
      "val Loss: 0.7684 Acc: 0.7994\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.3970 Acc: 0.8673\n",
      "val Loss: 0.7748 Acc: 0.8111\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.3832 Acc: 0.8727\n",
      "val Loss: 0.6834 Acc: 0.8175\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.3815 Acc: 0.8711\n",
      "val Loss: 0.6830 Acc: 0.8279\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "train Loss: 0.4056 Acc: 0.8627\n",
      "val Loss: 0.6586 Acc: 0.8195\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.3821 Acc: 0.8702\n",
      "val Loss: 0.6485 Acc: 0.8302\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.3837 Acc: 0.8693\n",
      "val Loss: 0.7157 Acc: 0.8094\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.3945 Acc: 0.8690\n",
      "val Loss: 0.8014 Acc: 0.8147\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.3776 Acc: 0.8762\n",
      "val Loss: 0.7355 Acc: 0.8178\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.3743 Acc: 0.8784\n",
      "val Loss: 0.6463 Acc: 0.8300\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.3703 Acc: 0.8773\n",
      "val Loss: 0.6918 Acc: 0.8259\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.3838 Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-28 01:39:36,330]\u001b[0m Trial 1 finished with value: 0.8302367014507508 and parameters: {'optimizer': 'Adam', 'lr': 0.0033728675244193286}. Best is trial 1 with value: 0.8302367014507508.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7112 Acc: 0.8211\n",
      "\n",
      "Training complete in 273m 4s\n",
      "Best val Acc: 0.830237\n",
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 2.5002 Acc: 0.1116\n",
      "val Loss: 8.4921 Acc: 0.0570\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 2.3980 Acc: 0.1415\n",
      "val Loss: 7.0569 Acc: 0.1036\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 2.3121 Acc: 0.1676\n",
      "val Loss: 5.5736 Acc: 0.1064\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 2.2684 Acc: 0.1783\n",
      "val Loss: 6.5449 Acc: 0.1044\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 2.2207 Acc: 0.1866\n",
      "val Loss: 5.4457 Acc: 0.1077\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 2.1803 Acc: 0.2002\n",
      "val Loss: 6.2965 Acc: 0.1105\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 2.1577 Acc: 0.2100\n",
      "val Loss: 6.8147 Acc: 0.1084\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 2.1178 Acc: 0.2256\n",
      "val Loss: 4.6509 Acc: 0.1064\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 2.1049 Acc: 0.2328\n",
      "val Loss: 4.3722 Acc: 0.1056\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 2.0871 Acc: 0.2365\n",
      "val Loss: 4.0011 Acc: 0.1196\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 2.0660 Acc: 0.2453\n",
      "val Loss: 5.9247 Acc: 0.1051\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 2.0258 Acc: 0.2654\n",
      "val Loss: 5.0188 Acc: 0.1158\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 2.0034 Acc: 0.2772\n",
      "val Loss: 4.0988 Acc: 0.1176\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 1.9607 Acc: 0.2954\n",
      "val Loss: 4.2269 Acc: 0.1283\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 1.9392 Acc: 0.3017\n",
      "val Loss: 3.4952 Acc: 0.1710\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 1.9188 Acc: 0.3060\n",
      "val Loss: 4.2146 Acc: 0.1308\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 1.8810 Acc: 0.3304\n",
      "val Loss: 4.0012 Acc: 0.1097\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 1.8518 Acc: 0.3334\n",
      "val Loss: 5.3382 Acc: 0.1257\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 1.8263 Acc: 0.3447\n",
      "val Loss: 3.6379 Acc: 0.2051\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 1.8187 Acc: 0.3484\n",
      "val Loss: 5.0011 Acc: 0.1471\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 1.7844 Acc: 0.3632\n",
      "val Loss: 3.2068 Acc: 0.2308\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 1.7880 Acc: 0.3588\n",
      "val Loss: 2.6750 Acc: 0.2487\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 1.7679 Acc: 0.3679\n",
      "val Loss: 4.4069 Acc: 0.1525\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 1.7304 Acc: 0.3832\n",
      "val Loss: 3.2641 Acc: 0.2217\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 1.7418 Acc: 0.3783\n",
      "val Loss: 2.4971 Acc: 0.2367\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 1.7072 Acc: 0.3973\n",
      "val Loss: 2.9043 Acc: 0.2247\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 1.6972 Acc: 0.3977\n",
      "val Loss: 2.0353 Acc: 0.3057\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 1.6741 Acc: 0.4037\n",
      "val Loss: 3.2308 Acc: 0.2352\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 1.6560 Acc: 0.4154\n",
      "val Loss: 2.5549 Acc: 0.2917\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 1.6475 Acc: 0.4183\n",
      "val Loss: 2.8617 Acc: 0.2637\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 1.6381 Acc: 0.4219\n",
      "val Loss: 2.9814 Acc: 0.2237\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 1.6276 Acc: 0.4293\n",
      "val Loss: 2.6497 Acc: 0.3171\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 1.6087 Acc: 0.4320\n",
      "val Loss: 2.8687 Acc: 0.3006\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 1.6055 Acc: 0.4356\n",
      "val Loss: 3.2198 Acc: 0.3316\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 1.5871 Acc: 0.4398\n",
      "val Loss: 2.3192 Acc: 0.3627\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 1.5662 Acc: 0.4489\n",
      "val Loss: 2.1375 Acc: 0.3408\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 1.5677 Acc: 0.4515\n",
      "val Loss: 2.7255 Acc: 0.3159\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 1.5465 Acc: 0.4536\n",
      "val Loss: 2.3973 Acc: 0.2947\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 1.5329 Acc: 0.4599\n",
      "val Loss: 2.6922 Acc: 0.3179\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 1.5131 Acc: 0.4665\n",
      "val Loss: 1.7973 Acc: 0.4225\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 1.5072 Acc: 0.4809\n",
      "val Loss: 2.5265 Acc: 0.3433\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 1.4991 Acc: 0.4798\n",
      "val Loss: 1.9840 Acc: 0.3970\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 1.4782 Acc: 0.4937\n",
      "val Loss: 2.3705 Acc: 0.3874\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 1.4778 Acc: 0.4899\n",
      "val Loss: 2.0592 Acc: 0.4243\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 1.4693 Acc: 0.4884\n",
      "val Loss: 2.1759 Acc: 0.4396\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 1.4369 Acc: 0.5050\n",
      "val Loss: 3.0147 Acc: 0.3194\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 1.4330 Acc: 0.5034\n",
      "val Loss: 1.8498 Acc: 0.4029\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 1.4179 Acc: 0.5104\n",
      "val Loss: 2.1740 Acc: 0.3619\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 1.4172 Acc: 0.5078\n",
      "val Loss: 1.8521 Acc: 0.4569\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 1.3864 Acc: 0.5197\n",
      "val Loss: 2.3529 Acc: 0.3991\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 1.3901 Acc: 0.5188\n",
      "val Loss: 2.3957 Acc: 0.4172\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 1.3658 Acc: 0.5282\n",
      "val Loss: 2.9173 Acc: 0.3993\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 1.3622 Acc: 0.5289\n",
      "val Loss: 1.5884 Acc: 0.4943\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 1.3497 Acc: 0.5331\n",
      "val Loss: 3.2340 Acc: 0.3902\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 1.3510 Acc: 0.5324\n",
      "val Loss: 2.4631 Acc: 0.4220\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 1.3426 Acc: 0.5376\n",
      "val Loss: 2.3515 Acc: 0.4334\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 1.3121 Acc: 0.5452\n",
      "val Loss: 2.1107 Acc: 0.4683\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 1.3125 Acc: 0.5493\n",
      "val Loss: 1.7781 Acc: 0.5195\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 1.3087 Acc: 0.5531\n",
      "val Loss: 1.4143 Acc: 0.5452\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 1.3154 Acc: 0.5549\n",
      "val Loss: 2.1565 Acc: 0.4548\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 1.2855 Acc: 0.5598\n",
      "val Loss: 2.1844 Acc: 0.4724\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 1.2720 Acc: 0.5695\n",
      "val Loss: 1.6150 Acc: 0.4803\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 1.2531 Acc: 0.5744\n",
      "val Loss: 1.8150 Acc: 0.5111\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 1.2568 Acc: 0.5730\n",
      "val Loss: 4.3040 Acc: 0.3299\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 1.2480 Acc: 0.5699\n",
      "val Loss: 2.5788 Acc: 0.4312\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 1.2275 Acc: 0.5782\n",
      "val Loss: 2.1195 Acc: 0.5019\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 1.2329 Acc: 0.5815\n",
      "val Loss: 2.0713 Acc: 0.4787\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 1.1949 Acc: 0.5863\n",
      "val Loss: 1.5945 Acc: 0.5090\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 1.2185 Acc: 0.5825\n",
      "val Loss: 1.8202 Acc: 0.5477\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 1.1795 Acc: 0.5946\n",
      "val Loss: 1.5545 Acc: 0.5617\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 1.1709 Acc: 0.5971\n",
      "val Loss: 2.2266 Acc: 0.5195\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 1.1675 Acc: 0.5963\n",
      "val Loss: 1.6277 Acc: 0.5233\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 1.1552 Acc: 0.6048\n",
      "val Loss: 1.9859 Acc: 0.5302\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 1.1434 Acc: 0.6103\n",
      "val Loss: 1.4053 Acc: 0.5770\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 1.1316 Acc: 0.6136\n",
      "val Loss: 1.3185 Acc: 0.5877\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 1.1373 Acc: 0.6093\n",
      "val Loss: 1.6826 Acc: 0.5727\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 1.1299 Acc: 0.6141\n",
      "val Loss: 1.5070 Acc: 0.5795\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 1.1254 Acc: 0.6171\n",
      "val Loss: 1.7054 Acc: 0.5526\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 1.1280 Acc: 0.6162\n",
      "val Loss: 1.8346 Acc: 0.5788\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 1.0966 Acc: 0.6295\n",
      "val Loss: 2.0016 Acc: 0.5365\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 1.1012 Acc: 0.6223\n",
      "val Loss: 1.4378 Acc: 0.5729\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 1.0729 Acc: 0.6397\n",
      "val Loss: 1.5303 Acc: 0.5986\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 1.0922 Acc: 0.6247\n",
      "val Loss: 1.3915 Acc: 0.5477\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 1.0615 Acc: 0.6339\n",
      "val Loss: 1.9045 Acc: 0.5592\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 1.0290 Acc: 0.6516\n",
      "val Loss: 1.9793 Acc: 0.5678\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 1.0481 Acc: 0.6453\n",
      "val Loss: 1.3613 Acc: 0.5981\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 1.0591 Acc: 0.6451\n",
      "val Loss: 2.3700 Acc: 0.5742\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 1.0390 Acc: 0.6480\n",
      "val Loss: 1.2611 Acc: 0.6190\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 1.0227 Acc: 0.6522\n",
      "val Loss: 1.4624 Acc: 0.5895\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 1.0211 Acc: 0.6552\n",
      "val Loss: 3.8711 Acc: 0.4767\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 1.0200 Acc: 0.6529\n",
      "val Loss: 1.1729 Acc: 0.6307\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 1.0241 Acc: 0.6523\n",
      "val Loss: 1.2248 Acc: 0.6063\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 1.0037 Acc: 0.6562\n",
      "val Loss: 1.0863 Acc: 0.6556\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.9861 Acc: 0.6688\n",
      "val Loss: 1.5178 Acc: 0.6136\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.9946 Acc: 0.6615\n",
      "val Loss: 1.2757 Acc: 0.6317\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.9967 Acc: 0.6598\n",
      "val Loss: 1.4524 Acc: 0.6243\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.9719 Acc: 0.6718\n",
      "val Loss: 1.6178 Acc: 0.6065\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.9655 Acc: 0.6736\n",
      "val Loss: 1.4079 Acc: 0.6177\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.9641 Acc: 0.6688\n",
      "val Loss: 3.2877 Acc: 0.5299\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.9590 Acc: 0.6778\n",
      "val Loss: 1.2275 Acc: 0.6325\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.9436 Acc: 0.6780\n",
      "val Loss: 1.5733 Acc: 0.6080\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.9443 Acc: 0.6777\n",
      "val Loss: 1.4149 Acc: 0.5879\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.9384 Acc: 0.6876\n",
      "val Loss: 3.5382 Acc: 0.5645\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.8992 Acc: 0.6934\n",
      "val Loss: 1.4417 Acc: 0.6447\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.9327 Acc: 0.6900\n",
      "val Loss: 1.4741 Acc: 0.6017\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.9135 Acc: 0.6920\n",
      "val Loss: 1.9309 Acc: 0.6121\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.9120 Acc: 0.6900\n",
      "val Loss: 1.1246 Acc: 0.6378\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.9004 Acc: 0.6947\n",
      "val Loss: 1.3617 Acc: 0.6106\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.8915 Acc: 0.6984\n",
      "val Loss: 2.4227 Acc: 0.5897\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.8833 Acc: 0.7028\n",
      "val Loss: 1.8600 Acc: 0.6281\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.8738 Acc: 0.7038\n",
      "val Loss: 1.6391 Acc: 0.6080\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.8768 Acc: 0.6999\n",
      "val Loss: 1.9541 Acc: 0.6037\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.8582 Acc: 0.7130\n",
      "val Loss: 1.3686 Acc: 0.6747\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.8538 Acc: 0.7093\n",
      "val Loss: 4.0754 Acc: 0.5963\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.8616 Acc: 0.7025\n",
      "val Loss: 1.1409 Acc: 0.6679\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.8561 Acc: 0.7067\n",
      "val Loss: 1.0287 Acc: 0.6956\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.8356 Acc: 0.7179\n",
      "val Loss: 1.4888 Acc: 0.6279\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.8334 Acc: 0.7227\n",
      "val Loss: 1.1159 Acc: 0.6839\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.8382 Acc: 0.7187\n",
      "val Loss: 1.5333 Acc: 0.6595\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.8315 Acc: 0.7212\n",
      "val Loss: 1.6820 Acc: 0.6279\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.8271 Acc: 0.7188\n",
      "val Loss: 1.4536 Acc: 0.6238\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.8295 Acc: 0.7198\n",
      "val Loss: 1.0850 Acc: 0.6770\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.8213 Acc: 0.7269\n",
      "val Loss: 1.1496 Acc: 0.6951\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.8145 Acc: 0.7231\n",
      "val Loss: 1.6311 Acc: 0.5523\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.8099 Acc: 0.7248\n",
      "val Loss: 1.7349 Acc: 0.5755\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.8111 Acc: 0.7274\n",
      "val Loss: 1.9499 Acc: 0.6220\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.7954 Acc: 0.7305\n",
      "val Loss: 1.2874 Acc: 0.6444\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.7924 Acc: 0.7344\n",
      "val Loss: 1.7571 Acc: 0.6322\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.7721 Acc: 0.7368\n",
      "val Loss: 0.9865 Acc: 0.6859\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.8023 Acc: 0.7300\n",
      "val Loss: 1.2456 Acc: 0.6905\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.7735 Acc: 0.7372\n",
      "val Loss: 1.1893 Acc: 0.6533\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.7815 Acc: 0.7330\n",
      "val Loss: 1.8997 Acc: 0.6544\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.7768 Acc: 0.7395\n",
      "val Loss: 1.1944 Acc: 0.6791\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.7552 Acc: 0.7473\n",
      "val Loss: 1.2870 Acc: 0.6200\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.7645 Acc: 0.7412\n",
      "val Loss: 1.0153 Acc: 0.6844\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.7552 Acc: 0.7479\n",
      "val Loss: 1.5047 Acc: 0.6722\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.7533 Acc: 0.7494\n",
      "val Loss: 1.1827 Acc: 0.6869\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.7564 Acc: 0.7471\n",
      "val Loss: 2.9805 Acc: 0.6434\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.7434 Acc: 0.7474\n",
      "val Loss: 1.3799 Acc: 0.6691\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.7550 Acc: 0.7453\n",
      "val Loss: 1.4721 Acc: 0.6640\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.7381 Acc: 0.7539\n",
      "val Loss: 2.5493 Acc: 0.5856\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.7489 Acc: 0.7440\n",
      "val Loss: 1.7640 Acc: 0.6253\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.7250 Acc: 0.7568\n",
      "val Loss: 1.0956 Acc: 0.6732\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.7146 Acc: 0.7581\n",
      "val Loss: 1.5927 Acc: 0.7071\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.7355 Acc: 0.7460\n",
      "val Loss: 2.0674 Acc: 0.6279\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.7159 Acc: 0.7573\n",
      "val Loss: 1.5598 Acc: 0.6467\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.7153 Acc: 0.7572\n",
      "val Loss: 2.2243 Acc: 0.6360\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.7155 Acc: 0.7603\n",
      "val Loss: 1.0067 Acc: 0.6913\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.6995 Acc: 0.7606\n",
      "val Loss: 1.1959 Acc: 0.6663\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.7298 Acc: 0.7531\n",
      "val Loss: 1.8285 Acc: 0.6620\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.6858 Acc: 0.7716\n",
      "val Loss: 1.0288 Acc: 0.6964\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.6835 Acc: 0.7690\n",
      "val Loss: 1.0075 Acc: 0.7193\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.6811 Acc: 0.7739\n",
      "val Loss: 1.6009 Acc: 0.6365\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.6747 Acc: 0.7706\n",
      "val Loss: 1.0325 Acc: 0.7060\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.6995 Acc: 0.7631\n",
      "val Loss: 3.1715 Acc: 0.6931\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.6571 Acc: 0.7799\n",
      "val Loss: 0.9257 Acc: 0.7391\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 0.7701\n",
      "val Loss: 2.1203 Acc: 0.6620\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.6745 Acc: 0.7742\n",
      "val Loss: 1.8231 Acc: 0.6714\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.6605 Acc: 0.7822\n",
      "val Loss: 0.9186 Acc: 0.7473\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.7824\n",
      "val Loss: 1.4547 Acc: 0.6811\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.6715 Acc: 0.7706\n",
      "val Loss: 1.2290 Acc: 0.7063\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.6597 Acc: 0.7815\n",
      "val Loss: 1.8790 Acc: 0.6661\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.6645 Acc: 0.7730\n",
      "val Loss: 1.3615 Acc: 0.6605\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 0.7894\n",
      "val Loss: 3.2169 Acc: 0.6180\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.6397 Acc: 0.7798\n",
      "val Loss: 1.0201 Acc: 0.7328\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.6354 Acc: 0.7845\n",
      "val Loss: 1.6013 Acc: 0.6602\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.6277 Acc: 0.7883\n",
      "val Loss: 3.4723 Acc: 0.6022\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.6475 Acc: 0.7806\n",
      "val Loss: 1.6385 Acc: 0.6595\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.6447 Acc: 0.7817\n",
      "val Loss: 1.2934 Acc: 0.6696\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.6230 Acc: 0.7911\n",
      "val Loss: 1.6104 Acc: 0.7020\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.6386 Acc: 0.7876\n",
      "val Loss: 1.4147 Acc: 0.7022\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.6226 Acc: 0.7912\n",
      "val Loss: 0.9175 Acc: 0.7440\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.6097 Acc: 0.7943\n",
      "val Loss: 1.2870 Acc: 0.7142\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.6201 Acc: 0.7932\n",
      "val Loss: 1.7354 Acc: 0.7025\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.6005 Acc: 0.7966\n",
      "val Loss: 3.6835 Acc: 0.6549\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.6288 Acc: 0.7899\n",
      "val Loss: 3.3075 Acc: 0.6740\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.6128 Acc: 0.7928\n",
      "val Loss: 1.8090 Acc: 0.6549\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.6163 Acc: 0.7932\n",
      "val Loss: 1.5558 Acc: 0.7007\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.5885 Acc: 0.8024\n",
      "val Loss: 1.4390 Acc: 0.6913\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.5884 Acc: 0.7998\n",
      "val Loss: 1.6031 Acc: 0.7081\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.5830 Acc: 0.8053\n",
      "val Loss: 1.3827 Acc: 0.7009\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.6115 Acc: 0.7956\n",
      "val Loss: 1.3615 Acc: 0.6976\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.6020 Acc: 0.7969\n",
      "val Loss: 2.1489 Acc: 0.6373\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.6099 Acc: 0.7943\n",
      "val Loss: 0.9851 Acc: 0.7358\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.5807 Acc: 0.8080\n",
      "val Loss: 1.1933 Acc: 0.7025\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.5850 Acc: 0.8013\n",
      "val Loss: 1.5924 Acc: 0.6849\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.5688 Acc: 0.8098\n",
      "val Loss: 1.0351 Acc: 0.7221\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.5675 Acc: 0.8057\n",
      "val Loss: 1.0521 Acc: 0.7279\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.5667 Acc: 0.8095\n",
      "val Loss: 1.2870 Acc: 0.7216\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.5744 Acc: 0.8089\n",
      "val Loss: 1.2057 Acc: 0.7213\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.5416 Acc: 0.8195\n",
      "val Loss: 1.5737 Acc: 0.7020\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.5647 Acc: 0.8083\n",
      "val Loss: 1.6425 Acc: 0.6981\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "train Loss: 0.5447 Acc: 0.8189\n",
      "val Loss: 1.4448 Acc: 0.7188\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.5869 Acc: 0.8019\n",
      "val Loss: 1.0500 Acc: 0.7343\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.5614 Acc: 0.8135\n",
      "val Loss: 1.3254 Acc: 0.7203\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.5572 Acc: 0.8146\n",
      "val Loss: 1.1189 Acc: 0.7254\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.5585 Acc: 0.8117\n",
      "val Loss: 1.3658 Acc: 0.7022\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.5612 Acc: 0.8176\n",
      "val Loss: 1.3683 Acc: 0.7338\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.5461 Acc: 0.8166\n",
      "val Loss: 0.9293 Acc: 0.7554\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.5438 Acc: 0.8189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-28 05:38:24,575]\u001b[0m Trial 2 finished with value: 0.7554085008908119 and parameters: {'optimizer': 'SGD', 'lr': 0.003926933727051871}. Best is trial 1 with value: 0.8302367014507508.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.7761 Acc: 0.6966\n",
      "\n",
      "Training complete in 238m 47s\n",
      "Best val Acc: 0.755409\n",
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 2.3069 Acc: 0.1122\n",
      "val Loss: 2.2993 Acc: 0.0985\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 2.2913 Acc: 0.1138\n",
      "val Loss: 2.2915 Acc: 0.1245\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 2.2882 Acc: 0.1220\n",
      "val Loss: 2.2988 Acc: 0.1201\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 2.2858 Acc: 0.1249\n",
      "val Loss: 2.3052 Acc: 0.1156\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 2.2855 Acc: 0.1227\n",
      "val Loss: 2.2905 Acc: 0.1267\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 2.2787 Acc: 0.1296\n",
      "val Loss: 2.2860 Acc: 0.1184\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 2.2816 Acc: 0.1270\n",
      "val Loss: 2.2836 Acc: 0.1339\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 2.2783 Acc: 0.1331\n",
      "val Loss: 2.2712 Acc: 0.1400\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 2.2785 Acc: 0.1341\n",
      "val Loss: 2.2920 Acc: 0.1184\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 2.2780 Acc: 0.1293\n",
      "val Loss: 2.2803 Acc: 0.1313\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 2.2730 Acc: 0.1384\n",
      "val Loss: 2.2764 Acc: 0.1267\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 2.2752 Acc: 0.1371\n",
      "val Loss: 2.2697 Acc: 0.1423\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 2.2673 Acc: 0.1438\n",
      "val Loss: 2.2676 Acc: 0.1308\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 2.2665 Acc: 0.1453\n",
      "val Loss: 2.2696 Acc: 0.1499\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 2.2602 Acc: 0.1485\n",
      "val Loss: 2.2610 Acc: 0.1278\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 2.2586 Acc: 0.1444\n",
      "val Loss: 2.2637 Acc: 0.1461\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 2.2551 Acc: 0.1487\n",
      "val Loss: 2.2705 Acc: 0.1575\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 2.2511 Acc: 0.1504\n",
      "val Loss: 2.2551 Acc: 0.1456\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 2.2483 Acc: 0.1594\n",
      "val Loss: 2.2405 Acc: 0.1591\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 2.2417 Acc: 0.1592\n",
      "val Loss: 2.2565 Acc: 0.1588\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 2.2388 Acc: 0.1581\n",
      "val Loss: 2.2453 Acc: 0.1644\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 2.2300 Acc: 0.1583\n",
      "val Loss: 2.2392 Acc: 0.1680\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 2.2294 Acc: 0.1597\n",
      "val Loss: 2.2226 Acc: 0.1713\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 2.2180 Acc: 0.1668\n",
      "val Loss: 2.2213 Acc: 0.1682\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 2.2181 Acc: 0.1587\n",
      "val Loss: 2.2135 Acc: 0.1817\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 2.2146 Acc: 0.1666\n",
      "val Loss: 2.2135 Acc: 0.1731\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 2.2068 Acc: 0.1692\n",
      "val Loss: 2.2233 Acc: 0.1700\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 2.2049 Acc: 0.1721\n",
      "val Loss: 2.2136 Acc: 0.1588\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 2.2020 Acc: 0.1780\n",
      "val Loss: 2.2048 Acc: 0.1642\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 2.1959 Acc: 0.1734\n",
      "val Loss: 2.1916 Acc: 0.1871\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 2.1953 Acc: 0.1758\n",
      "val Loss: 2.2287 Acc: 0.1644\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 2.1964 Acc: 0.1690\n",
      "val Loss: 2.2064 Acc: 0.1863\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 2.1902 Acc: 0.1762\n",
      "val Loss: 2.2060 Acc: 0.1736\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 2.1859 Acc: 0.1780\n",
      "val Loss: 2.1933 Acc: 0.1644\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 2.1899 Acc: 0.1726\n",
      "val Loss: 2.1917 Acc: 0.1820\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 2.1836 Acc: 0.1798\n",
      "val Loss: 2.1779 Acc: 0.1797\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 2.1801 Acc: 0.1803\n",
      "val Loss: 2.1831 Acc: 0.1886\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 2.1771 Acc: 0.1865\n",
      "val Loss: 2.1737 Acc: 0.1924\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 2.1741 Acc: 0.1856\n",
      "val Loss: 2.1647 Acc: 0.1883\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 2.1815 Acc: 0.1746\n",
      "val Loss: 2.1770 Acc: 0.1700\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 2.1733 Acc: 0.1815\n",
      "val Loss: 2.1877 Acc: 0.1746\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 2.1727 Acc: 0.1834\n",
      "val Loss: 2.1817 Acc: 0.2029\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 2.1777 Acc: 0.1786\n",
      "val Loss: 2.1609 Acc: 0.1973\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 2.1722 Acc: 0.1847\n",
      "val Loss: 2.1631 Acc: 0.1980\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 2.1671 Acc: 0.1880\n",
      "val Loss: 2.1619 Acc: 0.1917\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 2.1667 Acc: 0.1865\n",
      "val Loss: 2.1644 Acc: 0.1980\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 2.1654 Acc: 0.1891\n",
      "val Loss: 2.1589 Acc: 0.1939\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 2.1641 Acc: 0.1896\n",
      "val Loss: 2.1535 Acc: 0.1939\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 2.1615 Acc: 0.1889\n",
      "val Loss: 2.1605 Acc: 0.2003\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 2.1641 Acc: 0.1909\n",
      "val Loss: 2.1534 Acc: 0.1990\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 2.1567 Acc: 0.1900\n",
      "val Loss: 2.1462 Acc: 0.1927\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 2.1567 Acc: 0.1956\n",
      "val Loss: 2.1516 Acc: 0.1924\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 2.1564 Acc: 0.1952\n",
      "val Loss: 2.1374 Acc: 0.2044\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 2.1511 Acc: 0.1952\n",
      "val Loss: 2.1330 Acc: 0.2054\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 2.1455 Acc: 0.1989\n",
      "val Loss: 2.1408 Acc: 0.2054\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 2.1529 Acc: 0.1895\n",
      "val Loss: 2.1361 Acc: 0.2039\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 2.1478 Acc: 0.2007\n",
      "val Loss: 2.1330 Acc: 0.2021\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 2.1426 Acc: 0.1951\n",
      "val Loss: 2.1376 Acc: 0.2067\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 2.1488 Acc: 0.1916\n",
      "val Loss: 2.1446 Acc: 0.2057\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 2.1492 Acc: 0.1958\n",
      "val Loss: 2.1415 Acc: 0.2087\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 2.1379 Acc: 0.1996\n",
      "val Loss: 2.1314 Acc: 0.2148\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 2.1382 Acc: 0.1999\n",
      "val Loss: 2.1209 Acc: 0.2161\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 2.1459 Acc: 0.1941\n",
      "val Loss: 2.1177 Acc: 0.2199\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 2.1429 Acc: 0.2001\n",
      "val Loss: 2.1363 Acc: 0.2023\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 2.1408 Acc: 0.2017\n",
      "val Loss: 2.1271 Acc: 0.2062\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 2.1347 Acc: 0.2001\n",
      "val Loss: 2.1173 Acc: 0.2181\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 2.1374 Acc: 0.2079\n",
      "val Loss: 2.1092 Acc: 0.2168\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 2.1315 Acc: 0.2024\n",
      "val Loss: 2.1173 Acc: 0.2095\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 2.1340 Acc: 0.2066\n",
      "val Loss: 2.1129 Acc: 0.2158\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 2.1319 Acc: 0.2092\n",
      "val Loss: 2.1105 Acc: 0.2166\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 2.1269 Acc: 0.2075\n",
      "val Loss: 2.0996 Acc: 0.2207\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 2.1311 Acc: 0.2033\n",
      "val Loss: 2.0916 Acc: 0.2286\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 2.1282 Acc: 0.2085\n",
      "val Loss: 2.1074 Acc: 0.2158\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 2.1289 Acc: 0.2044\n",
      "val Loss: 2.1063 Acc: 0.2224\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 2.1252 Acc: 0.2091\n",
      "val Loss: 2.1051 Acc: 0.2194\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 2.1215 Acc: 0.2100\n",
      "val Loss: 2.1056 Acc: 0.2283\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 2.1189 Acc: 0.2117\n",
      "val Loss: 2.0915 Acc: 0.2283\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 2.1256 Acc: 0.2085\n",
      "val Loss: 2.1227 Acc: 0.2107\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 2.1303 Acc: 0.2093\n",
      "val Loss: 2.0921 Acc: 0.2296\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 2.1237 Acc: 0.2131\n",
      "val Loss: 2.0895 Acc: 0.2268\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 2.1226 Acc: 0.2115\n",
      "val Loss: 2.1003 Acc: 0.2130\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 2.1239 Acc: 0.2033\n",
      "val Loss: 2.0983 Acc: 0.2280\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 2.1161 Acc: 0.2148\n",
      "val Loss: 2.0827 Acc: 0.2298\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 2.1173 Acc: 0.2124\n",
      "val Loss: 2.0912 Acc: 0.2138\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 2.1216 Acc: 0.2136\n",
      "val Loss: 2.0833 Acc: 0.2326\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 2.1140 Acc: 0.2105\n",
      "val Loss: 2.0783 Acc: 0.2405\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 2.1141 Acc: 0.2095\n",
      "val Loss: 2.0793 Acc: 0.2217\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 2.1135 Acc: 0.2125\n",
      "val Loss: 2.0913 Acc: 0.2161\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 2.1098 Acc: 0.2184\n",
      "val Loss: 2.0785 Acc: 0.2385\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 2.1089 Acc: 0.2145\n",
      "val Loss: 2.0833 Acc: 0.2301\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 2.1123 Acc: 0.2168\n",
      "val Loss: 2.0965 Acc: 0.2296\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 2.1080 Acc: 0.2106\n",
      "val Loss: 2.0934 Acc: 0.2265\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 2.1122 Acc: 0.2124\n",
      "val Loss: 2.0810 Acc: 0.2227\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 2.1144 Acc: 0.2119\n",
      "val Loss: 2.0893 Acc: 0.2311\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 2.1173 Acc: 0.2178\n",
      "val Loss: 2.1024 Acc: 0.2191\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 2.1173 Acc: 0.2168\n",
      "val Loss: 2.0738 Acc: 0.2306\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 2.1147 Acc: 0.2129\n",
      "val Loss: 2.0838 Acc: 0.2250\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 2.1034 Acc: 0.2181\n",
      "val Loss: 2.0872 Acc: 0.2314\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 2.1047 Acc: 0.2194\n",
      "val Loss: 2.0690 Acc: 0.2321\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 2.1025 Acc: 0.2237\n",
      "val Loss: 2.0752 Acc: 0.2314\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 2.1058 Acc: 0.2224\n",
      "val Loss: 2.0837 Acc: 0.2275\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 2.0997 Acc: 0.2236\n",
      "val Loss: 2.0694 Acc: 0.2347\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 2.0983 Acc: 0.2257\n",
      "val Loss: 2.0739 Acc: 0.2153\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 2.1043 Acc: 0.2218\n",
      "val Loss: 2.0665 Acc: 0.2344\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 2.1011 Acc: 0.2219\n",
      "val Loss: 2.0681 Acc: 0.2163\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 2.0908 Acc: 0.2212\n",
      "val Loss: 2.0617 Acc: 0.2431\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 2.0879 Acc: 0.2224\n",
      "val Loss: 2.0553 Acc: 0.2400\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 2.0851 Acc: 0.2228\n",
      "val Loss: 2.0591 Acc: 0.2400\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 2.0873 Acc: 0.2246\n",
      "val Loss: 2.0506 Acc: 0.2494\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 2.0816 Acc: 0.2278\n",
      "val Loss: 2.0789 Acc: 0.2250\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 2.0864 Acc: 0.2322\n",
      "val Loss: 2.0544 Acc: 0.2413\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 2.0883 Acc: 0.2235\n",
      "val Loss: 2.0588 Acc: 0.2377\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 2.0762 Acc: 0.2343\n",
      "val Loss: 2.0431 Acc: 0.2471\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 2.0879 Acc: 0.2218\n",
      "val Loss: 2.0472 Acc: 0.2410\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 2.0788 Acc: 0.2290\n",
      "val Loss: 2.0389 Acc: 0.2436\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 2.0763 Acc: 0.2315\n",
      "val Loss: 2.0261 Acc: 0.2563\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 2.0740 Acc: 0.2319\n",
      "val Loss: 2.0366 Acc: 0.2540\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 2.0718 Acc: 0.2307\n",
      "val Loss: 2.0247 Acc: 0.2578\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 2.0794 Acc: 0.2376\n",
      "val Loss: 2.0317 Acc: 0.2476\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 2.0683 Acc: 0.2402\n",
      "val Loss: 2.0210 Acc: 0.2599\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 2.0661 Acc: 0.2392\n",
      "val Loss: 2.0362 Acc: 0.2408\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 2.0628 Acc: 0.2386\n",
      "val Loss: 2.0225 Acc: 0.2596\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 2.0717 Acc: 0.2352\n",
      "val Loss: 2.0229 Acc: 0.2639\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 2.0644 Acc: 0.2409\n",
      "val Loss: 2.0231 Acc: 0.2586\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 2.0649 Acc: 0.2411\n",
      "val Loss: 2.0305 Acc: 0.2655\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 2.0656 Acc: 0.2401\n",
      "val Loss: 2.0284 Acc: 0.2596\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 2.0627 Acc: 0.2424\n",
      "val Loss: 2.0300 Acc: 0.2718\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 2.0606 Acc: 0.2375\n",
      "val Loss: 2.0396 Acc: 0.2426\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 2.0656 Acc: 0.2390\n",
      "val Loss: 2.0335 Acc: 0.2520\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 2.0640 Acc: 0.2440\n",
      "val Loss: 2.0383 Acc: 0.2545\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 2.0596 Acc: 0.2401\n",
      "val Loss: 2.0292 Acc: 0.2629\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 2.0636 Acc: 0.2336\n",
      "val Loss: 2.0352 Acc: 0.2601\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 2.0566 Acc: 0.2448\n",
      "val Loss: 2.0443 Acc: 0.2622\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 2.0568 Acc: 0.2406\n",
      "val Loss: 2.0322 Acc: 0.2538\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 2.0641 Acc: 0.2459\n",
      "val Loss: 2.0167 Acc: 0.2606\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 2.0577 Acc: 0.2412\n",
      "val Loss: 2.0060 Acc: 0.2629\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 2.0557 Acc: 0.2399\n",
      "val Loss: 2.0165 Acc: 0.2573\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 2.0541 Acc: 0.2425\n",
      "val Loss: 2.0204 Acc: 0.2497\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 2.0479 Acc: 0.2494\n",
      "val Loss: 2.0163 Acc: 0.2614\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 2.0594 Acc: 0.2418\n",
      "val Loss: 2.0201 Acc: 0.2555\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 2.0472 Acc: 0.2414\n",
      "val Loss: 2.0077 Acc: 0.2685\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 2.0515 Acc: 0.2432\n",
      "val Loss: 1.9994 Acc: 0.2606\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 2.0569 Acc: 0.2434\n",
      "val Loss: 2.0081 Acc: 0.2616\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 2.0418 Acc: 0.2463\n",
      "val Loss: 2.0036 Acc: 0.2652\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 2.0392 Acc: 0.2454\n",
      "val Loss: 1.9970 Acc: 0.2627\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 2.0425 Acc: 0.2500\n",
      "val Loss: 1.9920 Acc: 0.2711\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 2.0379 Acc: 0.2504\n",
      "val Loss: 1.9956 Acc: 0.2759\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 2.0370 Acc: 0.2495\n",
      "val Loss: 1.9887 Acc: 0.2703\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 2.0342 Acc: 0.2500\n",
      "val Loss: 1.9998 Acc: 0.2751\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 2.0352 Acc: 0.2591\n",
      "val Loss: 1.9973 Acc: 0.2784\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 2.0306 Acc: 0.2481\n",
      "val Loss: 1.9899 Acc: 0.2810\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 2.0298 Acc: 0.2551\n",
      "val Loss: 1.9797 Acc: 0.2756\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 2.0231 Acc: 0.2561\n",
      "val Loss: 1.9933 Acc: 0.2708\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 2.0341 Acc: 0.2510\n",
      "val Loss: 1.9898 Acc: 0.2683\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 2.0234 Acc: 0.2566\n",
      "val Loss: 1.9854 Acc: 0.2772\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 2.0274 Acc: 0.2494\n",
      "val Loss: 1.9759 Acc: 0.2828\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 2.0259 Acc: 0.2516\n",
      "val Loss: 1.9908 Acc: 0.2818\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 2.0289 Acc: 0.2539\n",
      "val Loss: 1.9861 Acc: 0.2853\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 2.0253 Acc: 0.2534\n",
      "val Loss: 1.9870 Acc: 0.2749\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 2.0205 Acc: 0.2525\n",
      "val Loss: 1.9822 Acc: 0.2698\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 2.0263 Acc: 0.2566\n",
      "val Loss: 1.9586 Acc: 0.2802\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 2.0222 Acc: 0.2585\n",
      "val Loss: 1.9627 Acc: 0.2830\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 2.0159 Acc: 0.2629\n",
      "val Loss: 1.9692 Acc: 0.2879\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 2.0186 Acc: 0.2593\n",
      "val Loss: 1.9526 Acc: 0.2914\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 2.0131 Acc: 0.2632\n",
      "val Loss: 1.9645 Acc: 0.2907\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 2.0118 Acc: 0.2607\n",
      "val Loss: 1.9557 Acc: 0.2815\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 2.0145 Acc: 0.2642\n",
      "val Loss: 1.9668 Acc: 0.2774\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 2.0113 Acc: 0.2556\n",
      "val Loss: 1.9645 Acc: 0.2731\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 2.0071 Acc: 0.2572\n",
      "val Loss: 1.9910 Acc: 0.2594\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 2.0104 Acc: 0.2614\n",
      "val Loss: 1.9592 Acc: 0.2830\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 2.0026 Acc: 0.2657\n",
      "val Loss: 1.9445 Acc: 0.2858\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 2.0113 Acc: 0.2636\n",
      "val Loss: 1.9752 Acc: 0.2688\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 2.0093 Acc: 0.2612\n",
      "val Loss: 1.9627 Acc: 0.2871\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 2.0013 Acc: 0.2646\n",
      "val Loss: 1.9584 Acc: 0.2805\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 2.0088 Acc: 0.2597\n",
      "val Loss: 1.9590 Acc: 0.2744\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 2.0101 Acc: 0.2633\n",
      "val Loss: 1.9735 Acc: 0.2772\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 1.9978 Acc: 0.2687\n",
      "val Loss: 1.9469 Acc: 0.2774\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 1.9979 Acc: 0.2603\n",
      "val Loss: 1.9374 Acc: 0.2881\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 1.9967 Acc: 0.2712\n",
      "val Loss: 1.9416 Acc: 0.2828\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 2.0037 Acc: 0.2668\n",
      "val Loss: 1.9422 Acc: 0.2863\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 2.0109 Acc: 0.2607\n",
      "val Loss: 1.9545 Acc: 0.2812\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 1.9975 Acc: 0.2699\n",
      "val Loss: 1.9743 Acc: 0.2812\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 1.9917 Acc: 0.2688\n",
      "val Loss: 1.9524 Acc: 0.2812\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 1.9863 Acc: 0.2725\n",
      "val Loss: 1.9233 Acc: 0.2998\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 1.9860 Acc: 0.2751\n",
      "val Loss: 1.9372 Acc: 0.2907\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 1.9934 Acc: 0.2683\n",
      "val Loss: 1.9295 Acc: 0.2805\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 1.9883 Acc: 0.2693\n",
      "val Loss: 1.9228 Acc: 0.2843\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 1.9868 Acc: 0.2674\n",
      "val Loss: 1.9237 Acc: 0.2940\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 1.9845 Acc: 0.2748\n",
      "val Loss: 1.9157 Acc: 0.3021\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 1.9782 Acc: 0.2794\n",
      "val Loss: 1.9200 Acc: 0.3003\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 1.9865 Acc: 0.2751\n",
      "val Loss: 1.9338 Acc: 0.2950\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 2.0036 Acc: 0.2725\n",
      "val Loss: 1.9322 Acc: 0.2957\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "train Loss: 1.9913 Acc: 0.2718\n",
      "val Loss: 1.9234 Acc: 0.3026\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 1.9784 Acc: 0.2659\n",
      "val Loss: 1.9195 Acc: 0.3008\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 1.9859 Acc: 0.2773\n",
      "val Loss: 1.9240 Acc: 0.3036\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 1.9776 Acc: 0.2801\n",
      "val Loss: 1.9132 Acc: 0.2957\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 1.9831 Acc: 0.2748\n",
      "val Loss: 1.9178 Acc: 0.3031\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 1.9795 Acc: 0.2787\n",
      "val Loss: 1.9044 Acc: 0.3095\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 1.9661 Acc: 0.2883\n",
      "val Loss: 1.9154 Acc: 0.3011\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 1.9732 Acc: 0.2827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-28 09:12:23,316]\u001b[0m Trial 3 finished with value: 0.30949350979893103 and parameters: {'optimizer': 'SGD', 'lr': 0.00011942103885257488}. Best is trial 1 with value: 0.8302367014507508.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.9167 Acc: 0.3034\n",
      "\n",
      "Training complete in 213m 58s\n",
      "Best val Acc: 0.309494\n",
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 2.2132 Acc: 0.1771\n",
      "val Loss: 2.1811 Acc: 0.1670\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 2.1336 Acc: 0.2144\n",
      "val Loss: 2.1599 Acc: 0.1855\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 2.1020 Acc: 0.2232\n",
      "val Loss: 2.1074 Acc: 0.2288\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 2.0790 Acc: 0.2417\n",
      "val Loss: 2.0637 Acc: 0.2550\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 2.0440 Acc: 0.2547\n",
      "val Loss: 2.1191 Acc: 0.2331\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 2.0177 Acc: 0.2702\n",
      "val Loss: 1.9657 Acc: 0.2973\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 1.9933 Acc: 0.2792\n",
      "val Loss: 1.9419 Acc: 0.3013\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 1.9622 Acc: 0.2998\n",
      "val Loss: 1.8972 Acc: 0.3204\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 1.9438 Acc: 0.3090\n",
      "val Loss: 1.9640 Acc: 0.3085\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 1.9335 Acc: 0.3084\n",
      "val Loss: 1.8909 Acc: 0.3243\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 1.9111 Acc: 0.3221\n",
      "val Loss: 1.8257 Acc: 0.3418\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 1.8741 Acc: 0.3346\n",
      "val Loss: 1.7950 Acc: 0.3645\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 1.8546 Acc: 0.3378\n",
      "val Loss: 1.8526 Acc: 0.3316\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 1.8273 Acc: 0.3527\n",
      "val Loss: 1.7046 Acc: 0.4014\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 1.8127 Acc: 0.3590\n",
      "val Loss: 1.7241 Acc: 0.3958\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 1.7780 Acc: 0.3760\n",
      "val Loss: 1.7043 Acc: 0.4103\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 1.7563 Acc: 0.3804\n",
      "val Loss: 1.5829 Acc: 0.4558\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 1.7224 Acc: 0.4028\n",
      "val Loss: 1.6273 Acc: 0.4342\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 1.6826 Acc: 0.4127\n",
      "val Loss: 1.6515 Acc: 0.4228\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 1.6624 Acc: 0.4198\n",
      "val Loss: 1.6542 Acc: 0.4317\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 1.6518 Acc: 0.4263\n",
      "val Loss: 1.4986 Acc: 0.4912\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 1.6234 Acc: 0.4407\n",
      "val Loss: 1.5428 Acc: 0.4653\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 1.6006 Acc: 0.4481\n",
      "val Loss: 1.4578 Acc: 0.5022\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 1.5594 Acc: 0.4575\n",
      "val Loss: 1.5357 Acc: 0.4749\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 1.5456 Acc: 0.4595\n",
      "val Loss: 1.4146 Acc: 0.5230\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 1.5397 Acc: 0.4593\n",
      "val Loss: 1.4572 Acc: 0.5009\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 1.5102 Acc: 0.4840\n",
      "val Loss: 1.4512 Acc: 0.5070\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 1.4662 Acc: 0.4907\n",
      "val Loss: 1.4455 Acc: 0.5037\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 1.4571 Acc: 0.4995\n",
      "val Loss: 1.3576 Acc: 0.5409\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 1.4372 Acc: 0.4989\n",
      "val Loss: 1.3483 Acc: 0.5416\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 1.4044 Acc: 0.5112\n",
      "val Loss: 1.2998 Acc: 0.5594\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 1.3812 Acc: 0.5248\n",
      "val Loss: 1.2994 Acc: 0.5627\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 1.3588 Acc: 0.5330\n",
      "val Loss: 1.2333 Acc: 0.5846\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 1.3544 Acc: 0.5363\n",
      "val Loss: 1.2657 Acc: 0.5694\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 1.3421 Acc: 0.5387\n",
      "val Loss: 1.2604 Acc: 0.5813\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 1.3076 Acc: 0.5466\n",
      "val Loss: 1.1920 Acc: 0.5938\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 1.2844 Acc: 0.5598\n",
      "val Loss: 1.2079 Acc: 0.5772\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 1.2752 Acc: 0.5621\n",
      "val Loss: 1.2198 Acc: 0.5912\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 1.2711 Acc: 0.5679\n",
      "val Loss: 1.2271 Acc: 0.5806\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 1.2488 Acc: 0.5755\n",
      "val Loss: 1.1793 Acc: 0.5991\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 1.2292 Acc: 0.5793\n",
      "val Loss: 1.1647 Acc: 0.6157\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 1.2186 Acc: 0.5801\n",
      "val Loss: 1.1707 Acc: 0.6060\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 1.1985 Acc: 0.5900\n",
      "val Loss: 1.0794 Acc: 0.6373\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 1.1823 Acc: 0.5980\n",
      "val Loss: 1.1165 Acc: 0.6218\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 1.1732 Acc: 0.5986\n",
      "val Loss: 1.2806 Acc: 0.5803\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 1.1510 Acc: 0.6122\n",
      "val Loss: 1.0648 Acc: 0.6424\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 1.1343 Acc: 0.6112\n",
      "val Loss: 1.1070 Acc: 0.6393\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 1.1378 Acc: 0.6094\n",
      "val Loss: 1.1176 Acc: 0.6246\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 1.1226 Acc: 0.6171\n",
      "val Loss: 1.0253 Acc: 0.6541\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 1.0991 Acc: 0.6273\n",
      "val Loss: 1.0590 Acc: 0.6490\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 1.1007 Acc: 0.6245\n",
      "val Loss: 1.0594 Acc: 0.6421\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 1.0650 Acc: 0.6325\n",
      "val Loss: 1.0764 Acc: 0.6531\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 1.0416 Acc: 0.6512\n",
      "val Loss: 0.9920 Acc: 0.6714\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 1.0405 Acc: 0.6478\n",
      "val Loss: 1.1460 Acc: 0.6248\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 1.0269 Acc: 0.6507\n",
      "val Loss: 1.1092 Acc: 0.6462\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 1.0141 Acc: 0.6539\n",
      "val Loss: 0.9746 Acc: 0.6819\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 0.9997 Acc: 0.6617\n",
      "val Loss: 1.0123 Acc: 0.6676\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 0.9869 Acc: 0.6639\n",
      "val Loss: 0.9977 Acc: 0.6722\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 0.9606 Acc: 0.6797\n",
      "val Loss: 0.9850 Acc: 0.6735\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 0.9683 Acc: 0.6687\n",
      "val Loss: 0.9820 Acc: 0.6747\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 0.9639 Acc: 0.6765\n",
      "val Loss: 0.9610 Acc: 0.6854\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 0.9554 Acc: 0.6816\n",
      "val Loss: 0.9383 Acc: 0.6854\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 0.9371 Acc: 0.6796\n",
      "val Loss: 0.9396 Acc: 0.6841\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 0.9348 Acc: 0.6803\n",
      "val Loss: 0.9038 Acc: 0.6971\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 0.9108 Acc: 0.6946\n",
      "val Loss: 0.9853 Acc: 0.6775\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 0.9286 Acc: 0.6852\n",
      "val Loss: 0.9588 Acc: 0.6903\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 0.8778 Acc: 0.7038\n",
      "val Loss: 0.9134 Acc: 0.6981\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 0.8829 Acc: 0.7050\n",
      "val Loss: 1.0211 Acc: 0.6760\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 0.8710 Acc: 0.7029\n",
      "val Loss: 0.9377 Acc: 0.6987\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 0.8590 Acc: 0.7117\n",
      "val Loss: 0.9571 Acc: 0.6880\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 0.8493 Acc: 0.7120\n",
      "val Loss: 0.9830 Acc: 0.6931\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 0.8511 Acc: 0.7050\n",
      "val Loss: 1.0641 Acc: 0.6694\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 0.8314 Acc: 0.7152\n",
      "val Loss: 0.8740 Acc: 0.7195\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 0.8246 Acc: 0.7196\n",
      "val Loss: 0.9539 Acc: 0.6974\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 0.8080 Acc: 0.7255\n",
      "val Loss: 1.0400 Acc: 0.6617\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 0.8093 Acc: 0.7317\n",
      "val Loss: 0.9118 Acc: 0.7078\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 0.7991 Acc: 0.7344\n",
      "val Loss: 0.9164 Acc: 0.7144\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 0.7934 Acc: 0.7337\n",
      "val Loss: 0.9515 Acc: 0.6981\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 0.8002 Acc: 0.7261\n",
      "val Loss: 0.9020 Acc: 0.7043\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 0.7630 Acc: 0.7429\n",
      "val Loss: 0.9066 Acc: 0.7213\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 0.7691 Acc: 0.7439\n",
      "val Loss: 0.9791 Acc: 0.7009\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 0.7529 Acc: 0.7511\n",
      "val Loss: 0.9190 Acc: 0.7104\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 0.7532 Acc: 0.7484\n",
      "val Loss: 0.8805 Acc: 0.7249\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 0.7465 Acc: 0.7477\n",
      "val Loss: 0.9003 Acc: 0.7058\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 0.7387 Acc: 0.7530\n",
      "val Loss: 0.9548 Acc: 0.7093\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 0.7328 Acc: 0.7506\n",
      "val Loss: 0.9042 Acc: 0.7195\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 0.7328 Acc: 0.7565\n",
      "val Loss: 0.8427 Acc: 0.7317\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 0.7255 Acc: 0.7572\n",
      "val Loss: 0.9229 Acc: 0.7154\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 0.7253 Acc: 0.7592\n",
      "val Loss: 0.8662 Acc: 0.7264\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 0.7040 Acc: 0.7621\n",
      "val Loss: 0.9092 Acc: 0.7126\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 0.6995 Acc: 0.7616\n",
      "val Loss: 0.9174 Acc: 0.7175\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 0.7712\n",
      "val Loss: 0.9179 Acc: 0.7104\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 0.7021 Acc: 0.7663\n",
      "val Loss: 0.8650 Acc: 0.7363\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.6623 Acc: 0.7763\n",
      "val Loss: 0.8765 Acc: 0.7238\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.6569 Acc: 0.7756\n",
      "val Loss: 0.8657 Acc: 0.7221\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.6730 Acc: 0.7665\n",
      "val Loss: 0.8552 Acc: 0.7246\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.6631 Acc: 0.7775\n",
      "val Loss: 0.8481 Acc: 0.7391\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.6787 Acc: 0.7714\n",
      "val Loss: 0.8573 Acc: 0.7361\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.6499 Acc: 0.7857\n",
      "val Loss: 0.8877 Acc: 0.7297\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.6437 Acc: 0.7847\n",
      "val Loss: 0.8485 Acc: 0.7450\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.6207 Acc: 0.7908\n",
      "val Loss: 0.8716 Acc: 0.7269\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.6165 Acc: 0.7939\n",
      "val Loss: 0.8839 Acc: 0.7437\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.7847\n",
      "val Loss: 0.8042 Acc: 0.7529\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.6185 Acc: 0.7934\n",
      "val Loss: 0.8903 Acc: 0.7338\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.6141 Acc: 0.7936\n",
      "val Loss: 0.8201 Acc: 0.7457\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.6188 Acc: 0.7990\n",
      "val Loss: 0.8370 Acc: 0.7396\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.6062 Acc: 0.7999\n",
      "val Loss: 0.9371 Acc: 0.7226\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.5921 Acc: 0.8002\n",
      "val Loss: 0.9007 Acc: 0.7368\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.6059 Acc: 0.8020\n",
      "val Loss: 0.9072 Acc: 0.7396\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.5948 Acc: 0.8060\n",
      "val Loss: 0.9170 Acc: 0.7322\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.5831 Acc: 0.8062\n",
      "val Loss: 0.8788 Acc: 0.7508\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.5705 Acc: 0.8093\n",
      "val Loss: 0.9364 Acc: 0.7152\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.5748 Acc: 0.8093\n",
      "val Loss: 0.9103 Acc: 0.7353\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.5778 Acc: 0.8109\n",
      "val Loss: 0.8992 Acc: 0.7254\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.5831 Acc: 0.8057\n",
      "val Loss: 0.8660 Acc: 0.7406\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.5702 Acc: 0.8082\n",
      "val Loss: 0.8934 Acc: 0.7427\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.5382 Acc: 0.8244\n",
      "val Loss: 0.8936 Acc: 0.7414\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.5636 Acc: 0.8143\n",
      "val Loss: 0.9206 Acc: 0.7322\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.5560 Acc: 0.8142\n",
      "val Loss: 0.8693 Acc: 0.7480\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.5357 Acc: 0.8215\n",
      "val Loss: 0.9159 Acc: 0.7396\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.5517 Acc: 0.8198\n",
      "val Loss: 0.8473 Acc: 0.7539\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.5306 Acc: 0.8249\n",
      "val Loss: 0.8440 Acc: 0.7577\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.5512 Acc: 0.8184\n",
      "val Loss: 0.8649 Acc: 0.7488\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.5497 Acc: 0.8165\n",
      "val Loss: 0.8627 Acc: 0.7475\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.5173 Acc: 0.8269\n",
      "val Loss: 0.8791 Acc: 0.7348\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.5223 Acc: 0.8239\n",
      "val Loss: 0.8767 Acc: 0.7503\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.5261 Acc: 0.8277\n",
      "val Loss: 0.8733 Acc: 0.7580\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.5194 Acc: 0.8254\n",
      "val Loss: 0.9029 Acc: 0.7381\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.5276 Acc: 0.8217\n",
      "val Loss: 0.9220 Acc: 0.7315\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.5188 Acc: 0.8312\n",
      "val Loss: 0.8607 Acc: 0.7585\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.5211 Acc: 0.8295\n",
      "val Loss: 0.8191 Acc: 0.7508\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.5029 Acc: 0.8320\n",
      "val Loss: 0.8041 Acc: 0.7529\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.4945 Acc: 0.8340\n",
      "val Loss: 0.8585 Acc: 0.7524\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.5035 Acc: 0.8351\n",
      "val Loss: 0.8747 Acc: 0.7488\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.5032 Acc: 0.8321\n",
      "val Loss: 0.9552 Acc: 0.7317\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.4820 Acc: 0.8402\n",
      "val Loss: 0.8754 Acc: 0.7529\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.4931 Acc: 0.8386\n",
      "val Loss: 0.9218 Acc: 0.7333\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.4885 Acc: 0.8356\n",
      "val Loss: 0.8499 Acc: 0.7541\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.4681 Acc: 0.8433\n",
      "val Loss: 0.8683 Acc: 0.7615\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.4970 Acc: 0.8348\n",
      "val Loss: 0.9961 Acc: 0.7307\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.4879 Acc: 0.8348\n",
      "val Loss: 0.9717 Acc: 0.7305\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.4732 Acc: 0.8430\n",
      "val Loss: 1.0068 Acc: 0.7297\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.4642 Acc: 0.8478\n",
      "val Loss: 0.9302 Acc: 0.7401\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.4692 Acc: 0.8458\n",
      "val Loss: 0.9013 Acc: 0.7434\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.4562 Acc: 0.8465\n",
      "val Loss: 1.0526 Acc: 0.7244\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.4648 Acc: 0.8449\n",
      "val Loss: 0.8451 Acc: 0.7539\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.4643 Acc: 0.8442\n",
      "val Loss: 0.8526 Acc: 0.7564\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.4522 Acc: 0.8494\n",
      "val Loss: 0.8642 Acc: 0.7546\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.4680 Acc: 0.8444\n",
      "val Loss: 0.9247 Acc: 0.7378\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.4603 Acc: 0.8511\n",
      "val Loss: 0.9141 Acc: 0.7503\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.4561 Acc: 0.8494\n",
      "val Loss: 0.9423 Acc: 0.7445\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.4562 Acc: 0.8470\n",
      "val Loss: 0.9408 Acc: 0.7462\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.4472 Acc: 0.8546\n",
      "val Loss: 0.8421 Acc: 0.7689\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.4336 Acc: 0.8533\n",
      "val Loss: 0.9089 Acc: 0.7549\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.4358 Acc: 0.8583\n",
      "val Loss: 0.8957 Acc: 0.7567\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.4290 Acc: 0.8591\n",
      "val Loss: 0.8699 Acc: 0.7567\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.4301 Acc: 0.8567\n",
      "val Loss: 0.9305 Acc: 0.7636\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.4314 Acc: 0.8597\n",
      "val Loss: 0.9513 Acc: 0.7450\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.4390 Acc: 0.8531\n",
      "val Loss: 0.8382 Acc: 0.7656\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.4333 Acc: 0.8576\n",
      "val Loss: 0.8306 Acc: 0.7518\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.4253 Acc: 0.8587\n",
      "val Loss: 0.9370 Acc: 0.7470\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.4211 Acc: 0.8609\n",
      "val Loss: 0.9438 Acc: 0.7384\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.4330 Acc: 0.8574\n",
      "val Loss: 0.9058 Acc: 0.7429\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.4014 Acc: 0.8710\n",
      "val Loss: 0.9059 Acc: 0.7605\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.4168 Acc: 0.8650\n",
      "val Loss: 0.8162 Acc: 0.7671\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.4214 Acc: 0.8571\n",
      "val Loss: 0.8753 Acc: 0.7521\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.4181 Acc: 0.8613\n",
      "val Loss: 0.8636 Acc: 0.7546\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.4158 Acc: 0.8635\n",
      "val Loss: 0.8898 Acc: 0.7643\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.3996 Acc: 0.8694\n",
      "val Loss: 0.9279 Acc: 0.7541\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.3947 Acc: 0.8716\n",
      "val Loss: 0.8914 Acc: 0.7488\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.4182 Acc: 0.8570\n",
      "val Loss: 0.8660 Acc: 0.7600\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.4080 Acc: 0.8678\n",
      "val Loss: 0.9108 Acc: 0.7620\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.3991 Acc: 0.8670\n",
      "val Loss: 1.0102 Acc: 0.7246\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.3933 Acc: 0.8709\n",
      "val Loss: 0.9187 Acc: 0.7526\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.4043 Acc: 0.8674\n",
      "val Loss: 0.8413 Acc: 0.7666\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.3962 Acc: 0.8739\n",
      "val Loss: 0.8741 Acc: 0.7684\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.3972 Acc: 0.8694\n",
      "val Loss: 0.8732 Acc: 0.7557\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.3977 Acc: 0.8737\n",
      "val Loss: 0.8152 Acc: 0.7725\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.3889 Acc: 0.8720\n",
      "val Loss: 1.1487 Acc: 0.7065\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.3895 Acc: 0.8687\n",
      "val Loss: 0.9608 Acc: 0.7541\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.3944 Acc: 0.8742\n",
      "val Loss: 0.9243 Acc: 0.7541\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.3696 Acc: 0.8762\n",
      "val Loss: 0.9618 Acc: 0.7539\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.3848 Acc: 0.8701\n",
      "val Loss: 0.8922 Acc: 0.7633\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.3953 Acc: 0.8706\n",
      "val Loss: 0.9500 Acc: 0.7590\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.3856 Acc: 0.8767\n",
      "val Loss: 0.8617 Acc: 0.7600\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.3805 Acc: 0.8765\n",
      "val Loss: 0.8582 Acc: 0.7585\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.3927 Acc: 0.8720\n",
      "val Loss: 0.8531 Acc: 0.7804\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.3739 Acc: 0.8731\n",
      "val Loss: 0.9251 Acc: 0.7623\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.3660 Acc: 0.8799\n",
      "val Loss: 0.9725 Acc: 0.7587\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.3818 Acc: 0.8755\n",
      "val Loss: 0.8566 Acc: 0.7709\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.3622 Acc: 0.8813\n",
      "val Loss: 0.9441 Acc: 0.7605\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.3652 Acc: 0.8831\n",
      "val Loss: 0.9505 Acc: 0.7613\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "train Loss: 0.3657 Acc: 0.8806\n",
      "val Loss: 0.9425 Acc: 0.7641\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.3639 Acc: 0.8780\n",
      "val Loss: 0.9478 Acc: 0.7552\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.3675 Acc: 0.8787\n",
      "val Loss: 0.9362 Acc: 0.7658\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.3683 Acc: 0.8791\n",
      "val Loss: 0.9652 Acc: 0.7516\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.3601 Acc: 0.8814\n",
      "val Loss: 0.8968 Acc: 0.7679\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.3498 Acc: 0.8859\n",
      "val Loss: 0.8994 Acc: 0.7704\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.3406 Acc: 0.8884\n",
      "val Loss: 0.9106 Acc: 0.7574\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.3551 Acc: 0.8861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-28 12:36:53,036]\u001b[0m Trial 4 finished with value: 0.7803512344107916 and parameters: {'optimizer': 'RMSprop', 'lr': 2.550790889736528e-05}. Best is trial 1 with value: 0.8302367014507508.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.8932 Acc: 0.7707\n",
      "\n",
      "Training complete in 204m 29s\n",
      "Best val Acc: 0.780351\n",
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value:  0.8302367014507508\n",
      "  Params: \n",
      "    optimizer: Adam\n",
      "    lr: 0.0033728675244193286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/optuna/structs.py:18: FutureWarning: `structs` is deprecated. Classes have moved to the following modules. `structs.StudyDirection`->`study.StudyDirection`, `structs.StudySummary`->`study.StudySummary`, `structs.FrozenTrial`->`trial.FrozenTrial`, `structs.TrialState`->`trial.TrialState`, `structs.TrialPruned`->`exceptions.TrialPruned`.\n",
      "  warnings.warn(_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a343b71-804f-460c-ad5f-ec6ea243c3e2",
   "metadata": {},
   "source": [
    "## Train ResNet50 with parameters: optimizer-Adam, lr-0.003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd3df9-9ed8-498f-b20f-0b0e19ccaf2b",
   "metadata": {},
   "source": [
    "### Default train function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da426cd9-42aa-4e88-80a2-9b1c5af5622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ae8fc23-d9df-474c-b77f-f76102f6a77d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/299\n",
      "----------\n",
      "train Loss: 2.3652 Acc: 0.1514\n",
      "val Loss: 2.2741 Acc: 0.1481\n",
      "Epoch 1/299\n",
      "----------\n",
      "train Loss: 2.1923 Acc: 0.1784\n",
      "val Loss: 2.1881 Acc: 0.2034\n",
      "Epoch 2/299\n",
      "----------\n",
      "train Loss: 2.1511 Acc: 0.1965\n",
      "val Loss: 2.1019 Acc: 0.2204\n",
      "Epoch 3/299\n",
      "----------\n",
      "train Loss: 2.1859 Acc: 0.1797\n",
      "val Loss: 2.1214 Acc: 0.1950\n",
      "Epoch 4/299\n",
      "----------\n",
      "train Loss: 2.1336 Acc: 0.2081\n",
      "val Loss: 2.0650 Acc: 0.2347\n",
      "Epoch 5/299\n",
      "----------\n",
      "train Loss: 2.0821 Acc: 0.2245\n",
      "val Loss: 2.0566 Acc: 0.2311\n",
      "Epoch 6/299\n",
      "----------\n",
      "train Loss: 2.0578 Acc: 0.2327\n",
      "val Loss: 1.9403 Acc: 0.2830\n",
      "Epoch 7/299\n",
      "----------\n",
      "train Loss: 2.0173 Acc: 0.2578\n",
      "val Loss: 2.0294 Acc: 0.2614\n",
      "Epoch 8/299\n",
      "----------\n",
      "train Loss: 1.9962 Acc: 0.2654\n",
      "val Loss: 1.9318 Acc: 0.2952\n",
      "Epoch 9/299\n",
      "----------\n",
      "train Loss: 1.9494 Acc: 0.2849\n",
      "val Loss: 2.0381 Acc: 0.2606\n",
      "Epoch 10/299\n",
      "----------\n",
      "train Loss: 1.9010 Acc: 0.3014\n",
      "val Loss: 1.8561 Acc: 0.3047\n",
      "Epoch 11/299\n",
      "----------\n",
      "train Loss: 1.8827 Acc: 0.3217\n",
      "val Loss: 1.8131 Acc: 0.3464\n",
      "Epoch 12/299\n",
      "----------\n",
      "train Loss: 1.8237 Acc: 0.3483\n",
      "val Loss: 1.9541 Acc: 0.3263\n",
      "Epoch 13/299\n",
      "----------\n",
      "train Loss: 1.7868 Acc: 0.3601\n",
      "val Loss: 1.7419 Acc: 0.3907\n",
      "Epoch 14/299\n",
      "----------\n",
      "train Loss: 1.7522 Acc: 0.3647\n",
      "val Loss: 1.6561 Acc: 0.4095\n",
      "Epoch 15/299\n",
      "----------\n",
      "train Loss: 1.7185 Acc: 0.3853\n",
      "val Loss: 1.5823 Acc: 0.4299\n",
      "Epoch 16/299\n",
      "----------\n",
      "train Loss: 1.6795 Acc: 0.4065\n",
      "val Loss: 1.5479 Acc: 0.4472\n",
      "Epoch 17/299\n",
      "----------\n",
      "train Loss: 1.6571 Acc: 0.4182\n",
      "val Loss: 1.5394 Acc: 0.4614\n",
      "Epoch 18/299\n",
      "----------\n",
      "train Loss: 1.6184 Acc: 0.4306\n",
      "val Loss: 1.4647 Acc: 0.4800\n",
      "Epoch 19/299\n",
      "----------\n",
      "train Loss: 1.5862 Acc: 0.4409\n",
      "val Loss: 1.5211 Acc: 0.4693\n",
      "Epoch 20/299\n",
      "----------\n",
      "train Loss: 1.5598 Acc: 0.4453\n",
      "val Loss: 1.3950 Acc: 0.5032\n",
      "Epoch 21/299\n",
      "----------\n",
      "train Loss: 1.5252 Acc: 0.4628\n",
      "val Loss: 1.4022 Acc: 0.5162\n",
      "Epoch 22/299\n",
      "----------\n",
      "train Loss: 1.5051 Acc: 0.4711\n",
      "val Loss: 1.3122 Acc: 0.5482\n",
      "Epoch 23/299\n",
      "----------\n",
      "train Loss: 1.4740 Acc: 0.4837\n",
      "val Loss: 1.3572 Acc: 0.5309\n",
      "Epoch 24/299\n",
      "----------\n",
      "train Loss: 1.4470 Acc: 0.4953\n",
      "val Loss: 1.3649 Acc: 0.5386\n",
      "Epoch 25/299\n",
      "----------\n",
      "train Loss: 1.3996 Acc: 0.5102\n",
      "val Loss: 1.5233 Acc: 0.4902\n",
      "Epoch 26/299\n",
      "----------\n",
      "train Loss: 1.3751 Acc: 0.5258\n",
      "val Loss: 1.2098 Acc: 0.5862\n",
      "Epoch 27/299\n",
      "----------\n",
      "train Loss: 1.3599 Acc: 0.5362\n",
      "val Loss: 1.2061 Acc: 0.5877\n",
      "Epoch 28/299\n",
      "----------\n",
      "train Loss: 1.3098 Acc: 0.5506\n",
      "val Loss: 1.4389 Acc: 0.5230\n",
      "Epoch 29/299\n",
      "----------\n",
      "train Loss: 1.3014 Acc: 0.5562\n",
      "val Loss: 1.3268 Acc: 0.5783\n",
      "Epoch 30/299\n",
      "----------\n",
      "train Loss: 1.2635 Acc: 0.5721\n",
      "val Loss: 1.1478 Acc: 0.6200\n",
      "Epoch 31/299\n",
      "----------\n",
      "train Loss: 1.2644 Acc: 0.5618\n",
      "val Loss: 1.1020 Acc: 0.6312\n",
      "Epoch 32/299\n",
      "----------\n",
      "train Loss: 1.2197 Acc: 0.5825\n",
      "val Loss: 0.9898 Acc: 0.6638\n",
      "Epoch 33/299\n",
      "----------\n",
      "train Loss: 1.1767 Acc: 0.5962\n",
      "val Loss: 1.0950 Acc: 0.6264\n",
      "Epoch 34/299\n",
      "----------\n",
      "train Loss: 1.1837 Acc: 0.5982\n",
      "val Loss: 1.0518 Acc: 0.6533\n",
      "Epoch 35/299\n",
      "----------\n",
      "train Loss: 1.1508 Acc: 0.6099\n",
      "val Loss: 1.0391 Acc: 0.6442\n",
      "Epoch 36/299\n",
      "----------\n",
      "train Loss: 1.1220 Acc: 0.6129\n",
      "val Loss: 1.0506 Acc: 0.6541\n",
      "Epoch 37/299\n",
      "----------\n",
      "train Loss: 1.1874 Acc: 0.5999\n",
      "val Loss: 0.9583 Acc: 0.6778\n",
      "Epoch 38/299\n",
      "----------\n",
      "train Loss: 1.0953 Acc: 0.6271\n",
      "val Loss: 0.8653 Acc: 0.7101\n",
      "Epoch 39/299\n",
      "----------\n",
      "train Loss: 1.0594 Acc: 0.6399\n",
      "val Loss: 0.9487 Acc: 0.6903\n",
      "Epoch 40/299\n",
      "----------\n",
      "train Loss: 1.0894 Acc: 0.6309\n",
      "val Loss: 0.9234 Acc: 0.6908\n",
      "Epoch 41/299\n",
      "----------\n",
      "train Loss: 1.0455 Acc: 0.6407\n",
      "val Loss: 0.9008 Acc: 0.7007\n",
      "Epoch 42/299\n",
      "----------\n",
      "train Loss: 1.0204 Acc: 0.6545\n",
      "val Loss: 0.8534 Acc: 0.7157\n",
      "Epoch 43/299\n",
      "----------\n",
      "train Loss: 0.9982 Acc: 0.6603\n",
      "val Loss: 0.9640 Acc: 0.6750\n",
      "Epoch 44/299\n",
      "----------\n",
      "train Loss: 0.9979 Acc: 0.6567\n",
      "val Loss: 0.9351 Acc: 0.6966\n",
      "Epoch 45/299\n",
      "----------\n",
      "train Loss: 0.9679 Acc: 0.6728\n",
      "val Loss: 0.8420 Acc: 0.7300\n",
      "Epoch 46/299\n",
      "----------\n",
      "train Loss: 0.9597 Acc: 0.6753\n",
      "val Loss: 0.8830 Acc: 0.7058\n",
      "Epoch 47/299\n",
      "----------\n",
      "train Loss: 0.9576 Acc: 0.6737\n",
      "val Loss: 0.7795 Acc: 0.7488\n",
      "Epoch 48/299\n",
      "----------\n",
      "train Loss: 0.9460 Acc: 0.6810\n",
      "val Loss: 0.8556 Acc: 0.7205\n",
      "Epoch 49/299\n",
      "----------\n",
      "train Loss: 0.9251 Acc: 0.6885\n",
      "val Loss: 0.8935 Acc: 0.7175\n",
      "Epoch 50/299\n",
      "----------\n",
      "train Loss: 0.9109 Acc: 0.6886\n",
      "val Loss: 0.9156 Acc: 0.6987\n",
      "Epoch 51/299\n",
      "----------\n",
      "train Loss: 0.9096 Acc: 0.6916\n",
      "val Loss: 0.7746 Acc: 0.7493\n",
      "Epoch 52/299\n",
      "----------\n",
      "train Loss: 0.8851 Acc: 0.6982\n",
      "val Loss: 0.7801 Acc: 0.7468\n",
      "Epoch 53/299\n",
      "----------\n",
      "train Loss: 0.8750 Acc: 0.6974\n",
      "val Loss: 0.8799 Acc: 0.7221\n",
      "Epoch 54/299\n",
      "----------\n",
      "train Loss: 0.8941 Acc: 0.6952\n",
      "val Loss: 0.8224 Acc: 0.7287\n",
      "Epoch 55/299\n",
      "----------\n",
      "train Loss: 0.8737 Acc: 0.7044\n",
      "val Loss: 0.7864 Acc: 0.7368\n",
      "Epoch 56/299\n",
      "----------\n",
      "train Loss: 0.8544 Acc: 0.7110\n",
      "val Loss: 0.7965 Acc: 0.7432\n",
      "Epoch 57/299\n",
      "----------\n",
      "train Loss: 0.8170 Acc: 0.7227\n",
      "val Loss: 0.7351 Acc: 0.7613\n",
      "Epoch 58/299\n",
      "----------\n",
      "train Loss: 0.8244 Acc: 0.7198\n",
      "val Loss: 0.8156 Acc: 0.7506\n",
      "Epoch 59/299\n",
      "----------\n",
      "train Loss: 0.8170 Acc: 0.7238\n",
      "val Loss: 0.8727 Acc: 0.7205\n",
      "Epoch 60/299\n",
      "----------\n",
      "train Loss: 0.8162 Acc: 0.7305\n",
      "val Loss: 0.7346 Acc: 0.7602\n",
      "Epoch 61/299\n",
      "----------\n",
      "train Loss: 0.8202 Acc: 0.7243\n",
      "val Loss: 0.8391 Acc: 0.7322\n",
      "Epoch 62/299\n",
      "----------\n",
      "train Loss: 0.7915 Acc: 0.7324\n",
      "val Loss: 0.7660 Acc: 0.7572\n",
      "Epoch 63/299\n",
      "----------\n",
      "train Loss: 0.7771 Acc: 0.7371\n",
      "val Loss: 0.7311 Acc: 0.7554\n",
      "Epoch 64/299\n",
      "----------\n",
      "train Loss: 0.7594 Acc: 0.7386\n",
      "val Loss: 0.7421 Acc: 0.7641\n",
      "Epoch 65/299\n",
      "----------\n",
      "train Loss: 0.7687 Acc: 0.7381\n",
      "val Loss: 0.6976 Acc: 0.7788\n",
      "Epoch 66/299\n",
      "----------\n",
      "train Loss: 0.7586 Acc: 0.7453\n",
      "val Loss: 0.7629 Acc: 0.7478\n",
      "Epoch 67/299\n",
      "----------\n",
      "train Loss: 0.7313 Acc: 0.7518\n",
      "val Loss: 0.7755 Acc: 0.7539\n",
      "Epoch 68/299\n",
      "----------\n",
      "train Loss: 0.7453 Acc: 0.7499\n",
      "val Loss: 0.7952 Acc: 0.7468\n",
      "Epoch 69/299\n",
      "----------\n",
      "train Loss: 0.7435 Acc: 0.7501\n",
      "val Loss: 0.7402 Acc: 0.7562\n",
      "Epoch 70/299\n",
      "----------\n",
      "train Loss: 0.7406 Acc: 0.7449\n",
      "val Loss: 0.7304 Acc: 0.7661\n",
      "Epoch 71/299\n",
      "----------\n",
      "train Loss: 0.7403 Acc: 0.7542\n",
      "val Loss: 0.7163 Acc: 0.7661\n",
      "Epoch 72/299\n",
      "----------\n",
      "train Loss: 0.6996 Acc: 0.7600\n",
      "val Loss: 0.6977 Acc: 0.7697\n",
      "Epoch 73/299\n",
      "----------\n",
      "train Loss: 0.7045 Acc: 0.7623\n",
      "val Loss: 0.6893 Acc: 0.7877\n",
      "Epoch 74/299\n",
      "----------\n",
      "train Loss: 0.6984 Acc: 0.7620\n",
      "val Loss: 0.7981 Acc: 0.7457\n",
      "Epoch 75/299\n",
      "----------\n",
      "train Loss: 0.6986 Acc: 0.7654\n",
      "val Loss: 0.7442 Acc: 0.7679\n",
      "Epoch 76/299\n",
      "----------\n",
      "train Loss: 0.6851 Acc: 0.7654\n",
      "val Loss: 0.6807 Acc: 0.7921\n",
      "Epoch 77/299\n",
      "----------\n",
      "train Loss: 0.6808 Acc: 0.7703\n",
      "val Loss: 0.7218 Acc: 0.7712\n",
      "Epoch 78/299\n",
      "----------\n",
      "train Loss: 0.6806 Acc: 0.7672\n",
      "val Loss: 0.6608 Acc: 0.7933\n",
      "Epoch 79/299\n",
      "----------\n",
      "train Loss: 0.6610 Acc: 0.7734\n",
      "val Loss: 0.6860 Acc: 0.7854\n",
      "Epoch 80/299\n",
      "----------\n",
      "train Loss: 0.6786 Acc: 0.7709\n",
      "val Loss: 0.6597 Acc: 0.7931\n",
      "Epoch 81/299\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.7868\n",
      "val Loss: 0.7526 Acc: 0.7737\n",
      "Epoch 82/299\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 0.7822\n",
      "val Loss: 0.6850 Acc: 0.7839\n",
      "Epoch 83/299\n",
      "----------\n",
      "train Loss: 0.6428 Acc: 0.7840\n",
      "val Loss: 0.8378 Acc: 0.7478\n",
      "Epoch 84/299\n",
      "----------\n",
      "train Loss: 0.6343 Acc: 0.7854\n",
      "val Loss: 0.6693 Acc: 0.7890\n",
      "Epoch 85/299\n",
      "----------\n",
      "train Loss: 0.6458 Acc: 0.7842\n",
      "val Loss: 0.6991 Acc: 0.7862\n",
      "Epoch 86/299\n",
      "----------\n",
      "train Loss: 0.6239 Acc: 0.7918\n",
      "val Loss: 0.6524 Acc: 0.7933\n",
      "Epoch 87/299\n",
      "----------\n",
      "train Loss: 0.6052 Acc: 0.7958\n",
      "val Loss: 0.6530 Acc: 0.7895\n",
      "Epoch 88/299\n",
      "----------\n",
      "train Loss: 0.6055 Acc: 0.7969\n",
      "val Loss: 0.7349 Acc: 0.7776\n",
      "Epoch 89/299\n",
      "----------\n",
      "train Loss: 0.6168 Acc: 0.7969\n",
      "val Loss: 0.6895 Acc: 0.7824\n",
      "Epoch 90/299\n",
      "----------\n",
      "train Loss: 0.6116 Acc: 0.7934\n",
      "val Loss: 0.6442 Acc: 0.7971\n",
      "Epoch 91/299\n",
      "----------\n",
      "train Loss: 0.5916 Acc: 0.8019\n",
      "val Loss: 0.6688 Acc: 0.8017\n",
      "Epoch 92/299\n",
      "----------\n",
      "train Loss: 0.5989 Acc: 0.7983\n",
      "val Loss: 0.7471 Acc: 0.7742\n",
      "Epoch 93/299\n",
      "----------\n",
      "train Loss: 0.5904 Acc: 0.8020\n",
      "val Loss: 0.6388 Acc: 0.7989\n",
      "Epoch 94/299\n",
      "----------\n",
      "train Loss: 0.5856 Acc: 0.8041\n",
      "val Loss: 0.7580 Acc: 0.7745\n",
      "Epoch 95/299\n",
      "----------\n",
      "train Loss: 0.5983 Acc: 0.7958\n",
      "val Loss: 0.7255 Acc: 0.7842\n",
      "Epoch 96/299\n",
      "----------\n",
      "train Loss: 0.5730 Acc: 0.8034\n",
      "val Loss: 0.6804 Acc: 0.7949\n",
      "Epoch 97/299\n",
      "----------\n",
      "train Loss: 0.5720 Acc: 0.8057\n",
      "val Loss: 0.7224 Acc: 0.7788\n",
      "Epoch 98/299\n",
      "----------\n",
      "train Loss: 0.5682 Acc: 0.8103\n",
      "val Loss: 0.6542 Acc: 0.8017\n",
      "Epoch 99/299\n",
      "----------\n",
      "train Loss: 0.5633 Acc: 0.8054\n",
      "val Loss: 0.6807 Acc: 0.7910\n",
      "Epoch 100/299\n",
      "----------\n",
      "train Loss: 0.5631 Acc: 0.8136\n",
      "val Loss: 0.6980 Acc: 0.7908\n",
      "Epoch 101/299\n",
      "----------\n",
      "train Loss: 0.5443 Acc: 0.8134\n",
      "val Loss: 0.6752 Acc: 0.8025\n",
      "Epoch 102/299\n",
      "----------\n",
      "train Loss: 0.5407 Acc: 0.8133\n",
      "val Loss: 0.6790 Acc: 0.8043\n",
      "Epoch 103/299\n",
      "----------\n",
      "train Loss: 0.5512 Acc: 0.8091\n",
      "val Loss: 0.6745 Acc: 0.8005\n",
      "Epoch 104/299\n",
      "----------\n",
      "train Loss: 0.5540 Acc: 0.8127\n",
      "val Loss: 0.7472 Acc: 0.7727\n",
      "Epoch 105/299\n",
      "----------\n",
      "train Loss: 0.5473 Acc: 0.8148\n",
      "val Loss: 0.6872 Acc: 0.7910\n",
      "Epoch 106/299\n",
      "----------\n",
      "train Loss: 0.5507 Acc: 0.8170\n",
      "val Loss: 0.6452 Acc: 0.8050\n",
      "Epoch 107/299\n",
      "----------\n",
      "train Loss: 0.5326 Acc: 0.8192\n",
      "val Loss: 0.6488 Acc: 0.8114\n",
      "Epoch 108/299\n",
      "----------\n",
      "train Loss: 0.5182 Acc: 0.8226\n",
      "val Loss: 0.7802 Acc: 0.7811\n",
      "Epoch 109/299\n",
      "----------\n",
      "train Loss: 0.5062 Acc: 0.8277\n",
      "val Loss: 0.6803 Acc: 0.8099\n",
      "Epoch 110/299\n",
      "----------\n",
      "train Loss: 0.5268 Acc: 0.8220\n",
      "val Loss: 0.6630 Acc: 0.8078\n",
      "Epoch 111/299\n",
      "----------\n",
      "train Loss: 0.5241 Acc: 0.8279\n",
      "val Loss: 0.6964 Acc: 0.7999\n",
      "Epoch 112/299\n",
      "----------\n",
      "train Loss: 0.4900 Acc: 0.8401\n",
      "val Loss: 0.7057 Acc: 0.8005\n",
      "Epoch 113/299\n",
      "----------\n",
      "train Loss: 0.5091 Acc: 0.8305\n",
      "val Loss: 0.6733 Acc: 0.8081\n",
      "Epoch 114/299\n",
      "----------\n",
      "train Loss: 0.4977 Acc: 0.8348\n",
      "val Loss: 0.7654 Acc: 0.7796\n",
      "Epoch 115/299\n",
      "----------\n",
      "train Loss: 0.4983 Acc: 0.8317\n",
      "val Loss: 0.6817 Acc: 0.8045\n",
      "Epoch 116/299\n",
      "----------\n",
      "train Loss: 0.4917 Acc: 0.8330\n",
      "val Loss: 0.7655 Acc: 0.7923\n",
      "Epoch 117/299\n",
      "----------\n",
      "train Loss: 0.4876 Acc: 0.8376\n",
      "val Loss: 0.6162 Acc: 0.8170\n",
      "Epoch 118/299\n",
      "----------\n",
      "train Loss: 0.4966 Acc: 0.8365\n",
      "val Loss: 0.6870 Acc: 0.8068\n",
      "Epoch 119/299\n",
      "----------\n",
      "train Loss: 0.4838 Acc: 0.8375\n",
      "val Loss: 0.6940 Acc: 0.8040\n",
      "Epoch 120/299\n",
      "----------\n",
      "train Loss: 0.4980 Acc: 0.8330\n",
      "val Loss: 0.7019 Acc: 0.8012\n",
      "Epoch 121/299\n",
      "----------\n",
      "train Loss: 0.4847 Acc: 0.8351\n",
      "val Loss: 0.6961 Acc: 0.7974\n",
      "Epoch 122/299\n",
      "----------\n",
      "train Loss: 0.4822 Acc: 0.8357\n",
      "val Loss: 0.7075 Acc: 0.8025\n",
      "Epoch 123/299\n",
      "----------\n",
      "train Loss: 0.4637 Acc: 0.8441\n",
      "val Loss: 0.6544 Acc: 0.8117\n",
      "Epoch 124/299\n",
      "----------\n",
      "train Loss: 0.4690 Acc: 0.8422\n",
      "val Loss: 0.6227 Acc: 0.8201\n",
      "Epoch 125/299\n",
      "----------\n",
      "train Loss: 0.4567 Acc: 0.8489\n",
      "val Loss: 0.6487 Acc: 0.8183\n",
      "Epoch 126/299\n",
      "----------\n",
      "train Loss: 0.4785 Acc: 0.8369\n",
      "val Loss: 0.6395 Acc: 0.8178\n",
      "Epoch 127/299\n",
      "----------\n",
      "train Loss: 0.4766 Acc: 0.8352\n",
      "val Loss: 0.6410 Acc: 0.8119\n",
      "Epoch 128/299\n",
      "----------\n",
      "train Loss: 0.4545 Acc: 0.8499\n",
      "val Loss: 0.7233 Acc: 0.7913\n",
      "Epoch 129/299\n",
      "----------\n",
      "train Loss: 0.4788 Acc: 0.8393\n",
      "val Loss: 0.6651 Acc: 0.8063\n",
      "Epoch 130/299\n",
      "----------\n",
      "train Loss: 0.4488 Acc: 0.8485\n",
      "val Loss: 0.6129 Acc: 0.8277\n",
      "Epoch 131/299\n",
      "----------\n",
      "train Loss: 0.4473 Acc: 0.8483\n",
      "val Loss: 0.6607 Acc: 0.8173\n",
      "Epoch 132/299\n",
      "----------\n",
      "train Loss: 0.4451 Acc: 0.8472\n",
      "val Loss: 0.6624 Acc: 0.8139\n",
      "Epoch 133/299\n",
      "----------\n",
      "train Loss: 0.4519 Acc: 0.8455\n",
      "val Loss: 0.7037 Acc: 0.7977\n",
      "Epoch 134/299\n",
      "----------\n",
      "train Loss: 0.4554 Acc: 0.8479\n",
      "val Loss: 0.6981 Acc: 0.8068\n",
      "Epoch 135/299\n",
      "----------\n",
      "train Loss: 0.4420 Acc: 0.8519\n",
      "val Loss: 0.8332 Acc: 0.7956\n",
      "Epoch 136/299\n",
      "----------\n",
      "train Loss: 0.4246 Acc: 0.8563\n",
      "val Loss: 0.6505 Acc: 0.8167\n",
      "Epoch 137/299\n",
      "----------\n",
      "train Loss: 0.4292 Acc: 0.8570\n",
      "val Loss: 0.6177 Acc: 0.8223\n",
      "Epoch 138/299\n",
      "----------\n",
      "train Loss: 0.4260 Acc: 0.8572\n",
      "val Loss: 0.7136 Acc: 0.8022\n",
      "Epoch 139/299\n",
      "----------\n",
      "train Loss: 0.4290 Acc: 0.8591\n",
      "val Loss: 0.7664 Acc: 0.7949\n",
      "Epoch 140/299\n",
      "----------\n",
      "train Loss: 0.4325 Acc: 0.8553\n",
      "val Loss: 0.6541 Acc: 0.8129\n",
      "Epoch 141/299\n",
      "----------\n",
      "train Loss: 0.4420 Acc: 0.8554\n",
      "val Loss: 0.6134 Acc: 0.8236\n",
      "Epoch 142/299\n",
      "----------\n",
      "train Loss: 0.4083 Acc: 0.8602\n",
      "val Loss: 0.8211 Acc: 0.7949\n",
      "Epoch 143/299\n",
      "----------\n",
      "train Loss: 0.4290 Acc: 0.8557\n",
      "val Loss: 0.7073 Acc: 0.8073\n",
      "Epoch 144/299\n",
      "----------\n",
      "train Loss: 0.4350 Acc: 0.8565\n",
      "val Loss: 0.6942 Acc: 0.8106\n",
      "Epoch 145/299\n",
      "----------\n",
      "train Loss: 0.4144 Acc: 0.8626\n",
      "val Loss: 0.7217 Acc: 0.8086\n",
      "Epoch 146/299\n",
      "----------\n",
      "train Loss: 0.4239 Acc: 0.8544\n",
      "val Loss: 0.6859 Acc: 0.8106\n",
      "Epoch 147/299\n",
      "----------\n",
      "train Loss: 0.4192 Acc: 0.8573\n",
      "val Loss: 0.7400 Acc: 0.7923\n",
      "Epoch 148/299\n",
      "----------\n",
      "train Loss: 0.4016 Acc: 0.8679\n",
      "val Loss: 0.6851 Acc: 0.8290\n",
      "Epoch 149/299\n",
      "----------\n",
      "train Loss: 0.4214 Acc: 0.8595\n",
      "val Loss: 0.6583 Acc: 0.8269\n",
      "Epoch 150/299\n",
      "----------\n",
      "train Loss: 0.3897 Acc: 0.8708\n",
      "val Loss: 0.7076 Acc: 0.8134\n",
      "Epoch 151/299\n",
      "----------\n",
      "train Loss: 0.4006 Acc: 0.8648\n",
      "val Loss: 0.7186 Acc: 0.7982\n",
      "Epoch 152/299\n",
      "----------\n",
      "train Loss: 0.4073 Acc: 0.8613\n",
      "val Loss: 0.6994 Acc: 0.8096\n",
      "Epoch 153/299\n",
      "----------\n",
      "train Loss: 0.4129 Acc: 0.8656\n",
      "val Loss: 0.6696 Acc: 0.8089\n",
      "Epoch 154/299\n",
      "----------\n",
      "train Loss: 0.4232 Acc: 0.8592\n",
      "val Loss: 0.6916 Acc: 0.8094\n",
      "Epoch 155/299\n",
      "----------\n",
      "train Loss: 0.4075 Acc: 0.8665\n",
      "val Loss: 0.6269 Acc: 0.8185\n",
      "Epoch 156/299\n",
      "----------\n",
      "train Loss: 0.3937 Acc: 0.8677\n",
      "val Loss: 0.6387 Acc: 0.8208\n",
      "Epoch 157/299\n",
      "----------\n",
      "train Loss: 0.3814 Acc: 0.8730\n",
      "val Loss: 0.7181 Acc: 0.8061\n",
      "Epoch 158/299\n",
      "----------\n",
      "train Loss: 0.3760 Acc: 0.8747\n",
      "val Loss: 0.7350 Acc: 0.8068\n",
      "Epoch 159/299\n",
      "----------\n",
      "train Loss: 0.3979 Acc: 0.8664\n",
      "val Loss: 0.7554 Acc: 0.8010\n",
      "Epoch 160/299\n",
      "----------\n",
      "train Loss: 0.4034 Acc: 0.8659\n",
      "val Loss: 0.7029 Acc: 0.8025\n",
      "Epoch 161/299\n",
      "----------\n",
      "train Loss: 0.3980 Acc: 0.8656\n",
      "val Loss: 0.6868 Acc: 0.8188\n",
      "Epoch 162/299\n",
      "----------\n",
      "train Loss: 0.3777 Acc: 0.8741\n",
      "val Loss: 0.7280 Acc: 0.8038\n",
      "Epoch 163/299\n",
      "----------\n",
      "train Loss: 0.3800 Acc: 0.8732\n",
      "val Loss: 0.6837 Acc: 0.8129\n",
      "Epoch 164/299\n",
      "----------\n",
      "train Loss: 0.3933 Acc: 0.8697\n",
      "val Loss: 0.6339 Acc: 0.8213\n",
      "Epoch 165/299\n",
      "----------\n",
      "train Loss: 0.3895 Acc: 0.8716\n",
      "val Loss: 0.6476 Acc: 0.8259\n",
      "Epoch 166/299\n",
      "----------\n",
      "train Loss: 0.3791 Acc: 0.8709\n",
      "val Loss: 0.7185 Acc: 0.8096\n",
      "Epoch 167/299\n",
      "----------\n",
      "train Loss: 0.3587 Acc: 0.8808\n",
      "val Loss: 0.6888 Acc: 0.8190\n",
      "Epoch 168/299\n",
      "----------\n",
      "train Loss: 0.3747 Acc: 0.8770\n",
      "val Loss: 0.7142 Acc: 0.8162\n",
      "Epoch 169/299\n",
      "----------\n",
      "train Loss: 0.3738 Acc: 0.8760\n",
      "val Loss: 0.6872 Acc: 0.8211\n",
      "Epoch 170/299\n",
      "----------\n",
      "train Loss: 0.3745 Acc: 0.8719\n",
      "val Loss: 0.6639 Acc: 0.8313\n",
      "Epoch 171/299\n",
      "----------\n",
      "train Loss: 0.3799 Acc: 0.8738\n",
      "val Loss: 0.7541 Acc: 0.8173\n",
      "Epoch 172/299\n",
      "----------\n",
      "train Loss: 0.3697 Acc: 0.8767\n",
      "val Loss: 0.6834 Acc: 0.8269\n",
      "Epoch 173/299\n",
      "----------\n",
      "train Loss: 0.3752 Acc: 0.8740\n",
      "val Loss: 0.6809 Acc: 0.8173\n",
      "Epoch 174/299\n",
      "----------\n",
      "train Loss: 0.3558 Acc: 0.8797\n",
      "val Loss: 0.6777 Acc: 0.8173\n",
      "Epoch 175/299\n",
      "----------\n",
      "train Loss: 0.3755 Acc: 0.8745\n",
      "val Loss: 0.7316 Acc: 0.8251\n",
      "Epoch 176/299\n",
      "----------\n",
      "train Loss: 0.3670 Acc: 0.8790\n",
      "val Loss: 0.6735 Acc: 0.8330\n",
      "Epoch 177/299\n",
      "----------\n",
      "train Loss: 0.3550 Acc: 0.8835\n",
      "val Loss: 0.6566 Acc: 0.8302\n",
      "Epoch 178/299\n",
      "----------\n",
      "train Loss: 0.3672 Acc: 0.8781\n",
      "val Loss: 0.7106 Acc: 0.8094\n",
      "Epoch 179/299\n",
      "----------\n",
      "train Loss: 0.3636 Acc: 0.8808\n",
      "val Loss: 0.6727 Acc: 0.8216\n",
      "Epoch 180/299\n",
      "----------\n",
      "train Loss: 0.3583 Acc: 0.8800\n",
      "val Loss: 0.7133 Acc: 0.8226\n",
      "Epoch 181/299\n",
      "----------\n",
      "train Loss: 0.3488 Acc: 0.8881\n",
      "val Loss: 0.7453 Acc: 0.8076\n",
      "Epoch 182/299\n",
      "----------\n",
      "train Loss: 0.3392 Acc: 0.8874\n",
      "val Loss: 0.8171 Acc: 0.8025\n",
      "Epoch 183/299\n",
      "----------\n",
      "train Loss: 0.3613 Acc: 0.8794\n",
      "val Loss: 0.7020 Acc: 0.8170\n",
      "Epoch 184/299\n",
      "----------\n",
      "train Loss: 0.3762 Acc: 0.8761\n",
      "val Loss: 0.6998 Acc: 0.8178\n",
      "Epoch 185/299\n",
      "----------\n",
      "train Loss: 0.3699 Acc: 0.8763\n",
      "val Loss: 0.6767 Acc: 0.8211\n",
      "Epoch 186/299\n",
      "----------\n",
      "train Loss: 0.3484 Acc: 0.8850\n",
      "val Loss: 0.7018 Acc: 0.8145\n",
      "Epoch 187/299\n",
      "----------\n",
      "train Loss: 0.3471 Acc: 0.8858\n",
      "val Loss: 0.7576 Acc: 0.8038\n",
      "Epoch 188/299\n",
      "----------\n",
      "train Loss: 0.3477 Acc: 0.8843\n",
      "val Loss: 0.6936 Acc: 0.8188\n",
      "Epoch 189/299\n",
      "----------\n",
      "train Loss: 0.3488 Acc: 0.8855\n",
      "val Loss: 0.7043 Acc: 0.8160\n",
      "Epoch 190/299\n",
      "----------\n",
      "train Loss: 0.3717 Acc: 0.8750\n",
      "val Loss: 0.6856 Acc: 0.8218\n",
      "Epoch 191/299\n",
      "----------\n",
      "train Loss: 0.3469 Acc: 0.8853\n",
      "val Loss: 0.6840 Acc: 0.8277\n",
      "Epoch 192/299\n",
      "----------\n",
      "train Loss: 0.3449 Acc: 0.8847\n",
      "val Loss: 0.7114 Acc: 0.8249\n",
      "Epoch 193/299\n",
      "----------\n",
      "train Loss: 0.3432 Acc: 0.8879\n",
      "val Loss: 0.6534 Acc: 0.8295\n",
      "Epoch 194/299\n",
      "----------\n",
      "train Loss: 0.3289 Acc: 0.8893\n",
      "val Loss: 0.7548 Acc: 0.8150\n",
      "Epoch 195/299\n",
      "----------\n",
      "train Loss: 0.3384 Acc: 0.8876\n",
      "val Loss: 0.7457 Acc: 0.8132\n",
      "Epoch 196/299\n",
      "----------\n",
      "train Loss: 0.3560 Acc: 0.8801\n",
      "val Loss: 0.6347 Acc: 0.8369\n",
      "Epoch 197/299\n",
      "----------\n",
      "train Loss: 0.3411 Acc: 0.8911\n",
      "val Loss: 0.7837 Acc: 0.8111\n",
      "Epoch 198/299\n",
      "----------\n",
      "train Loss: 0.3352 Acc: 0.8937\n",
      "val Loss: 0.7231 Acc: 0.8221\n",
      "Epoch 199/299\n",
      "----------\n",
      "train Loss: 0.3356 Acc: 0.8864\n",
      "val Loss: 0.7026 Acc: 0.8251\n",
      "Epoch 200/299\n",
      "----------\n",
      "train Loss: 0.3384 Acc: 0.8902\n",
      "val Loss: 0.7265 Acc: 0.8175\n",
      "Epoch 201/299\n",
      "----------\n",
      "train Loss: 0.3235 Acc: 0.8920\n",
      "val Loss: 0.8067 Acc: 0.8119\n",
      "Epoch 202/299\n",
      "----------\n",
      "train Loss: 0.3425 Acc: 0.8853\n",
      "val Loss: 0.7039 Acc: 0.8132\n",
      "Epoch 203/299\n",
      "----------\n",
      "train Loss: 0.3312 Acc: 0.8872\n",
      "val Loss: 0.7092 Acc: 0.8262\n",
      "Epoch 204/299\n",
      "----------\n",
      "train Loss: 0.3364 Acc: 0.8850\n",
      "val Loss: 0.7088 Acc: 0.8218\n",
      "Epoch 205/299\n",
      "----------\n",
      "train Loss: 0.3083 Acc: 0.8946\n",
      "val Loss: 0.7859 Acc: 0.8109\n",
      "Epoch 206/299\n",
      "----------\n",
      "train Loss: 0.3296 Acc: 0.8921\n",
      "val Loss: 0.7396 Acc: 0.8109\n",
      "Epoch 207/299\n",
      "----------\n",
      "train Loss: 0.3501 Acc: 0.8812\n",
      "val Loss: 0.7597 Acc: 0.8193\n",
      "Epoch 208/299\n",
      "----------\n",
      "train Loss: 0.3248 Acc: 0.8913\n",
      "val Loss: 0.6971 Acc: 0.8213\n",
      "Epoch 209/299\n",
      "----------\n",
      "train Loss: 0.3266 Acc: 0.8892\n",
      "val Loss: 0.7095 Acc: 0.8119\n",
      "Epoch 210/299\n",
      "----------\n",
      "train Loss: 0.3183 Acc: 0.8947\n",
      "val Loss: 0.7123 Acc: 0.8173\n",
      "Epoch 211/299\n",
      "----------\n",
      "train Loss: 0.3200 Acc: 0.8917\n",
      "val Loss: 0.7329 Acc: 0.8234\n",
      "Epoch 212/299\n",
      "----------\n",
      "train Loss: 0.3256 Acc: 0.8948\n",
      "val Loss: 0.6758 Acc: 0.8272\n",
      "Epoch 213/299\n",
      "----------\n",
      "train Loss: 0.3221 Acc: 0.8932\n",
      "val Loss: 0.7413 Acc: 0.8292\n",
      "Epoch 214/299\n",
      "----------\n",
      "train Loss: 0.3133 Acc: 0.8953\n",
      "val Loss: 0.7139 Acc: 0.8307\n",
      "Epoch 215/299\n",
      "----------\n",
      "train Loss: 0.3355 Acc: 0.8909\n",
      "val Loss: 0.6933 Acc: 0.8249\n",
      "Epoch 216/299\n",
      "----------\n",
      "train Loss: 0.3098 Acc: 0.8968\n",
      "val Loss: 0.8314 Acc: 0.8150\n",
      "Epoch 217/299\n",
      "----------\n",
      "train Loss: 0.3155 Acc: 0.8972\n",
      "val Loss: 0.7462 Acc: 0.8165\n",
      "Epoch 218/299\n",
      "----------\n",
      "train Loss: 0.2973 Acc: 0.8995\n",
      "val Loss: 0.6809 Acc: 0.8287\n",
      "Epoch 219/299\n",
      "----------\n",
      "train Loss: 0.3069 Acc: 0.8995\n",
      "val Loss: 0.7969 Acc: 0.8142\n",
      "Epoch 220/299\n",
      "----------\n",
      "train Loss: 0.3051 Acc: 0.8974\n",
      "val Loss: 0.7328 Acc: 0.8292\n",
      "Epoch 221/299\n",
      "----------\n",
      "train Loss: 0.3286 Acc: 0.8919\n",
      "val Loss: 0.6625 Acc: 0.8262\n",
      "Epoch 222/299\n",
      "----------\n",
      "train Loss: 0.3048 Acc: 0.8992\n",
      "val Loss: 0.7176 Acc: 0.8251\n",
      "Epoch 223/299\n",
      "----------\n",
      "train Loss: 0.3095 Acc: 0.8978\n",
      "val Loss: 0.7326 Acc: 0.8193\n",
      "Epoch 224/299\n",
      "----------\n",
      "train Loss: 0.3100 Acc: 0.9002\n",
      "val Loss: 0.7411 Acc: 0.8178\n",
      "Epoch 225/299\n",
      "----------\n",
      "train Loss: 0.3048 Acc: 0.8983\n",
      "val Loss: 0.7377 Acc: 0.8155\n",
      "Epoch 226/299\n",
      "----------\n",
      "train Loss: 0.3193 Acc: 0.8911\n",
      "val Loss: 0.6836 Acc: 0.8318\n",
      "Epoch 227/299\n",
      "----------\n",
      "train Loss: 0.3119 Acc: 0.8994\n",
      "val Loss: 0.6657 Acc: 0.8333\n",
      "Epoch 228/299\n",
      "----------\n",
      "train Loss: 0.3155 Acc: 0.8970\n",
      "val Loss: 0.6952 Acc: 0.8358\n",
      "Epoch 229/299\n",
      "----------\n",
      "train Loss: 0.2992 Acc: 0.8988\n",
      "val Loss: 0.6749 Acc: 0.8313\n",
      "Epoch 230/299\n",
      "----------\n",
      "train Loss: 0.3171 Acc: 0.8964\n",
      "val Loss: 0.7830 Acc: 0.8203\n",
      "Epoch 231/299\n",
      "----------\n",
      "train Loss: 0.3068 Acc: 0.8996\n",
      "val Loss: 0.7490 Acc: 0.8145\n",
      "Epoch 232/299\n",
      "----------\n",
      "train Loss: 0.2902 Acc: 0.9038\n",
      "val Loss: 0.7115 Acc: 0.8341\n",
      "Epoch 233/299\n",
      "----------\n",
      "train Loss: 0.3091 Acc: 0.8986\n",
      "val Loss: 0.7311 Acc: 0.8211\n",
      "Epoch 234/299\n",
      "----------\n",
      "train Loss: 0.3156 Acc: 0.8982\n",
      "val Loss: 0.7266 Acc: 0.8267\n",
      "Epoch 235/299\n",
      "----------\n",
      "train Loss: 0.3003 Acc: 0.9001\n",
      "val Loss: 0.6930 Acc: 0.8333\n",
      "Epoch 236/299\n",
      "----------\n",
      "train Loss: 0.3022 Acc: 0.8980\n",
      "val Loss: 0.7472 Acc: 0.8134\n",
      "Epoch 237/299\n",
      "----------\n",
      "train Loss: 0.3022 Acc: 0.9008\n",
      "val Loss: 0.7247 Acc: 0.8295\n",
      "Epoch 238/299\n",
      "----------\n",
      "train Loss: 0.2941 Acc: 0.9043\n",
      "val Loss: 0.7655 Acc: 0.8236\n",
      "Epoch 239/299\n",
      "----------\n",
      "train Loss: 0.3052 Acc: 0.8988\n",
      "val Loss: 0.7554 Acc: 0.8236\n",
      "Epoch 240/299\n",
      "----------\n",
      "train Loss: 0.3066 Acc: 0.9003\n",
      "val Loss: 0.7336 Acc: 0.8330\n",
      "Epoch 241/299\n",
      "----------\n",
      "train Loss: 0.2858 Acc: 0.9046\n",
      "val Loss: 0.7387 Acc: 0.8267\n",
      "Epoch 242/299\n",
      "----------\n",
      "train Loss: 0.2950 Acc: 0.9037\n",
      "val Loss: 0.8326 Acc: 0.8269\n",
      "Epoch 243/299\n",
      "----------\n",
      "train Loss: 0.3071 Acc: 0.9020\n",
      "val Loss: 0.6654 Acc: 0.8394\n",
      "Epoch 244/299\n",
      "----------\n",
      "train Loss: 0.2856 Acc: 0.9061\n",
      "val Loss: 0.7040 Acc: 0.8323\n",
      "Epoch 245/299\n",
      "----------\n",
      "train Loss: 0.2858 Acc: 0.9026\n",
      "val Loss: 0.6715 Acc: 0.8391\n",
      "Epoch 246/299\n",
      "----------\n",
      "train Loss: 0.3109 Acc: 0.8985\n",
      "val Loss: 0.6984 Acc: 0.8325\n",
      "Epoch 247/299\n",
      "----------\n",
      "train Loss: 0.2965 Acc: 0.9024\n",
      "val Loss: 0.7771 Acc: 0.8139\n",
      "Epoch 248/299\n",
      "----------\n",
      "train Loss: 0.3073 Acc: 0.8980\n",
      "val Loss: 0.6934 Acc: 0.8315\n",
      "Epoch 249/299\n",
      "----------\n",
      "train Loss: 0.2822 Acc: 0.9073\n",
      "val Loss: 0.7438 Acc: 0.8341\n",
      "Epoch 250/299\n",
      "----------\n",
      "train Loss: 0.2758 Acc: 0.9068\n",
      "val Loss: 0.7412 Acc: 0.8351\n",
      "Epoch 251/299\n",
      "----------\n",
      "train Loss: 0.2903 Acc: 0.9038\n",
      "val Loss: 0.7122 Acc: 0.8371\n",
      "Epoch 252/299\n",
      "----------\n",
      "train Loss: 0.2864 Acc: 0.9065\n",
      "val Loss: 0.8348 Acc: 0.8285\n",
      "Epoch 253/299\n",
      "----------\n",
      "train Loss: 0.2763 Acc: 0.9100\n",
      "val Loss: 0.8741 Acc: 0.8091\n",
      "Epoch 254/299\n",
      "----------\n",
      "train Loss: 0.3050 Acc: 0.9016\n",
      "val Loss: 0.7541 Acc: 0.8241\n",
      "Epoch 255/299\n",
      "----------\n",
      "train Loss: 0.2763 Acc: 0.9111\n",
      "val Loss: 0.7553 Acc: 0.8279\n",
      "Epoch 256/299\n",
      "----------\n",
      "train Loss: 0.2542 Acc: 0.9156\n",
      "val Loss: 0.7410 Acc: 0.8257\n",
      "Epoch 257/299\n",
      "----------\n",
      "train Loss: 0.2896 Acc: 0.9036\n",
      "val Loss: 0.7533 Acc: 0.8208\n",
      "Epoch 258/299\n",
      "----------\n",
      "train Loss: 0.2688 Acc: 0.9096\n",
      "val Loss: 0.6972 Acc: 0.8279\n",
      "Epoch 259/299\n",
      "----------\n",
      "train Loss: 0.2891 Acc: 0.9070\n",
      "val Loss: 0.8545 Acc: 0.8033\n",
      "Epoch 260/299\n",
      "----------\n",
      "train Loss: 0.2731 Acc: 0.9076\n",
      "val Loss: 0.7945 Acc: 0.8236\n",
      "Epoch 261/299\n",
      "----------\n",
      "train Loss: 0.2794 Acc: 0.9063\n",
      "val Loss: 0.7081 Acc: 0.8363\n",
      "Epoch 262/299\n",
      "----------\n",
      "train Loss: 0.2823 Acc: 0.9067\n",
      "val Loss: 0.7810 Acc: 0.8262\n",
      "Epoch 263/299\n",
      "----------\n",
      "train Loss: 0.2795 Acc: 0.9057\n",
      "val Loss: 0.7583 Acc: 0.8259\n",
      "Epoch 264/299\n",
      "----------\n",
      "train Loss: 0.2734 Acc: 0.9084\n",
      "val Loss: 0.7901 Acc: 0.8162\n",
      "Epoch 265/299\n",
      "----------\n",
      "train Loss: 0.2815 Acc: 0.9087\n",
      "val Loss: 0.7117 Acc: 0.8320\n",
      "Epoch 266/299\n",
      "----------\n",
      "train Loss: 0.2842 Acc: 0.9030\n",
      "val Loss: 0.6918 Acc: 0.8341\n",
      "Epoch 267/299\n",
      "----------\n",
      "train Loss: 0.2880 Acc: 0.9056\n",
      "val Loss: 0.7126 Acc: 0.8269\n",
      "Epoch 268/299\n",
      "----------\n",
      "train Loss: 0.2682 Acc: 0.9140\n",
      "val Loss: 0.7067 Acc: 0.8348\n",
      "Epoch 269/299\n",
      "----------\n",
      "train Loss: 0.2634 Acc: 0.9137\n",
      "val Loss: 0.7466 Acc: 0.8292\n",
      "Epoch 270/299\n",
      "----------\n",
      "train Loss: 0.2942 Acc: 0.9028\n",
      "val Loss: 0.7148 Acc: 0.8325\n",
      "Epoch 271/299\n",
      "----------\n",
      "train Loss: 0.2776 Acc: 0.9088\n",
      "val Loss: 0.7608 Acc: 0.8213\n",
      "Epoch 272/299\n",
      "----------\n",
      "train Loss: 0.2802 Acc: 0.9081\n",
      "val Loss: 0.7440 Acc: 0.8290\n",
      "Epoch 273/299\n",
      "----------\n",
      "train Loss: 0.2764 Acc: 0.9079\n",
      "val Loss: 0.7764 Acc: 0.8259\n",
      "Epoch 274/299\n",
      "----------\n",
      "train Loss: 0.2782 Acc: 0.9090\n",
      "val Loss: 0.7146 Acc: 0.8292\n",
      "Epoch 275/299\n",
      "----------\n",
      "train Loss: 0.2755 Acc: 0.9110\n",
      "val Loss: 0.8035 Acc: 0.8193\n",
      "Epoch 276/299\n",
      "----------\n",
      "train Loss: 0.2758 Acc: 0.9089\n",
      "val Loss: 0.7474 Acc: 0.8318\n",
      "Epoch 277/299\n",
      "----------\n",
      "train Loss: 0.2946 Acc: 0.9026\n",
      "val Loss: 0.7644 Acc: 0.8241\n",
      "Epoch 278/299\n",
      "----------\n",
      "train Loss: 0.2621 Acc: 0.9142\n",
      "val Loss: 0.8782 Acc: 0.8020\n",
      "Epoch 279/299\n",
      "----------\n",
      "train Loss: 0.2721 Acc: 0.9109\n",
      "val Loss: 0.7543 Acc: 0.8297\n",
      "Epoch 280/299\n",
      "----------\n",
      "train Loss: 0.2565 Acc: 0.9145\n",
      "val Loss: 0.8594 Acc: 0.8127\n",
      "Epoch 281/299\n",
      "----------\n",
      "train Loss: 0.2694 Acc: 0.9130\n",
      "val Loss: 0.7752 Acc: 0.8264\n",
      "Epoch 282/299\n",
      "----------\n",
      "train Loss: 0.2624 Acc: 0.9107\n",
      "val Loss: 0.7466 Acc: 0.8290\n",
      "Epoch 283/299\n",
      "----------\n",
      "train Loss: 0.2593 Acc: 0.9135\n",
      "val Loss: 0.7386 Acc: 0.8325\n",
      "Epoch 284/299\n",
      "----------\n",
      "train Loss: 0.2835 Acc: 0.9084\n",
      "val Loss: 0.8083 Acc: 0.8081\n",
      "Epoch 285/299\n",
      "----------\n",
      "train Loss: 0.2456 Acc: 0.9188\n",
      "val Loss: 0.7936 Acc: 0.8185\n",
      "Epoch 286/299\n",
      "----------\n",
      "train Loss: 0.2629 Acc: 0.9148\n",
      "val Loss: 0.7486 Acc: 0.8323\n",
      "Epoch 287/299\n",
      "----------\n",
      "train Loss: 0.2818 Acc: 0.9052\n",
      "val Loss: 0.7416 Acc: 0.8231\n",
      "Epoch 288/299\n",
      "----------\n",
      "train Loss: 0.2602 Acc: 0.9149\n",
      "val Loss: 0.7371 Acc: 0.8325\n",
      "Epoch 289/299\n",
      "----------\n",
      "train Loss: 0.2477 Acc: 0.9216\n",
      "val Loss: 0.7925 Acc: 0.8274\n",
      "Epoch 290/299\n",
      "----------\n",
      "train Loss: 0.2609 Acc: 0.9147\n",
      "val Loss: 0.7891 Acc: 0.8251\n",
      "Epoch 291/299\n",
      "----------\n",
      "train Loss: 0.2537 Acc: 0.9158\n",
      "val Loss: 0.6965 Acc: 0.8363\n",
      "Epoch 292/299\n",
      "----------\n",
      "train Loss: 0.2820 Acc: 0.9067\n",
      "val Loss: 0.7909 Acc: 0.8127\n",
      "Epoch 293/299\n",
      "----------\n",
      "train Loss: 0.2661 Acc: 0.9107\n",
      "val Loss: 0.7024 Acc: 0.8366\n",
      "Epoch 294/299\n",
      "----------\n",
      "train Loss: 0.2462 Acc: 0.9167\n",
      "val Loss: 0.8037 Acc: 0.8241\n",
      "Epoch 295/299\n",
      "----------\n",
      "train Loss: 0.2561 Acc: 0.9141\n",
      "val Loss: 0.8180 Acc: 0.8185\n",
      "Epoch 296/299\n",
      "----------\n",
      "train Loss: 0.2555 Acc: 0.9169\n",
      "val Loss: 0.7420 Acc: 0.8353\n",
      "Epoch 297/299\n",
      "----------\n",
      "train Loss: 0.2539 Acc: 0.9180\n",
      "val Loss: 0.7756 Acc: 0.8315\n",
      "Epoch 298/299\n",
      "----------\n",
      "train Loss: 0.2528 Acc: 0.9161\n",
      "val Loss: 0.7482 Acc: 0.8272\n",
      "Epoch 299/299\n",
      "----------\n",
      "train Loss: 0.2603 Acc: 0.9156\n",
      "val Loss: 0.8096 Acc: 0.8216\n",
      "Training complete in 317m 48s\n",
      "Best val Acc: 0.839399\n"
     ]
    }
   ],
   "source": [
    "final_model = models.resnet50(pretrained=use_pretrained)\n",
    "num_ftrs = final_model.fc.in_features\n",
    "final_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "final_model = final_model.to(device)\n",
    "\n",
    "optimizer_ft = optim.Adam(final_model.parameters(), lr=0.003)\n",
    "final_model, hist = train_model(final_model, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34728a46-52c4-4a1b-8f89-b86da7409d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(final_model.state_dict(), \"/app/50.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a593ee23-7305-4cb6-9737-7a2812c93298",
   "metadata": {},
   "source": [
    "## Check the stability of other models to learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e9316-5c70-483f-aee5-81aff37cb4c3",
   "metadata": {},
   "source": [
    "### ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6421b43b-02a0-4647-b858-b876bb376e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/299\n",
      "----------\n",
      "train Loss: 2.3294 Acc: 0.1499\n",
      "val Loss: 2.4557 Acc: 0.1514\n",
      "Epoch 1/299\n",
      "----------\n",
      "train Loss: 2.2108 Acc: 0.1754\n",
      "val Loss: 2.3319 Acc: 0.1896\n",
      "Epoch 2/299\n",
      "----------\n",
      "train Loss: 2.1736 Acc: 0.1787\n",
      "val Loss: 2.1215 Acc: 0.1957\n",
      "Epoch 3/299\n",
      "----------\n",
      "train Loss: 2.1514 Acc: 0.1958\n",
      "val Loss: 2.0643 Acc: 0.2288\n",
      "Epoch 4/299\n",
      "----------\n",
      "train Loss: 2.1226 Acc: 0.2088\n",
      "val Loss: 2.2037 Acc: 0.1932\n",
      "Epoch 5/299\n",
      "----------\n",
      "train Loss: 2.0799 Acc: 0.2265\n",
      "val Loss: 1.9425 Acc: 0.2721\n",
      "Epoch 6/299\n",
      "----------\n",
      "train Loss: 2.0471 Acc: 0.2408\n",
      "val Loss: 1.9368 Acc: 0.2812\n",
      "Epoch 7/299\n",
      "----------\n",
      "train Loss: 1.9992 Acc: 0.2688\n",
      "val Loss: 2.0167 Acc: 0.2634\n",
      "Epoch 8/299\n",
      "----------\n",
      "train Loss: 1.9556 Acc: 0.2831\n",
      "val Loss: 1.8845 Acc: 0.3118\n",
      "Epoch 9/299\n",
      "----------\n",
      "train Loss: 1.8885 Acc: 0.3165\n",
      "val Loss: 1.7762 Acc: 0.3563\n",
      "Epoch 10/299\n",
      "----------\n",
      "train Loss: 1.8269 Acc: 0.3465\n",
      "val Loss: 1.6711 Acc: 0.4001\n",
      "Epoch 11/299\n",
      "----------\n",
      "train Loss: 1.7643 Acc: 0.3732\n",
      "val Loss: 1.8088 Acc: 0.3777\n",
      "Epoch 12/299\n",
      "----------\n",
      "train Loss: 1.6803 Acc: 0.3969\n",
      "val Loss: 1.5658 Acc: 0.4413\n",
      "Epoch 13/299\n",
      "----------\n",
      "train Loss: 1.6406 Acc: 0.4218\n",
      "val Loss: 1.7596 Acc: 0.4164\n",
      "Epoch 14/299\n",
      "----------\n",
      "train Loss: 1.6127 Acc: 0.4326\n",
      "val Loss: 1.3993 Acc: 0.5174\n",
      "Epoch 15/299\n",
      "----------\n",
      "train Loss: 1.5430 Acc: 0.4606\n",
      "val Loss: 1.5059 Acc: 0.4681\n",
      "Epoch 16/299\n",
      "----------\n",
      "train Loss: 1.5203 Acc: 0.4648\n",
      "val Loss: 1.3355 Acc: 0.5396\n",
      "Epoch 17/299\n",
      "----------\n",
      "train Loss: 1.4522 Acc: 0.4948\n",
      "val Loss: 1.2361 Acc: 0.5823\n",
      "Epoch 18/299\n",
      "----------\n",
      "train Loss: 1.4075 Acc: 0.5148\n",
      "val Loss: 1.8646 Acc: 0.4846\n",
      "Epoch 19/299\n",
      "----------\n",
      "train Loss: 1.3736 Acc: 0.5214\n",
      "val Loss: 1.8656 Acc: 0.5416\n",
      "Epoch 20/299\n",
      "----------\n",
      "train Loss: 1.3358 Acc: 0.5339\n",
      "val Loss: 1.2020 Acc: 0.6042\n",
      "Epoch 21/299\n",
      "----------\n",
      "train Loss: 1.2832 Acc: 0.5561\n",
      "val Loss: 1.2288 Acc: 0.5961\n",
      "Epoch 22/299\n",
      "----------\n",
      "train Loss: 1.2415 Acc: 0.5765\n",
      "val Loss: 1.2025 Acc: 0.5951\n",
      "Epoch 23/299\n",
      "----------\n",
      "train Loss: 1.2248 Acc: 0.5768\n",
      "val Loss: 1.0293 Acc: 0.6488\n",
      "Epoch 24/299\n",
      "----------\n",
      "train Loss: 1.1669 Acc: 0.6025\n",
      "val Loss: 0.9887 Acc: 0.6661\n",
      "Epoch 25/299\n",
      "----------\n",
      "train Loss: 1.1388 Acc: 0.6117\n",
      "val Loss: 1.0573 Acc: 0.6343\n",
      "Epoch 26/299\n",
      "----------\n",
      "train Loss: 1.0946 Acc: 0.6261\n",
      "val Loss: 1.0160 Acc: 0.6645\n",
      "Epoch 27/299\n",
      "----------\n",
      "train Loss: 1.0704 Acc: 0.6408\n",
      "val Loss: 0.9599 Acc: 0.6747\n",
      "Epoch 28/299\n",
      "----------\n",
      "train Loss: 1.0422 Acc: 0.6425\n",
      "val Loss: 0.9281 Acc: 0.6905\n",
      "Epoch 29/299\n",
      "----------\n",
      "train Loss: 0.9994 Acc: 0.6573\n",
      "val Loss: 0.8541 Acc: 0.7152\n",
      "Epoch 30/299\n",
      "----------\n",
      "train Loss: 0.9994 Acc: 0.6617\n",
      "val Loss: 0.9751 Acc: 0.6793\n",
      "Epoch 31/299\n",
      "----------\n",
      "train Loss: 0.9522 Acc: 0.6767\n",
      "val Loss: 0.8730 Acc: 0.7081\n",
      "Epoch 32/299\n",
      "----------\n",
      "train Loss: 0.9408 Acc: 0.6791\n",
      "val Loss: 0.8413 Acc: 0.7165\n",
      "Epoch 33/299\n",
      "----------\n",
      "train Loss: 0.9007 Acc: 0.6991\n",
      "val Loss: 0.7829 Acc: 0.7356\n",
      "Epoch 34/299\n",
      "----------\n",
      "train Loss: 0.9010 Acc: 0.6934\n",
      "val Loss: 0.7652 Acc: 0.7478\n",
      "Epoch 35/299\n",
      "----------\n",
      "train Loss: 0.8712 Acc: 0.7042\n",
      "val Loss: 0.8662 Acc: 0.7236\n",
      "Epoch 36/299\n",
      "----------\n",
      "train Loss: 0.8430 Acc: 0.7104\n",
      "val Loss: 0.7552 Acc: 0.7541\n",
      "Epoch 37/299\n",
      "----------\n",
      "train Loss: 0.8419 Acc: 0.7118\n",
      "val Loss: 0.7711 Acc: 0.7457\n",
      "Epoch 38/299\n",
      "----------\n",
      "train Loss: 0.8171 Acc: 0.7276\n",
      "val Loss: 0.7939 Acc: 0.7554\n",
      "Epoch 39/299\n",
      "----------\n",
      "train Loss: 0.7940 Acc: 0.7319\n",
      "val Loss: 0.8458 Acc: 0.7340\n",
      "Epoch 40/299\n",
      "----------\n",
      "train Loss: 0.7806 Acc: 0.7357\n",
      "val Loss: 0.7670 Acc: 0.7554\n",
      "Epoch 41/299\n",
      "----------\n",
      "train Loss: 0.7777 Acc: 0.7326\n",
      "val Loss: 0.6851 Acc: 0.7847\n",
      "Epoch 42/299\n",
      "----------\n",
      "train Loss: 0.7354 Acc: 0.7448\n",
      "val Loss: 0.7871 Acc: 0.7496\n",
      "Epoch 43/299\n",
      "----------\n",
      "train Loss: 0.7422 Acc: 0.7461\n",
      "val Loss: 0.6928 Acc: 0.7786\n",
      "Epoch 44/299\n",
      "----------\n",
      "train Loss: 0.7270 Acc: 0.7560\n",
      "val Loss: 0.7294 Acc: 0.7577\n",
      "Epoch 45/299\n",
      "----------\n",
      "train Loss: 0.7128 Acc: 0.7594\n",
      "val Loss: 0.7412 Acc: 0.7610\n",
      "Epoch 46/299\n",
      "----------\n",
      "train Loss: 0.6986 Acc: 0.7676\n",
      "val Loss: 0.7133 Acc: 0.7801\n",
      "Epoch 47/299\n",
      "----------\n",
      "train Loss: 0.7106 Acc: 0.7622\n",
      "val Loss: 0.7560 Acc: 0.7554\n",
      "Epoch 48/299\n",
      "----------\n",
      "train Loss: 0.6867 Acc: 0.7607\n",
      "val Loss: 0.7001 Acc: 0.7722\n",
      "Epoch 49/299\n",
      "----------\n",
      "train Loss: 0.6624 Acc: 0.7695\n",
      "val Loss: 0.6881 Acc: 0.7903\n",
      "Epoch 50/299\n",
      "----------\n",
      "train Loss: 0.6425 Acc: 0.7858\n",
      "val Loss: 0.6883 Acc: 0.7819\n",
      "Epoch 51/299\n",
      "----------\n",
      "train Loss: 0.6381 Acc: 0.7802\n",
      "val Loss: 0.6989 Acc: 0.7765\n",
      "Epoch 52/299\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.7833\n",
      "val Loss: 0.6754 Acc: 0.7852\n",
      "Epoch 53/299\n",
      "----------\n",
      "train Loss: 0.6154 Acc: 0.7947\n",
      "val Loss: 0.8471 Acc: 0.7483\n",
      "Epoch 54/299\n",
      "----------\n",
      "train Loss: 0.6268 Acc: 0.7884\n",
      "val Loss: 0.6725 Acc: 0.7839\n",
      "Epoch 55/299\n",
      "----------\n",
      "train Loss: 0.6318 Acc: 0.7887\n",
      "val Loss: 0.6648 Acc: 0.7977\n",
      "Epoch 56/299\n",
      "----------\n",
      "train Loss: 0.6068 Acc: 0.7959\n",
      "val Loss: 0.6738 Acc: 0.7982\n",
      "Epoch 57/299\n",
      "----------\n",
      "train Loss: 0.5882 Acc: 0.8047\n",
      "val Loss: 0.7601 Acc: 0.7748\n",
      "Epoch 58/299\n",
      "----------\n",
      "train Loss: 0.5731 Acc: 0.8080\n",
      "val Loss: 0.6484 Acc: 0.8005\n",
      "Epoch 59/299\n",
      "----------\n",
      "train Loss: 0.5730 Acc: 0.8024\n",
      "val Loss: 0.6768 Acc: 0.7961\n",
      "Epoch 60/299\n",
      "----------\n",
      "train Loss: 0.5974 Acc: 0.8013\n",
      "val Loss: 0.6563 Acc: 0.7949\n",
      "Epoch 61/299\n",
      "----------\n",
      "train Loss: 0.5792 Acc: 0.8017\n",
      "val Loss: 0.6664 Acc: 0.7910\n",
      "Epoch 62/299\n",
      "----------\n",
      "train Loss: 0.5764 Acc: 0.8016\n",
      "val Loss: 0.6967 Acc: 0.7837\n",
      "Epoch 63/299\n",
      "----------\n",
      "train Loss: 0.5507 Acc: 0.8152\n",
      "val Loss: 0.6840 Acc: 0.7954\n",
      "Epoch 64/299\n",
      "----------\n",
      "train Loss: 0.5523 Acc: 0.8115\n",
      "val Loss: 0.6809 Acc: 0.7982\n",
      "Epoch 65/299\n",
      "----------\n",
      "train Loss: 0.5492 Acc: 0.8178\n",
      "val Loss: 0.6831 Acc: 0.7870\n",
      "Epoch 66/299\n",
      "----------\n",
      "train Loss: 0.5445 Acc: 0.8152\n",
      "val Loss: 0.7075 Acc: 0.7926\n",
      "Epoch 67/299\n",
      "----------\n",
      "train Loss: 0.5082 Acc: 0.8296\n",
      "val Loss: 0.6768 Acc: 0.8012\n",
      "Epoch 68/299\n",
      "----------\n",
      "train Loss: 0.5169 Acc: 0.8258\n",
      "val Loss: 0.6373 Acc: 0.8066\n",
      "Epoch 69/299\n",
      "----------\n",
      "train Loss: 0.4999 Acc: 0.8301\n",
      "val Loss: 0.6387 Acc: 0.8150\n",
      "Epoch 70/299\n",
      "----------\n",
      "train Loss: 0.5004 Acc: 0.8312\n",
      "val Loss: 0.7400 Acc: 0.7933\n",
      "Epoch 71/299\n",
      "----------\n",
      "train Loss: 0.5018 Acc: 0.8279\n",
      "val Loss: 0.6481 Acc: 0.8015\n",
      "Epoch 72/299\n",
      "----------\n",
      "train Loss: 0.4918 Acc: 0.8353\n",
      "val Loss: 0.6656 Acc: 0.8053\n",
      "Epoch 73/299\n",
      "----------\n",
      "train Loss: 0.5059 Acc: 0.8257\n",
      "val Loss: 0.6198 Acc: 0.8104\n",
      "Epoch 74/299\n",
      "----------\n",
      "train Loss: 0.4950 Acc: 0.8349\n",
      "val Loss: 0.6380 Acc: 0.8198\n",
      "Epoch 75/299\n",
      "----------\n",
      "train Loss: 0.4726 Acc: 0.8392\n",
      "val Loss: 0.7156 Acc: 0.8033\n",
      "Epoch 76/299\n",
      "----------\n",
      "train Loss: 0.4773 Acc: 0.8403\n",
      "val Loss: 0.6488 Acc: 0.8175\n",
      "Epoch 77/299\n",
      "----------\n",
      "train Loss: 0.4550 Acc: 0.8506\n",
      "val Loss: 0.6834 Acc: 0.8002\n",
      "Epoch 78/299\n",
      "----------\n",
      "train Loss: 0.4682 Acc: 0.8412\n",
      "val Loss: 0.6565 Acc: 0.8058\n",
      "Epoch 79/299\n",
      "----------\n",
      "train Loss: 0.4745 Acc: 0.8438\n",
      "val Loss: 0.6565 Acc: 0.8145\n",
      "Epoch 80/299\n",
      "----------\n",
      "train Loss: 0.4579 Acc: 0.8458\n",
      "val Loss: 0.6863 Acc: 0.7959\n",
      "Epoch 81/299\n",
      "----------\n",
      "train Loss: 0.4648 Acc: 0.8450\n",
      "val Loss: 0.6342 Acc: 0.8145\n",
      "Epoch 82/299\n",
      "----------\n",
      "train Loss: 0.4477 Acc: 0.8506\n",
      "val Loss: 0.6730 Acc: 0.8071\n",
      "Epoch 83/299\n",
      "----------\n",
      "train Loss: 0.4381 Acc: 0.8514\n",
      "val Loss: 0.6564 Acc: 0.8147\n",
      "Epoch 84/299\n",
      "----------\n",
      "train Loss: 0.4397 Acc: 0.8592\n",
      "val Loss: 0.7505 Acc: 0.7941\n",
      "Epoch 85/299\n",
      "----------\n",
      "train Loss: 0.4296 Acc: 0.8588\n",
      "val Loss: 0.7146 Acc: 0.8071\n",
      "Epoch 86/299\n",
      "----------\n",
      "train Loss: 0.4364 Acc: 0.8556\n",
      "val Loss: 0.6088 Acc: 0.8152\n",
      "Epoch 87/299\n",
      "----------\n",
      "train Loss: 0.4254 Acc: 0.8561\n",
      "val Loss: 0.6941 Acc: 0.8073\n",
      "Epoch 88/299\n",
      "----------\n",
      "train Loss: 0.4472 Acc: 0.8516\n",
      "val Loss: 0.7238 Acc: 0.7908\n",
      "Epoch 89/299\n",
      "----------\n",
      "train Loss: 0.4155 Acc: 0.8596\n",
      "val Loss: 0.7479 Acc: 0.7977\n",
      "Epoch 90/299\n",
      "----------\n",
      "train Loss: 0.4232 Acc: 0.8595\n",
      "val Loss: 0.6410 Acc: 0.8239\n",
      "Epoch 91/299\n",
      "----------\n",
      "train Loss: 0.4089 Acc: 0.8628\n",
      "val Loss: 0.6721 Acc: 0.8129\n",
      "Epoch 92/299\n",
      "----------\n",
      "train Loss: 0.4157 Acc: 0.8627\n",
      "val Loss: 0.7413 Acc: 0.8005\n",
      "Epoch 93/299\n",
      "----------\n",
      "train Loss: 0.3961 Acc: 0.8663\n",
      "val Loss: 0.6846 Acc: 0.8257\n",
      "Epoch 94/299\n",
      "----------\n",
      "train Loss: 0.4108 Acc: 0.8663\n",
      "val Loss: 0.6668 Acc: 0.8178\n",
      "Epoch 95/299\n",
      "----------\n",
      "train Loss: 0.4141 Acc: 0.8619\n",
      "val Loss: 0.6719 Acc: 0.8043\n",
      "Epoch 96/299\n",
      "----------\n",
      "train Loss: 0.3893 Acc: 0.8721\n",
      "val Loss: 0.7186 Acc: 0.8030\n",
      "Epoch 97/299\n",
      "----------\n",
      "train Loss: 0.3965 Acc: 0.8665\n",
      "val Loss: 0.7140 Acc: 0.8048\n",
      "Epoch 98/299\n",
      "----------\n",
      "train Loss: 0.3893 Acc: 0.8684\n",
      "val Loss: 0.7106 Acc: 0.8030\n",
      "Epoch 99/299\n",
      "----------\n",
      "train Loss: 0.3974 Acc: 0.8675\n",
      "val Loss: 0.6314 Acc: 0.8259\n",
      "Epoch 100/299\n",
      "----------\n",
      "train Loss: 0.3747 Acc: 0.8752\n",
      "val Loss: 0.6706 Acc: 0.8152\n",
      "Epoch 101/299\n",
      "----------\n",
      "train Loss: 0.3708 Acc: 0.8776\n",
      "val Loss: 0.7048 Acc: 0.8190\n",
      "Epoch 102/299\n",
      "----------\n",
      "train Loss: 0.3718 Acc: 0.8749\n",
      "val Loss: 0.7356 Acc: 0.8145\n",
      "Epoch 103/299\n",
      "----------\n",
      "train Loss: 0.3682 Acc: 0.8787\n",
      "val Loss: 0.7388 Acc: 0.8106\n",
      "Epoch 104/299\n",
      "----------\n",
      "train Loss: 0.4023 Acc: 0.8696\n",
      "val Loss: 0.6693 Acc: 0.8218\n",
      "Epoch 105/299\n",
      "----------\n",
      "train Loss: 0.3717 Acc: 0.8758\n",
      "val Loss: 0.7329 Acc: 0.8111\n",
      "Epoch 106/299\n",
      "----------\n",
      "train Loss: 0.3786 Acc: 0.8730\n",
      "val Loss: 0.7325 Acc: 0.8175\n",
      "Epoch 107/299\n",
      "----------\n",
      "train Loss: 0.3679 Acc: 0.8768\n",
      "val Loss: 0.7032 Acc: 0.8119\n",
      "Epoch 108/299\n",
      "----------\n",
      "train Loss: 0.3853 Acc: 0.8745\n",
      "val Loss: 0.7404 Acc: 0.7992\n",
      "Epoch 109/299\n",
      "----------\n",
      "train Loss: 0.3778 Acc: 0.8739\n",
      "val Loss: 0.6744 Acc: 0.8137\n",
      "Epoch 110/299\n",
      "----------\n",
      "train Loss: 0.3649 Acc: 0.8758\n",
      "val Loss: 0.7181 Acc: 0.8155\n",
      "Epoch 111/299\n",
      "----------\n",
      "train Loss: 0.3579 Acc: 0.8817\n",
      "val Loss: 0.6468 Acc: 0.8264\n",
      "Epoch 112/299\n",
      "----------\n",
      "train Loss: 0.3425 Acc: 0.8827\n",
      "val Loss: 0.6859 Acc: 0.8218\n",
      "Epoch 113/299\n",
      "----------\n",
      "train Loss: 0.3724 Acc: 0.8767\n",
      "val Loss: 0.7410 Acc: 0.8027\n",
      "Epoch 114/299\n",
      "----------\n",
      "train Loss: 0.3604 Acc: 0.8801\n",
      "val Loss: 0.6506 Acc: 0.8195\n",
      "Epoch 115/299\n",
      "----------\n",
      "train Loss: 0.3471 Acc: 0.8858\n",
      "val Loss: 0.7308 Acc: 0.8145\n",
      "Epoch 116/299\n",
      "----------\n",
      "train Loss: 0.3335 Acc: 0.8892\n",
      "val Loss: 0.7373 Acc: 0.8180\n",
      "Epoch 117/299\n",
      "----------\n",
      "train Loss: 0.3545 Acc: 0.8840\n",
      "val Loss: 0.6871 Acc: 0.8295\n",
      "Epoch 118/299\n",
      "----------\n",
      "train Loss: 0.3426 Acc: 0.8853\n",
      "val Loss: 0.6487 Acc: 0.8290\n",
      "Epoch 119/299\n",
      "----------\n",
      "train Loss: 0.3291 Acc: 0.8923\n",
      "val Loss: 0.7567 Acc: 0.8160\n",
      "Epoch 120/299\n",
      "----------\n",
      "train Loss: 0.3333 Acc: 0.8880\n",
      "val Loss: 0.6927 Acc: 0.8216\n",
      "Epoch 121/299\n",
      "----------\n",
      "train Loss: 0.3345 Acc: 0.8853\n",
      "val Loss: 0.7593 Acc: 0.8058\n",
      "Epoch 122/299\n",
      "----------\n",
      "train Loss: 0.3430 Acc: 0.8878\n",
      "val Loss: 0.7184 Acc: 0.8083\n",
      "Epoch 123/299\n",
      "----------\n",
      "train Loss: 0.3352 Acc: 0.8901\n",
      "val Loss: 0.7309 Acc: 0.8236\n",
      "Epoch 124/299\n",
      "----------\n",
      "train Loss: 0.3337 Acc: 0.8863\n",
      "val Loss: 0.7307 Acc: 0.8050\n",
      "Epoch 125/299\n",
      "----------\n",
      "train Loss: 0.3524 Acc: 0.8809\n",
      "val Loss: 0.7738 Acc: 0.7999\n",
      "Epoch 126/299\n",
      "----------\n",
      "train Loss: 0.3212 Acc: 0.8975\n",
      "val Loss: 0.6821 Acc: 0.8173\n",
      "Epoch 127/299\n",
      "----------\n",
      "train Loss: 0.3208 Acc: 0.8937\n",
      "val Loss: 0.6744 Acc: 0.8305\n",
      "Epoch 128/299\n",
      "----------\n",
      "train Loss: 0.3241 Acc: 0.8968\n",
      "val Loss: 0.7350 Acc: 0.8175\n",
      "Epoch 129/299\n",
      "----------\n",
      "train Loss: 0.3195 Acc: 0.8902\n",
      "val Loss: 0.7023 Acc: 0.8218\n",
      "Epoch 130/299\n",
      "----------\n",
      "train Loss: 0.3269 Acc: 0.8909\n",
      "val Loss: 0.7193 Acc: 0.8180\n",
      "Epoch 131/299\n",
      "----------\n",
      "train Loss: 0.2978 Acc: 0.9055\n",
      "val Loss: 0.7893 Acc: 0.8073\n",
      "Epoch 132/299\n",
      "----------\n",
      "train Loss: 0.3369 Acc: 0.8886\n",
      "val Loss: 0.7353 Acc: 0.8213\n",
      "Epoch 133/299\n",
      "----------\n",
      "train Loss: 0.3348 Acc: 0.8891\n",
      "val Loss: 0.7237 Acc: 0.8236\n",
      "Epoch 134/299\n",
      "----------\n",
      "train Loss: 0.3154 Acc: 0.8961\n",
      "val Loss: 0.7453 Acc: 0.8251\n",
      "Epoch 135/299\n",
      "----------\n",
      "train Loss: 0.3189 Acc: 0.8966\n",
      "val Loss: 0.6898 Acc: 0.8267\n",
      "Epoch 136/299\n",
      "----------\n",
      "train Loss: 0.3107 Acc: 0.8936\n",
      "val Loss: 0.6721 Acc: 0.8384\n",
      "Epoch 137/299\n",
      "----------\n",
      "train Loss: 0.3221 Acc: 0.8946\n",
      "val Loss: 0.7101 Acc: 0.8241\n",
      "Epoch 138/299\n",
      "----------\n",
      "train Loss: 0.3055 Acc: 0.8972\n",
      "val Loss: 0.7108 Acc: 0.8246\n",
      "Epoch 139/299\n",
      "----------\n",
      "train Loss: 0.3339 Acc: 0.8882\n",
      "val Loss: 0.7114 Acc: 0.8259\n",
      "Epoch 140/299\n",
      "----------\n",
      "train Loss: 0.3119 Acc: 0.8954\n",
      "val Loss: 0.6936 Acc: 0.8165\n",
      "Epoch 141/299\n",
      "----------\n",
      "train Loss: 0.2947 Acc: 0.9011\n",
      "val Loss: 0.7734 Acc: 0.8305\n",
      "Epoch 142/299\n",
      "----------\n",
      "train Loss: 0.2932 Acc: 0.9017\n",
      "val Loss: 0.7493 Acc: 0.8358\n",
      "Epoch 143/299\n",
      "----------\n",
      "train Loss: 0.3179 Acc: 0.8970\n",
      "val Loss: 0.7204 Acc: 0.8162\n",
      "Epoch 144/299\n",
      "----------\n",
      "train Loss: 0.3127 Acc: 0.8999\n",
      "val Loss: 0.7509 Acc: 0.8226\n",
      "Epoch 145/299\n",
      "----------\n",
      "train Loss: 0.3040 Acc: 0.8996\n",
      "val Loss: 0.7500 Acc: 0.8137\n",
      "Epoch 146/299\n",
      "----------\n",
      "train Loss: 0.3027 Acc: 0.8999\n",
      "val Loss: 0.6700 Acc: 0.8302\n",
      "Epoch 147/299\n",
      "----------\n",
      "train Loss: 0.3144 Acc: 0.9007\n",
      "val Loss: 0.7594 Acc: 0.8104\n",
      "Epoch 148/299\n",
      "----------\n",
      "train Loss: 0.3125 Acc: 0.8968\n",
      "val Loss: 0.7785 Acc: 0.8122\n",
      "Epoch 149/299\n",
      "----------\n",
      "train Loss: 0.3005 Acc: 0.9025\n",
      "val Loss: 0.7800 Acc: 0.8119\n",
      "Epoch 150/299\n",
      "----------\n",
      "train Loss: 0.2918 Acc: 0.9032\n",
      "val Loss: 0.6826 Acc: 0.8310\n",
      "Epoch 151/299\n",
      "----------\n",
      "train Loss: 0.2890 Acc: 0.9050\n",
      "val Loss: 0.7355 Acc: 0.8218\n",
      "Epoch 152/299\n",
      "----------\n",
      "train Loss: 0.3028 Acc: 0.8991\n",
      "val Loss: 0.7365 Acc: 0.8251\n",
      "Epoch 153/299\n",
      "----------\n",
      "train Loss: 0.2879 Acc: 0.9055\n",
      "val Loss: 0.7924 Acc: 0.8124\n",
      "Epoch 154/299\n",
      "----------\n",
      "train Loss: 0.2909 Acc: 0.9036\n",
      "val Loss: 0.7419 Acc: 0.8096\n",
      "Epoch 155/299\n",
      "----------\n",
      "train Loss: 0.2897 Acc: 0.9019\n",
      "val Loss: 0.8393 Acc: 0.7971\n",
      "Epoch 156/299\n",
      "----------\n",
      "train Loss: 0.3023 Acc: 0.9011\n",
      "val Loss: 0.6938 Acc: 0.8206\n",
      "Epoch 157/299\n",
      "----------\n",
      "train Loss: 0.2834 Acc: 0.9075\n",
      "val Loss: 0.7195 Acc: 0.8254\n",
      "Epoch 158/299\n",
      "----------\n",
      "train Loss: 0.2793 Acc: 0.9065\n",
      "val Loss: 0.7808 Acc: 0.8089\n",
      "Epoch 159/299\n",
      "----------\n",
      "train Loss: 0.2922 Acc: 0.9046\n",
      "val Loss: 0.7714 Acc: 0.8117\n",
      "Epoch 160/299\n",
      "----------\n",
      "train Loss: 0.3016 Acc: 0.8984\n",
      "val Loss: 0.7777 Acc: 0.8249\n",
      "Epoch 161/299\n",
      "----------\n",
      "train Loss: 0.2847 Acc: 0.9058\n",
      "val Loss: 0.7569 Acc: 0.8216\n",
      "Epoch 162/299\n",
      "----------\n",
      "train Loss: 0.2836 Acc: 0.9057\n",
      "val Loss: 0.7439 Acc: 0.8287\n",
      "Epoch 163/299\n",
      "----------\n",
      "train Loss: 0.2759 Acc: 0.9102\n",
      "val Loss: 0.7573 Acc: 0.8188\n",
      "Epoch 164/299\n",
      "----------\n",
      "train Loss: 0.2821 Acc: 0.9084\n",
      "val Loss: 0.7926 Acc: 0.8104\n",
      "Epoch 165/299\n",
      "----------\n",
      "train Loss: 0.2708 Acc: 0.9101\n",
      "val Loss: 0.7262 Acc: 0.8226\n",
      "Epoch 166/299\n",
      "----------\n",
      "train Loss: 0.2864 Acc: 0.9065\n",
      "val Loss: 0.7079 Acc: 0.8267\n",
      "Epoch 167/299\n",
      "----------\n",
      "train Loss: 0.2728 Acc: 0.9121\n",
      "val Loss: 0.7459 Acc: 0.8185\n",
      "Epoch 168/299\n",
      "----------\n",
      "train Loss: 0.2996 Acc: 0.9005\n",
      "val Loss: 0.7076 Acc: 0.8274\n",
      "Epoch 169/299\n",
      "----------\n",
      "train Loss: 0.2712 Acc: 0.9085\n",
      "val Loss: 0.7935 Acc: 0.8091\n",
      "Epoch 170/299\n",
      "----------\n",
      "train Loss: 0.2766 Acc: 0.9087\n",
      "val Loss: 0.7738 Acc: 0.8188\n",
      "Epoch 171/299\n",
      "----------\n",
      "train Loss: 0.2708 Acc: 0.9104\n",
      "val Loss: 0.7931 Acc: 0.8229\n",
      "Epoch 172/299\n",
      "----------\n",
      "train Loss: 0.2680 Acc: 0.9119\n",
      "val Loss: 0.7436 Acc: 0.8246\n",
      "Epoch 173/299\n",
      "----------\n",
      "train Loss: 0.2642 Acc: 0.9120\n",
      "val Loss: 0.7076 Acc: 0.8353\n",
      "Epoch 174/299\n",
      "----------\n",
      "train Loss: 0.2774 Acc: 0.9075\n",
      "val Loss: 0.7649 Acc: 0.8257\n",
      "Epoch 175/299\n",
      "----------\n",
      "train Loss: 0.2743 Acc: 0.9086\n",
      "val Loss: 0.7504 Acc: 0.8213\n",
      "Epoch 176/299\n",
      "----------\n",
      "train Loss: 0.2672 Acc: 0.9124\n",
      "val Loss: 0.7627 Acc: 0.8251\n",
      "Epoch 177/299\n",
      "----------\n",
      "train Loss: 0.2661 Acc: 0.9143\n",
      "val Loss: 0.8110 Acc: 0.8173\n",
      "Epoch 178/299\n",
      "----------\n",
      "train Loss: 0.2721 Acc: 0.9098\n",
      "val Loss: 0.8081 Acc: 0.8155\n",
      "Epoch 179/299\n",
      "----------\n",
      "train Loss: 0.2581 Acc: 0.9153\n",
      "val Loss: 0.7308 Acc: 0.8292\n",
      "Epoch 180/299\n",
      "----------\n",
      "train Loss: 0.2621 Acc: 0.9146\n",
      "val Loss: 0.8179 Acc: 0.8208\n",
      "Epoch 181/299\n",
      "----------\n",
      "train Loss: 0.2639 Acc: 0.9127\n",
      "val Loss: 0.8730 Acc: 0.8073\n",
      "Epoch 182/299\n",
      "----------\n",
      "train Loss: 0.2686 Acc: 0.9107\n",
      "val Loss: 0.7615 Acc: 0.8277\n",
      "Epoch 183/299\n",
      "----------\n",
      "train Loss: 0.2605 Acc: 0.9155\n",
      "val Loss: 0.7633 Acc: 0.8264\n",
      "Epoch 184/299\n",
      "----------\n",
      "train Loss: 0.2620 Acc: 0.9124\n",
      "val Loss: 0.7653 Acc: 0.8287\n",
      "Epoch 185/299\n",
      "----------\n",
      "train Loss: 0.2501 Acc: 0.9190\n",
      "val Loss: 0.7633 Acc: 0.8272\n",
      "Epoch 186/299\n",
      "----------\n",
      "train Loss: 0.2734 Acc: 0.9105\n",
      "val Loss: 0.7817 Acc: 0.8239\n",
      "Epoch 187/299\n",
      "----------\n",
      "train Loss: 0.2697 Acc: 0.9091\n",
      "val Loss: 0.7914 Acc: 0.8244\n",
      "Epoch 188/299\n",
      "----------\n",
      "train Loss: 0.2591 Acc: 0.9126\n",
      "val Loss: 0.7746 Acc: 0.8244\n",
      "Epoch 189/299\n",
      "----------\n",
      "train Loss: 0.2443 Acc: 0.9191\n",
      "val Loss: 0.7197 Acc: 0.8279\n",
      "Epoch 190/299\n",
      "----------\n",
      "train Loss: 0.2677 Acc: 0.9155\n",
      "val Loss: 0.7326 Acc: 0.8264\n",
      "Epoch 191/299\n",
      "----------\n",
      "train Loss: 0.2578 Acc: 0.9177\n",
      "val Loss: 0.6773 Acc: 0.8297\n",
      "Epoch 192/299\n",
      "----------\n",
      "train Loss: 0.2278 Acc: 0.9239\n",
      "val Loss: 0.8587 Acc: 0.8282\n",
      "Epoch 193/299\n",
      "----------\n",
      "train Loss: 0.2712 Acc: 0.9091\n",
      "val Loss: 0.7993 Acc: 0.8231\n",
      "Epoch 194/299\n",
      "----------\n",
      "train Loss: 0.2634 Acc: 0.9143\n",
      "val Loss: 0.8160 Acc: 0.8241\n",
      "Epoch 195/299\n",
      "----------\n",
      "train Loss: 0.2550 Acc: 0.9155\n",
      "val Loss: 0.7583 Acc: 0.8315\n",
      "Epoch 196/299\n",
      "----------\n",
      "train Loss: 0.2589 Acc: 0.9176\n",
      "val Loss: 0.7761 Acc: 0.8277\n",
      "Epoch 197/299\n",
      "----------\n",
      "train Loss: 0.2512 Acc: 0.9182\n",
      "val Loss: 0.7596 Acc: 0.8287\n",
      "Epoch 198/299\n",
      "----------\n",
      "train Loss: 0.2430 Acc: 0.9223\n",
      "val Loss: 0.7542 Acc: 0.8287\n",
      "Epoch 199/299\n",
      "----------\n",
      "train Loss: 0.2466 Acc: 0.9200\n",
      "val Loss: 0.7584 Acc: 0.8356\n",
      "Epoch 200/299\n",
      "----------\n",
      "train Loss: 0.2455 Acc: 0.9169\n",
      "val Loss: 0.8242 Acc: 0.8178\n",
      "Epoch 201/299\n",
      "----------\n",
      "train Loss: 0.2553 Acc: 0.9170\n",
      "val Loss: 0.7367 Acc: 0.8236\n",
      "Epoch 202/299\n",
      "----------\n",
      "train Loss: 0.2408 Acc: 0.9199\n",
      "val Loss: 0.7870 Acc: 0.8295\n",
      "Epoch 203/299\n",
      "----------\n",
      "train Loss: 0.2542 Acc: 0.9145\n",
      "val Loss: 0.7668 Acc: 0.8313\n",
      "Epoch 204/299\n",
      "----------\n",
      "train Loss: 0.2477 Acc: 0.9183\n",
      "val Loss: 0.7627 Acc: 0.8236\n",
      "Epoch 205/299\n",
      "----------\n",
      "train Loss: 0.2466 Acc: 0.9184\n",
      "val Loss: 0.8099 Acc: 0.8274\n",
      "Epoch 206/299\n",
      "----------\n",
      "train Loss: 0.2556 Acc: 0.9124\n",
      "val Loss: 0.7960 Acc: 0.8231\n",
      "Epoch 207/299\n",
      "----------\n",
      "train Loss: 0.2419 Acc: 0.9230\n",
      "val Loss: 0.8375 Acc: 0.8162\n",
      "Epoch 208/299\n",
      "----------\n",
      "train Loss: 0.2499 Acc: 0.9184\n",
      "val Loss: 0.7994 Acc: 0.8305\n",
      "Epoch 209/299\n",
      "----------\n",
      "train Loss: 0.2412 Acc: 0.9167\n",
      "val Loss: 0.8418 Acc: 0.8175\n",
      "Epoch 210/299\n",
      "----------\n",
      "train Loss: 0.2430 Acc: 0.9218\n",
      "val Loss: 0.7536 Acc: 0.8335\n",
      "Epoch 211/299\n",
      "----------\n",
      "train Loss: 0.2435 Acc: 0.9201\n",
      "val Loss: 0.8117 Acc: 0.8346\n",
      "Epoch 212/299\n",
      "----------\n",
      "train Loss: 0.2323 Acc: 0.9257\n",
      "val Loss: 0.7609 Acc: 0.8267\n",
      "Epoch 213/299\n",
      "----------\n",
      "train Loss: 0.2410 Acc: 0.9203\n",
      "val Loss: 0.8021 Acc: 0.8361\n",
      "Epoch 214/299\n",
      "----------\n",
      "train Loss: 0.2532 Acc: 0.9194\n",
      "val Loss: 0.7391 Acc: 0.8325\n",
      "Epoch 215/299\n",
      "----------\n",
      "train Loss: 0.2367 Acc: 0.9230\n",
      "val Loss: 0.7390 Acc: 0.8259\n",
      "Epoch 216/299\n",
      "----------\n",
      "train Loss: 0.2545 Acc: 0.9167\n",
      "val Loss: 0.7709 Acc: 0.8257\n",
      "Epoch 217/299\n",
      "----------\n",
      "train Loss: 0.2193 Acc: 0.9283\n",
      "val Loss: 0.8012 Acc: 0.8346\n",
      "Epoch 218/299\n",
      "----------\n",
      "train Loss: 0.2454 Acc: 0.9204\n",
      "val Loss: 0.7368 Acc: 0.8335\n",
      "Epoch 219/299\n",
      "----------\n",
      "train Loss: 0.2235 Acc: 0.9266\n",
      "val Loss: 0.7091 Acc: 0.8404\n",
      "Epoch 220/299\n",
      "----------\n",
      "train Loss: 0.2411 Acc: 0.9204\n",
      "val Loss: 0.7288 Acc: 0.8348\n",
      "Epoch 221/299\n",
      "----------\n",
      "train Loss: 0.2096 Acc: 0.9323\n",
      "val Loss: 0.7903 Acc: 0.8305\n",
      "Epoch 222/299\n",
      "----------\n",
      "train Loss: 0.2454 Acc: 0.9160\n",
      "val Loss: 0.7555 Acc: 0.8310\n",
      "Epoch 223/299\n",
      "----------\n",
      "train Loss: 0.2453 Acc: 0.9221\n",
      "val Loss: 0.7672 Acc: 0.8330\n",
      "Epoch 224/299\n",
      "----------\n",
      "train Loss: 0.2320 Acc: 0.9240\n",
      "val Loss: 0.7544 Acc: 0.8397\n",
      "Epoch 225/299\n",
      "----------\n",
      "train Loss: 0.2598 Acc: 0.9181\n",
      "val Loss: 0.7623 Acc: 0.8297\n",
      "Epoch 226/299\n",
      "----------\n",
      "train Loss: 0.2439 Acc: 0.9214\n",
      "val Loss: 0.7798 Acc: 0.8330\n",
      "Epoch 227/299\n",
      "----------\n",
      "train Loss: 0.2378 Acc: 0.9210\n",
      "val Loss: 0.7210 Acc: 0.8318\n",
      "Epoch 228/299\n",
      "----------\n",
      "train Loss: 0.2215 Acc: 0.9269\n",
      "val Loss: 0.7388 Acc: 0.8371\n",
      "Epoch 229/299\n",
      "----------\n",
      "train Loss: 0.2246 Acc: 0.9268\n",
      "val Loss: 0.7626 Acc: 0.8297\n",
      "Epoch 230/299\n",
      "----------\n",
      "train Loss: 0.2186 Acc: 0.9279\n",
      "val Loss: 0.7621 Acc: 0.8399\n",
      "Epoch 231/299\n",
      "----------\n",
      "train Loss: 0.2350 Acc: 0.9237\n",
      "val Loss: 0.8166 Acc: 0.8279\n",
      "Epoch 232/299\n",
      "----------\n",
      "train Loss: 0.2179 Acc: 0.9269\n",
      "val Loss: 0.7948 Acc: 0.8353\n",
      "Epoch 233/299\n",
      "----------\n",
      "train Loss: 0.2410 Acc: 0.9203\n",
      "val Loss: 0.7820 Acc: 0.8267\n",
      "Epoch 234/299\n",
      "----------\n",
      "train Loss: 0.2207 Acc: 0.9278\n",
      "val Loss: 0.6893 Acc: 0.8425\n",
      "Epoch 235/299\n",
      "----------\n",
      "train Loss: 0.2229 Acc: 0.9264\n",
      "val Loss: 0.8169 Acc: 0.8300\n",
      "Epoch 236/299\n",
      "----------\n",
      "train Loss: 0.2287 Acc: 0.9242\n",
      "val Loss: 0.8150 Acc: 0.8231\n",
      "Epoch 237/299\n",
      "----------\n",
      "train Loss: 0.2274 Acc: 0.9245\n",
      "val Loss: 0.8034 Acc: 0.8198\n",
      "Epoch 238/299\n",
      "----------\n",
      "train Loss: 0.2279 Acc: 0.9250\n",
      "val Loss: 0.8450 Acc: 0.8236\n",
      "Epoch 239/299\n",
      "----------\n",
      "train Loss: 0.2313 Acc: 0.9241\n",
      "val Loss: 0.8040 Acc: 0.8229\n",
      "Epoch 240/299\n",
      "----------\n",
      "train Loss: 0.2319 Acc: 0.9250\n",
      "val Loss: 0.8526 Acc: 0.8277\n",
      "Epoch 241/299\n",
      "----------\n",
      "train Loss: 0.2440 Acc: 0.9188\n",
      "val Loss: 0.8115 Acc: 0.8282\n",
      "Epoch 242/299\n",
      "----------\n",
      "train Loss: 0.2333 Acc: 0.9212\n",
      "val Loss: 0.8551 Acc: 0.8234\n",
      "Epoch 243/299\n",
      "----------\n",
      "train Loss: 0.2251 Acc: 0.9249\n",
      "val Loss: 0.7740 Acc: 0.8343\n",
      "Epoch 244/299\n",
      "----------\n",
      "train Loss: 0.2203 Acc: 0.9286\n",
      "val Loss: 0.8308 Acc: 0.8272\n",
      "Epoch 245/299\n",
      "----------\n",
      "train Loss: 0.2199 Acc: 0.9285\n",
      "val Loss: 0.7717 Acc: 0.8323\n",
      "Epoch 246/299\n",
      "----------\n",
      "train Loss: 0.2290 Acc: 0.9234\n",
      "val Loss: 0.9013 Acc: 0.8239\n",
      "Epoch 247/299\n",
      "----------\n",
      "train Loss: 0.2287 Acc: 0.9214\n",
      "val Loss: 0.8557 Acc: 0.8201\n",
      "Epoch 248/299\n",
      "----------\n",
      "train Loss: 0.2261 Acc: 0.9279\n",
      "val Loss: 0.8086 Acc: 0.8218\n",
      "Epoch 249/299\n",
      "----------\n",
      "train Loss: 0.2117 Acc: 0.9304\n",
      "val Loss: 0.7746 Acc: 0.8351\n",
      "Epoch 250/299\n",
      "----------\n",
      "train Loss: 0.2195 Acc: 0.9284\n",
      "val Loss: 0.7988 Acc: 0.8305\n",
      "Epoch 251/299\n",
      "----------\n",
      "train Loss: 0.2312 Acc: 0.9198\n",
      "val Loss: 0.8102 Acc: 0.8254\n",
      "Epoch 252/299\n",
      "----------\n",
      "train Loss: 0.2282 Acc: 0.9240\n",
      "val Loss: 0.8796 Acc: 0.8269\n",
      "Epoch 253/299\n",
      "----------\n",
      "train Loss: 0.2104 Acc: 0.9317\n",
      "val Loss: 0.8650 Acc: 0.8208\n",
      "Epoch 254/299\n",
      "----------\n",
      "train Loss: 0.2119 Acc: 0.9294\n",
      "val Loss: 0.8784 Acc: 0.8081\n",
      "Epoch 255/299\n",
      "----------\n",
      "train Loss: 0.2241 Acc: 0.9254\n",
      "val Loss: 0.7979 Acc: 0.8328\n",
      "Epoch 256/299\n",
      "----------\n",
      "train Loss: 0.2280 Acc: 0.9271\n",
      "val Loss: 0.8838 Acc: 0.8183\n",
      "Epoch 257/299\n",
      "----------\n",
      "train Loss: 0.2241 Acc: 0.9274\n",
      "val Loss: 0.8867 Acc: 0.8109\n",
      "Epoch 258/299\n",
      "----------\n",
      "train Loss: 0.2208 Acc: 0.9285\n",
      "val Loss: 0.9037 Acc: 0.8236\n",
      "Epoch 259/299\n",
      "----------\n",
      "train Loss: 0.2207 Acc: 0.9288\n",
      "val Loss: 0.8320 Acc: 0.8307\n",
      "Epoch 260/299\n",
      "----------\n",
      "train Loss: 0.2173 Acc: 0.9290\n",
      "val Loss: 0.7909 Acc: 0.8269\n",
      "Epoch 261/299\n",
      "----------\n",
      "train Loss: 0.2126 Acc: 0.9313\n",
      "val Loss: 0.8199 Acc: 0.8348\n",
      "Epoch 262/299\n",
      "----------\n",
      "train Loss: 0.2214 Acc: 0.9250\n",
      "val Loss: 0.8370 Acc: 0.8282\n",
      "Epoch 263/299\n",
      "----------\n",
      "train Loss: 0.2090 Acc: 0.9320\n",
      "val Loss: 0.7812 Acc: 0.8307\n",
      "Epoch 264/299\n",
      "----------\n",
      "train Loss: 0.2107 Acc: 0.9337\n",
      "val Loss: 0.7929 Acc: 0.8361\n",
      "Epoch 265/299\n",
      "----------\n",
      "train Loss: 0.2037 Acc: 0.9333\n",
      "val Loss: 0.7823 Acc: 0.8262\n",
      "Epoch 266/299\n",
      "----------\n",
      "train Loss: 0.2116 Acc: 0.9334\n",
      "val Loss: 0.7706 Acc: 0.8287\n",
      "Epoch 267/299\n",
      "----------\n",
      "train Loss: 0.2178 Acc: 0.9263\n",
      "val Loss: 0.7596 Acc: 0.8335\n",
      "Epoch 268/299\n",
      "----------\n",
      "train Loss: 0.2050 Acc: 0.9346\n",
      "val Loss: 0.7372 Acc: 0.8343\n",
      "Epoch 269/299\n",
      "----------\n",
      "train Loss: 0.2191 Acc: 0.9268\n",
      "val Loss: 0.8269 Acc: 0.8254\n",
      "Epoch 270/299\n",
      "----------\n",
      "train Loss: 0.2204 Acc: 0.9240\n",
      "val Loss: 0.8157 Acc: 0.8269\n",
      "Epoch 271/299\n",
      "----------\n",
      "train Loss: 0.2247 Acc: 0.9283\n",
      "val Loss: 0.7449 Acc: 0.8470\n",
      "Epoch 272/299\n",
      "----------\n",
      "train Loss: 0.2093 Acc: 0.9339\n",
      "val Loss: 0.8307 Acc: 0.8229\n",
      "Epoch 273/299\n",
      "----------\n",
      "train Loss: 0.2188 Acc: 0.9265\n",
      "val Loss: 0.7413 Acc: 0.8356\n",
      "Epoch 274/299\n",
      "----------\n",
      "train Loss: 0.1939 Acc: 0.9368\n",
      "val Loss: 0.9493 Acc: 0.8190\n",
      "Epoch 275/299\n",
      "----------\n",
      "train Loss: 0.2048 Acc: 0.9316\n",
      "val Loss: 0.8235 Acc: 0.8236\n",
      "Epoch 276/299\n",
      "----------\n",
      "train Loss: 0.2168 Acc: 0.9280\n",
      "val Loss: 0.7732 Acc: 0.8297\n",
      "Epoch 277/299\n",
      "----------\n",
      "train Loss: 0.2096 Acc: 0.9303\n",
      "val Loss: 0.7746 Acc: 0.8333\n",
      "Epoch 278/299\n",
      "----------\n",
      "train Loss: 0.2040 Acc: 0.9316\n",
      "val Loss: 0.8149 Acc: 0.8333\n",
      "Epoch 279/299\n",
      "----------\n",
      "train Loss: 0.2208 Acc: 0.9270\n",
      "val Loss: 0.8566 Acc: 0.8269\n",
      "Epoch 280/299\n",
      "----------\n",
      "train Loss: 0.2202 Acc: 0.9265\n",
      "val Loss: 0.7575 Acc: 0.8356\n",
      "Epoch 281/299\n",
      "----------\n",
      "train Loss: 0.2027 Acc: 0.9333\n",
      "val Loss: 0.8403 Acc: 0.8341\n",
      "Epoch 282/299\n",
      "----------\n",
      "train Loss: 0.2044 Acc: 0.9319\n",
      "val Loss: 0.7798 Acc: 0.8323\n",
      "Epoch 283/299\n",
      "----------\n",
      "train Loss: 0.2000 Acc: 0.9326\n",
      "val Loss: 0.8923 Acc: 0.8274\n",
      "Epoch 284/299\n",
      "----------\n",
      "train Loss: 0.2051 Acc: 0.9296\n",
      "val Loss: 0.8444 Acc: 0.8292\n",
      "Epoch 285/299\n",
      "----------\n",
      "train Loss: 0.2091 Acc: 0.9326\n",
      "val Loss: 0.8535 Acc: 0.8295\n",
      "Epoch 286/299\n",
      "----------\n",
      "train Loss: 0.2166 Acc: 0.9284\n",
      "val Loss: 0.8805 Acc: 0.8206\n",
      "Epoch 287/299\n",
      "----------\n",
      "train Loss: 0.2123 Acc: 0.9309\n",
      "val Loss: 0.8568 Acc: 0.8229\n",
      "Epoch 288/299\n",
      "----------\n",
      "train Loss: 0.2185 Acc: 0.9289\n",
      "val Loss: 0.7677 Acc: 0.8402\n",
      "Epoch 289/299\n",
      "----------\n",
      "train Loss: 0.2020 Acc: 0.9323\n",
      "val Loss: 0.8889 Acc: 0.8272\n",
      "Epoch 290/299\n",
      "----------\n",
      "train Loss: 0.2141 Acc: 0.9278\n",
      "val Loss: 0.8204 Acc: 0.8285\n",
      "Epoch 291/299\n",
      "----------\n",
      "train Loss: 0.2087 Acc: 0.9307\n",
      "val Loss: 0.8549 Acc: 0.8285\n",
      "Epoch 292/299\n",
      "----------\n",
      "train Loss: 0.1976 Acc: 0.9355\n",
      "val Loss: 0.8167 Acc: 0.8333\n",
      "Epoch 293/299\n",
      "----------\n",
      "train Loss: 0.2152 Acc: 0.9288\n",
      "val Loss: 0.8353 Acc: 0.8246\n",
      "Epoch 294/299\n",
      "----------\n",
      "train Loss: 0.2083 Acc: 0.9324\n",
      "val Loss: 0.7850 Acc: 0.8348\n",
      "Epoch 295/299\n",
      "----------\n",
      "train Loss: 0.2149 Acc: 0.9273\n",
      "val Loss: 0.8078 Acc: 0.8300\n",
      "Epoch 296/299\n",
      "----------\n",
      "train Loss: 0.1784 Acc: 0.9414\n",
      "val Loss: 0.7893 Acc: 0.8379\n",
      "Epoch 297/299\n",
      "----------\n",
      "train Loss: 0.1994 Acc: 0.9339\n",
      "val Loss: 0.8435 Acc: 0.8267\n",
      "Epoch 298/299\n",
      "----------\n",
      "train Loss: 0.2090 Acc: 0.9321\n",
      "val Loss: 0.7901 Acc: 0.8236\n",
      "Epoch 299/299\n",
      "----------\n",
      "train Loss: 0.2081 Acc: 0.9312\n",
      "val Loss: 0.8568 Acc: 0.8178\n",
      "Training complete in 212m 13s\n",
      "Best val Acc: 0.847035\n"
     ]
    }
   ],
   "source": [
    "final_model = models.resnet34(pretrained=use_pretrained)\n",
    "num_ftrs = final_model.fc.in_features\n",
    "final_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "final_model = final_model.to(device)\n",
    "\n",
    "optimizer_ft = optim.Adam(final_model.parameters(), lr=0.003)\n",
    "final_model, hist = train_model(final_model, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55252d80-c149-49df-bab5-bb663d570991",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a8f2c4-0b43-4d40-b258-314469985ced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/299\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1153.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.3041 Acc: 0.1572\n",
      "val Loss: 2.1571 Acc: 0.1891\n",
      "Epoch 1/299\n",
      "----------\n",
      "train Loss: 2.1752 Acc: 0.1875\n",
      "val Loss: 2.0998 Acc: 0.2202\n",
      "Epoch 2/299\n",
      "----------\n",
      "train Loss: 2.1250 Acc: 0.2104\n",
      "val Loss: 2.0400 Acc: 0.2400\n",
      "Epoch 3/299\n",
      "----------\n",
      "train Loss: 2.0698 Acc: 0.2382\n",
      "val Loss: 1.9517 Acc: 0.2818\n",
      "Epoch 4/299\n",
      "----------\n",
      "train Loss: 2.0186 Acc: 0.2604\n",
      "val Loss: 1.8734 Acc: 0.3148\n",
      "Epoch 5/299\n",
      "----------\n",
      "train Loss: 1.9540 Acc: 0.2916\n",
      "val Loss: 1.8537 Acc: 0.3248\n",
      "Epoch 6/299\n",
      "----------\n",
      "train Loss: 1.8788 Acc: 0.3202\n",
      "val Loss: 1.7638 Acc: 0.3762\n",
      "Epoch 7/299\n",
      "----------\n",
      "train Loss: 1.8070 Acc: 0.3488\n",
      "val Loss: 1.6929 Acc: 0.3920\n",
      "Epoch 8/299\n",
      "----------\n",
      "train Loss: 1.7434 Acc: 0.3796\n",
      "val Loss: 1.6303 Acc: 0.4261\n",
      "Epoch 9/299\n",
      "----------\n",
      "train Loss: 1.6925 Acc: 0.4009\n",
      "val Loss: 1.5190 Acc: 0.4548\n",
      "Epoch 10/299\n",
      "----------\n",
      "train Loss: 1.6362 Acc: 0.4193\n",
      "val Loss: 1.4915 Acc: 0.4894\n",
      "Epoch 11/299\n",
      "----------\n",
      "train Loss: 1.5818 Acc: 0.4417\n",
      "val Loss: 1.4597 Acc: 0.4882\n",
      "Epoch 12/299\n",
      "----------\n",
      "train Loss: 1.5214 Acc: 0.4645\n",
      "val Loss: 1.3780 Acc: 0.5136\n",
      "Epoch 13/299\n",
      "----------\n",
      "train Loss: 1.4665 Acc: 0.4952\n",
      "val Loss: 1.4457 Acc: 0.5085\n",
      "Epoch 14/299\n",
      "----------\n",
      "train Loss: 1.4302 Acc: 0.5068\n",
      "val Loss: 1.2210 Acc: 0.5757\n",
      "Epoch 15/299\n",
      "----------\n",
      "train Loss: 1.3729 Acc: 0.5255\n",
      "val Loss: 1.1870 Acc: 0.5966\n",
      "Epoch 16/299\n",
      "----------\n",
      "train Loss: 1.3159 Acc: 0.5476\n",
      "val Loss: 1.1792 Acc: 0.5966\n",
      "Epoch 17/299\n",
      "----------\n",
      "train Loss: 1.2562 Acc: 0.5658\n",
      "val Loss: 1.0806 Acc: 0.6371\n",
      "Epoch 18/299\n",
      "----------\n",
      "train Loss: 1.2248 Acc: 0.5842\n",
      "val Loss: 1.2465 Acc: 0.5818\n",
      "Epoch 19/299\n",
      "----------\n",
      "train Loss: 1.1650 Acc: 0.5981\n",
      "val Loss: 0.9804 Acc: 0.6757\n",
      "Epoch 20/299\n",
      "----------\n",
      "train Loss: 1.1411 Acc: 0.6090\n",
      "val Loss: 1.2241 Acc: 0.6185\n",
      "Epoch 21/299\n",
      "----------\n",
      "train Loss: 1.0954 Acc: 0.6260\n",
      "val Loss: 0.9674 Acc: 0.6742\n",
      "Epoch 22/299\n",
      "----------\n",
      "train Loss: 1.0900 Acc: 0.6260\n",
      "val Loss: 0.9508 Acc: 0.6745\n",
      "Epoch 23/299\n",
      "----------\n",
      "train Loss: 1.0436 Acc: 0.6448\n",
      "val Loss: 0.9498 Acc: 0.7040\n",
      "Epoch 24/299\n",
      "----------\n",
      "train Loss: 1.0353 Acc: 0.6480\n",
      "val Loss: 0.8959 Acc: 0.6966\n",
      "Epoch 25/299\n",
      "----------\n",
      "train Loss: 0.9968 Acc: 0.6587\n",
      "val Loss: 0.8573 Acc: 0.7098\n",
      "Epoch 26/299\n",
      "----------\n",
      "train Loss: 0.9562 Acc: 0.6759\n",
      "val Loss: 0.9113 Acc: 0.7076\n",
      "Epoch 27/299\n",
      "----------\n",
      "train Loss: 0.9462 Acc: 0.6756\n",
      "val Loss: 0.8845 Acc: 0.7073\n",
      "Epoch 28/299\n",
      "----------\n",
      "train Loss: 0.9148 Acc: 0.6878\n",
      "val Loss: 0.8248 Acc: 0.7208\n",
      "Epoch 29/299\n",
      "----------\n",
      "train Loss: 0.8954 Acc: 0.6955\n",
      "val Loss: 0.7802 Acc: 0.7493\n",
      "Epoch 30/299\n",
      "----------\n",
      "train Loss: 0.8641 Acc: 0.7056\n",
      "val Loss: 0.8438 Acc: 0.7289\n",
      "Epoch 31/299\n",
      "----------\n",
      "train Loss: 0.8493 Acc: 0.7134\n",
      "val Loss: 0.7637 Acc: 0.7557\n",
      "Epoch 32/299\n",
      "----------\n",
      "train Loss: 0.8403 Acc: 0.7183\n",
      "val Loss: 0.7675 Acc: 0.7498\n",
      "Epoch 33/299\n",
      "----------\n",
      "train Loss: 0.8247 Acc: 0.7224\n",
      "val Loss: 0.7919 Acc: 0.7409\n",
      "Epoch 34/299\n",
      "----------\n",
      "train Loss: 0.8171 Acc: 0.7244\n",
      "val Loss: 0.8396 Acc: 0.7294\n",
      "Epoch 35/299\n",
      "----------\n",
      "train Loss: 0.7987 Acc: 0.7268\n",
      "val Loss: 0.7084 Acc: 0.7768\n",
      "Epoch 36/299\n",
      "----------\n",
      "train Loss: 0.7809 Acc: 0.7345\n",
      "val Loss: 0.7778 Acc: 0.7529\n",
      "Epoch 37/299\n",
      "----------\n",
      "train Loss: 0.7469 Acc: 0.7475\n",
      "val Loss: 0.7869 Acc: 0.7498\n",
      "Epoch 38/299\n",
      "----------\n",
      "train Loss: 0.7590 Acc: 0.7454\n",
      "val Loss: 0.6969 Acc: 0.7778\n",
      "Epoch 39/299\n",
      "----------\n",
      "train Loss: 0.7177 Acc: 0.7546\n",
      "val Loss: 0.7579 Acc: 0.7625\n",
      "Epoch 40/299\n",
      "----------\n",
      "train Loss: 0.7235 Acc: 0.7516\n",
      "val Loss: 0.7716 Acc: 0.7592\n",
      "Epoch 41/299\n",
      "----------\n",
      "train Loss: 0.7078 Acc: 0.7600\n",
      "val Loss: 0.7306 Acc: 0.7613\n",
      "Epoch 42/299\n",
      "----------\n",
      "train Loss: 0.6950 Acc: 0.7562\n",
      "val Loss: 0.7721 Acc: 0.7625\n",
      "Epoch 43/299\n",
      "----------\n",
      "train Loss: 0.6989 Acc: 0.7606\n",
      "val Loss: 0.7042 Acc: 0.7829\n",
      "Epoch 44/299\n",
      "----------\n",
      "train Loss: 0.6632 Acc: 0.7732\n",
      "val Loss: 0.7293 Acc: 0.7745\n",
      "Epoch 45/299\n",
      "----------\n",
      "train Loss: 0.6658 Acc: 0.7747\n",
      "val Loss: 0.7650 Acc: 0.7676\n",
      "Epoch 46/299\n",
      "----------\n",
      "train Loss: 0.6464 Acc: 0.7801\n",
      "val Loss: 0.6521 Acc: 0.7903\n",
      "Epoch 47/299\n",
      "----------\n",
      "train Loss: 0.6279 Acc: 0.7869\n",
      "val Loss: 0.7051 Acc: 0.7801\n",
      "Epoch 48/299\n",
      "----------\n",
      "train Loss: 0.6287 Acc: 0.7865\n",
      "val Loss: 0.6993 Acc: 0.7857\n",
      "Epoch 49/299\n",
      "----------\n",
      "train Loss: 0.6108 Acc: 0.7889\n",
      "val Loss: 0.7236 Acc: 0.7793\n",
      "Epoch 50/299\n",
      "----------\n",
      "train Loss: 0.6187 Acc: 0.7910\n",
      "val Loss: 0.7717 Acc: 0.7712\n",
      "Epoch 51/299\n",
      "----------\n",
      "train Loss: 0.6003 Acc: 0.8009\n",
      "val Loss: 0.6712 Acc: 0.7898\n",
      "Epoch 52/299\n",
      "----------\n",
      "train Loss: 0.5925 Acc: 0.8004\n",
      "val Loss: 0.7575 Acc: 0.7679\n",
      "Epoch 53/299\n",
      "----------\n",
      "train Loss: 0.5997 Acc: 0.7982\n",
      "val Loss: 0.6749 Acc: 0.7992\n",
      "Epoch 54/299\n",
      "----------\n",
      "train Loss: 0.5851 Acc: 0.8028\n",
      "val Loss: 0.6932 Acc: 0.7961\n",
      "Epoch 55/299\n",
      "----------\n",
      "train Loss: 0.5671 Acc: 0.8053\n",
      "val Loss: 0.6974 Acc: 0.7971\n",
      "Epoch 56/299\n",
      "----------\n",
      "train Loss: 0.5772 Acc: 0.8048\n",
      "val Loss: 0.6766 Acc: 0.7903\n",
      "Epoch 57/299\n",
      "----------\n",
      "train Loss: 0.5536 Acc: 0.8141\n",
      "val Loss: 0.7067 Acc: 0.7888\n",
      "Epoch 58/299\n",
      "----------\n",
      "train Loss: 0.5698 Acc: 0.8055\n",
      "val Loss: 0.7443 Acc: 0.7750\n",
      "Epoch 59/299\n",
      "----------\n",
      "train Loss: 0.5431 Acc: 0.8171\n",
      "val Loss: 0.6666 Acc: 0.7903\n",
      "Epoch 60/299\n",
      "----------\n",
      "train Loss: 0.5224 Acc: 0.8215\n",
      "val Loss: 0.6915 Acc: 0.7908\n",
      "Epoch 61/299\n",
      "----------\n",
      "train Loss: 0.5391 Acc: 0.8182\n",
      "val Loss: 0.6896 Acc: 0.8010\n",
      "Epoch 62/299\n",
      "----------\n",
      "train Loss: 0.5175 Acc: 0.8237\n",
      "val Loss: 0.6823 Acc: 0.8007\n",
      "Epoch 63/299\n",
      "----------\n",
      "train Loss: 0.5301 Acc: 0.8209\n",
      "val Loss: 0.6901 Acc: 0.7931\n",
      "Epoch 64/299\n",
      "----------\n",
      "train Loss: 0.5051 Acc: 0.8325\n",
      "val Loss: 0.6547 Acc: 0.8124\n",
      "Epoch 65/299\n",
      "----------\n",
      "train Loss: 0.4917 Acc: 0.8353\n",
      "val Loss: 0.7200 Acc: 0.7860\n",
      "Epoch 66/299\n",
      "----------\n",
      "train Loss: 0.4994 Acc: 0.8321\n",
      "val Loss: 0.6949 Acc: 0.8063\n",
      "Epoch 67/299\n",
      "----------\n",
      "train Loss: 0.5022 Acc: 0.8288\n",
      "val Loss: 0.6599 Acc: 0.8147\n",
      "Epoch 68/299\n",
      "----------\n",
      "train Loss: 0.4865 Acc: 0.8386\n",
      "val Loss: 0.7273 Acc: 0.7903\n",
      "Epoch 69/299\n",
      "----------\n",
      "train Loss: 0.4801 Acc: 0.8338\n",
      "val Loss: 0.6926 Acc: 0.8078\n",
      "Epoch 70/299\n",
      "----------\n",
      "train Loss: 0.4836 Acc: 0.8399\n",
      "val Loss: 0.6620 Acc: 0.8137\n",
      "Epoch 71/299\n",
      "----------\n",
      "train Loss: 0.4718 Acc: 0.8406\n",
      "val Loss: 0.7253 Acc: 0.8027\n",
      "Epoch 72/299\n",
      "----------\n",
      "train Loss: 0.4693 Acc: 0.8416\n",
      "val Loss: 0.7120 Acc: 0.8005\n",
      "Epoch 73/299\n",
      "----------\n",
      "train Loss: 0.4649 Acc: 0.8423\n",
      "val Loss: 0.7576 Acc: 0.7918\n",
      "Epoch 74/299\n",
      "----------\n",
      "train Loss: 0.4588 Acc: 0.8454\n",
      "val Loss: 0.7322 Acc: 0.8010\n",
      "Epoch 75/299\n",
      "----------\n",
      "train Loss: 0.4569 Acc: 0.8488\n",
      "val Loss: 0.6570 Acc: 0.8129\n",
      "Epoch 76/299\n",
      "----------\n",
      "train Loss: 0.4306 Acc: 0.8551\n",
      "val Loss: 0.7375 Acc: 0.8055\n",
      "Epoch 77/299\n",
      "----------\n",
      "train Loss: 0.4271 Acc: 0.8537\n",
      "val Loss: 0.7505 Acc: 0.8055\n",
      "Epoch 78/299\n",
      "----------\n",
      "train Loss: 0.4439 Acc: 0.8512\n",
      "val Loss: 0.8103 Acc: 0.7875\n",
      "Epoch 79/299\n",
      "----------\n",
      "train Loss: 0.4384 Acc: 0.8546\n",
      "val Loss: 0.7416 Acc: 0.8068\n",
      "Epoch 80/299\n",
      "----------\n",
      "train Loss: 0.4374 Acc: 0.8553\n",
      "val Loss: 0.7577 Acc: 0.8071\n",
      "Epoch 81/299\n",
      "----------\n",
      "train Loss: 0.4287 Acc: 0.8560\n",
      "val Loss: 0.7282 Acc: 0.7959\n",
      "Epoch 82/299\n",
      "----------\n",
      "train Loss: 0.4230 Acc: 0.8591\n",
      "val Loss: 0.7084 Acc: 0.8111\n",
      "Epoch 83/299\n",
      "----------\n",
      "train Loss: 0.4078 Acc: 0.8629\n",
      "val Loss: 0.7403 Acc: 0.8035\n",
      "Epoch 84/299\n",
      "----------\n",
      "train Loss: 0.4216 Acc: 0.8566\n",
      "val Loss: 0.6700 Acc: 0.8193\n",
      "Epoch 85/299\n",
      "----------\n",
      "train Loss: 0.4236 Acc: 0.8625\n",
      "val Loss: 0.6919 Acc: 0.8122\n",
      "Epoch 86/299\n",
      "----------\n",
      "train Loss: 0.4235 Acc: 0.8596\n",
      "val Loss: 0.6426 Acc: 0.8198\n",
      "Epoch 87/299\n",
      "----------\n",
      "train Loss: 0.4022 Acc: 0.8649\n",
      "val Loss: 0.7412 Acc: 0.8096\n",
      "Epoch 88/299\n",
      "----------\n",
      "train Loss: 0.4096 Acc: 0.8619\n",
      "val Loss: 0.7839 Acc: 0.7969\n",
      "Epoch 89/299\n",
      "----------\n",
      "train Loss: 0.4205 Acc: 0.8594\n",
      "val Loss: 0.7093 Acc: 0.8124\n",
      "Epoch 90/299\n",
      "----------\n",
      "train Loss: 0.3999 Acc: 0.8689\n",
      "val Loss: 0.6779 Acc: 0.8221\n",
      "Epoch 91/299\n",
      "----------\n",
      "train Loss: 0.3962 Acc: 0.8687\n",
      "val Loss: 0.6879 Acc: 0.8198\n",
      "Epoch 92/299\n",
      "----------\n",
      "train Loss: 0.4029 Acc: 0.8648\n",
      "val Loss: 0.7364 Acc: 0.8005\n",
      "Epoch 93/299\n",
      "----------\n",
      "train Loss: 0.3988 Acc: 0.8671\n",
      "val Loss: 0.6764 Acc: 0.8152\n",
      "Epoch 94/299\n",
      "----------\n",
      "train Loss: 0.3895 Acc: 0.8707\n",
      "val Loss: 0.7142 Acc: 0.8099\n",
      "Epoch 95/299\n",
      "----------\n",
      "train Loss: 0.3965 Acc: 0.8653\n",
      "val Loss: 0.7151 Acc: 0.7966\n",
      "Epoch 96/299\n",
      "----------\n",
      "train Loss: 0.3882 Acc: 0.8738\n",
      "val Loss: 0.7286 Acc: 0.7946\n",
      "Epoch 97/299\n",
      "----------\n",
      "train Loss: 0.3770 Acc: 0.8763\n",
      "val Loss: 0.7039 Acc: 0.8157\n",
      "Epoch 98/299\n",
      "----------\n",
      "train Loss: 0.3719 Acc: 0.8767\n",
      "val Loss: 0.7492 Acc: 0.8066\n",
      "Epoch 99/299\n",
      "----------\n",
      "train Loss: 0.3752 Acc: 0.8769\n",
      "val Loss: 0.7928 Acc: 0.8048\n",
      "Epoch 100/299\n",
      "----------\n",
      "train Loss: 0.3669 Acc: 0.8781\n",
      "val Loss: 0.6836 Acc: 0.8157\n",
      "Epoch 101/299\n",
      "----------\n",
      "train Loss: 0.3794 Acc: 0.8751\n",
      "val Loss: 0.7466 Acc: 0.8086\n",
      "Epoch 102/299\n",
      "----------\n",
      "train Loss: 0.3684 Acc: 0.8769\n",
      "val Loss: 0.7395 Acc: 0.8086\n",
      "Epoch 103/299\n",
      "----------\n",
      "train Loss: 0.3617 Acc: 0.8827\n",
      "val Loss: 0.7573 Acc: 0.8157\n",
      "Epoch 104/299\n",
      "----------\n",
      "train Loss: 0.3610 Acc: 0.8804\n",
      "val Loss: 0.7016 Acc: 0.8249\n",
      "Epoch 105/299\n",
      "----------\n",
      "train Loss: 0.3553 Acc: 0.8832\n",
      "val Loss: 0.7538 Acc: 0.8129\n",
      "Epoch 106/299\n",
      "----------\n",
      "train Loss: 0.3548 Acc: 0.8861\n",
      "val Loss: 0.8192 Acc: 0.8109\n",
      "Epoch 107/299\n",
      "----------\n",
      "train Loss: 0.3741 Acc: 0.8783\n",
      "val Loss: 0.7280 Acc: 0.8229\n",
      "Epoch 108/299\n",
      "----------\n",
      "train Loss: 0.3445 Acc: 0.8857\n",
      "val Loss: 0.7778 Acc: 0.8030\n",
      "Epoch 109/299\n",
      "----------\n",
      "train Loss: 0.3398 Acc: 0.8896\n",
      "val Loss: 0.7683 Acc: 0.8129\n",
      "Epoch 110/299\n",
      "----------\n",
      "train Loss: 0.3552 Acc: 0.8810\n",
      "val Loss: 0.6995 Acc: 0.8290\n",
      "Epoch 111/299\n",
      "----------\n",
      "train Loss: 0.3431 Acc: 0.8870\n",
      "val Loss: 0.8632 Acc: 0.7969\n",
      "Epoch 112/299\n",
      "----------\n",
      "train Loss: 0.3276 Acc: 0.8903\n",
      "val Loss: 0.7239 Acc: 0.8119\n",
      "Epoch 113/299\n",
      "----------\n",
      "train Loss: 0.3478 Acc: 0.8878\n",
      "val Loss: 0.8586 Acc: 0.7954\n",
      "Epoch 114/299\n",
      "----------\n",
      "train Loss: 0.3534 Acc: 0.8832\n",
      "val Loss: 0.7261 Acc: 0.8134\n",
      "Epoch 115/299\n",
      "----------\n",
      "train Loss: 0.3381 Acc: 0.8899\n",
      "val Loss: 0.7420 Acc: 0.8173\n",
      "Epoch 116/299\n",
      "----------\n",
      "train Loss: 0.3312 Acc: 0.8915\n",
      "val Loss: 0.7842 Acc: 0.8180\n",
      "Epoch 117/299\n",
      "----------\n",
      "train Loss: 0.3434 Acc: 0.8841\n",
      "val Loss: 0.7253 Acc: 0.8147\n",
      "Epoch 118/299\n",
      "----------\n",
      "train Loss: 0.3259 Acc: 0.8914\n",
      "val Loss: 0.7394 Acc: 0.8027\n",
      "Epoch 119/299\n",
      "----------\n",
      "train Loss: 0.3289 Acc: 0.8896\n",
      "val Loss: 0.7645 Acc: 0.8114\n",
      "Epoch 120/299\n",
      "----------\n",
      "train Loss: 0.3363 Acc: 0.8893\n",
      "val Loss: 0.7783 Acc: 0.8119\n",
      "Epoch 121/299\n",
      "----------\n",
      "train Loss: 0.3217 Acc: 0.8911\n",
      "val Loss: 0.7676 Acc: 0.8063\n",
      "Epoch 122/299\n",
      "----------\n",
      "train Loss: 0.3374 Acc: 0.8850\n",
      "val Loss: 0.7512 Acc: 0.8096\n",
      "Epoch 123/299\n",
      "----------\n",
      "train Loss: 0.3345 Acc: 0.8910\n",
      "val Loss: 0.7067 Acc: 0.8203\n",
      "Epoch 124/299\n",
      "----------\n",
      "train Loss: 0.3251 Acc: 0.8916\n",
      "val Loss: 0.8060 Acc: 0.8045\n",
      "Epoch 125/299\n",
      "----------\n",
      "train Loss: 0.3125 Acc: 0.8962\n",
      "val Loss: 0.7569 Acc: 0.8193\n",
      "Epoch 126/299\n",
      "----------\n",
      "train Loss: 0.3147 Acc: 0.8951\n",
      "val Loss: 0.7459 Acc: 0.8206\n",
      "Epoch 127/299\n",
      "----------\n",
      "train Loss: 0.3156 Acc: 0.8961\n",
      "val Loss: 0.7789 Acc: 0.8165\n",
      "Epoch 128/299\n",
      "----------\n",
      "train Loss: 0.3142 Acc: 0.8935\n",
      "val Loss: 0.7477 Acc: 0.8193\n",
      "Epoch 129/299\n",
      "----------\n",
      "train Loss: 0.3042 Acc: 0.9007\n",
      "val Loss: 0.7904 Acc: 0.8068\n",
      "Epoch 130/299\n",
      "----------\n",
      "train Loss: 0.3408 Acc: 0.8886\n",
      "val Loss: 0.8011 Acc: 0.8127\n",
      "Epoch 131/299\n",
      "----------\n",
      "train Loss: 0.3113 Acc: 0.8967\n",
      "val Loss: 0.8540 Acc: 0.8050\n",
      "Epoch 132/299\n",
      "----------\n",
      "train Loss: 0.3213 Acc: 0.8910\n",
      "val Loss: 0.7501 Acc: 0.8058\n",
      "Epoch 133/299\n",
      "----------\n",
      "train Loss: 0.2924 Acc: 0.9047\n",
      "val Loss: 0.8428 Acc: 0.8010\n",
      "Epoch 134/299\n",
      "----------\n",
      "train Loss: 0.3127 Acc: 0.8973\n",
      "val Loss: 0.7109 Acc: 0.8246\n",
      "Epoch 135/299\n",
      "----------\n",
      "train Loss: 0.2921 Acc: 0.9045\n",
      "val Loss: 0.7871 Acc: 0.8180\n",
      "Epoch 136/299\n",
      "----------\n",
      "train Loss: 0.2869 Acc: 0.9030\n",
      "val Loss: 0.7412 Acc: 0.8249\n",
      "Epoch 137/299\n",
      "----------\n",
      "train Loss: 0.3018 Acc: 0.9024\n",
      "val Loss: 0.7144 Acc: 0.8208\n",
      "Epoch 138/299\n",
      "----------\n",
      "train Loss: 0.3002 Acc: 0.9016\n",
      "val Loss: 0.7519 Acc: 0.8328\n",
      "Epoch 139/299\n",
      "----------\n",
      "train Loss: 0.3075 Acc: 0.8964\n",
      "val Loss: 0.8113 Acc: 0.8083\n",
      "Epoch 140/299\n",
      "----------\n",
      "train Loss: 0.3164 Acc: 0.8982\n",
      "val Loss: 0.8263 Acc: 0.8053\n",
      "Epoch 141/299\n",
      "----------\n",
      "train Loss: 0.2995 Acc: 0.9006\n",
      "val Loss: 0.7515 Acc: 0.8178\n",
      "Epoch 142/299\n",
      "----------\n",
      "train Loss: 0.3075 Acc: 0.8985\n",
      "val Loss: 0.7272 Acc: 0.8167\n",
      "Epoch 143/299\n",
      "----------\n",
      "train Loss: 0.2914 Acc: 0.9026\n",
      "val Loss: 0.8500 Acc: 0.8089\n",
      "Epoch 144/299\n",
      "----------\n",
      "train Loss: 0.2934 Acc: 0.9056\n",
      "val Loss: 0.7523 Acc: 0.8129\n",
      "Epoch 145/299\n",
      "----------\n",
      "train Loss: 0.2909 Acc: 0.9022\n",
      "val Loss: 0.7845 Acc: 0.8208\n",
      "Epoch 146/299\n",
      "----------\n",
      "train Loss: 0.2946 Acc: 0.9002\n",
      "val Loss: 0.7347 Acc: 0.8157\n",
      "Epoch 147/299\n",
      "----------\n",
      "train Loss: 0.2973 Acc: 0.9017\n",
      "val Loss: 0.7518 Acc: 0.8127\n",
      "Epoch 148/299\n",
      "----------\n",
      "train Loss: 0.2745 Acc: 0.9099\n",
      "val Loss: 0.7637 Acc: 0.8206\n",
      "Epoch 149/299\n",
      "----------\n",
      "train Loss: 0.2849 Acc: 0.9037\n",
      "val Loss: 0.8697 Acc: 0.8068\n",
      "Epoch 150/299\n",
      "----------\n",
      "train Loss: 0.2914 Acc: 0.9020\n",
      "val Loss: 0.8292 Acc: 0.8030\n",
      "Epoch 151/299\n",
      "----------\n",
      "train Loss: 0.2798 Acc: 0.9056\n",
      "val Loss: 0.8058 Acc: 0.8096\n",
      "Epoch 152/299\n",
      "----------\n",
      "train Loss: 0.2886 Acc: 0.9091\n",
      "val Loss: 0.7580 Acc: 0.8183\n",
      "Epoch 153/299\n",
      "----------\n",
      "train Loss: 0.2950 Acc: 0.9030\n",
      "val Loss: 0.7450 Acc: 0.8236\n",
      "Epoch 154/299\n",
      "----------\n",
      "train Loss: 0.2810 Acc: 0.9088\n",
      "val Loss: 0.7575 Acc: 0.8178\n",
      "Epoch 155/299\n",
      "----------\n",
      "train Loss: 0.2949 Acc: 0.9056\n",
      "val Loss: 0.7672 Acc: 0.8157\n",
      "Epoch 156/299\n",
      "----------\n",
      "train Loss: 0.2687 Acc: 0.9105\n",
      "val Loss: 0.8449 Acc: 0.8117\n",
      "Epoch 157/299\n",
      "----------\n",
      "train Loss: 0.2764 Acc: 0.9118\n",
      "val Loss: 0.7630 Acc: 0.8193\n",
      "Epoch 158/299\n",
      "----------\n",
      "train Loss: 0.2836 Acc: 0.9061\n",
      "val Loss: 0.7967 Acc: 0.8193\n",
      "Epoch 159/299\n",
      "----------\n",
      "train Loss: 0.2754 Acc: 0.9105\n",
      "val Loss: 0.7445 Acc: 0.8272\n",
      "Epoch 160/299\n",
      "----------\n",
      "train Loss: 0.2636 Acc: 0.9132\n",
      "val Loss: 0.7468 Acc: 0.8264\n",
      "Epoch 161/299\n",
      "----------\n",
      "train Loss: 0.2770 Acc: 0.9107\n",
      "val Loss: 0.8273 Acc: 0.8178\n",
      "Epoch 162/299\n",
      "----------\n",
      "train Loss: 0.2763 Acc: 0.9093\n",
      "val Loss: 0.7310 Acc: 0.8282\n",
      "Epoch 163/299\n",
      "----------\n",
      "train Loss: 0.2808 Acc: 0.9086\n",
      "val Loss: 0.8041 Acc: 0.8091\n",
      "Epoch 164/299\n",
      "----------\n",
      "train Loss: 0.2673 Acc: 0.9109\n",
      "val Loss: 0.7244 Acc: 0.8223\n",
      "Epoch 165/299\n",
      "----------\n",
      "train Loss: 0.2781 Acc: 0.9094\n",
      "val Loss: 0.7702 Acc: 0.8142\n",
      "Epoch 166/299\n",
      "----------\n",
      "train Loss: 0.2686 Acc: 0.9120\n",
      "val Loss: 0.8357 Acc: 0.8096\n",
      "Epoch 167/299\n",
      "----------\n",
      "train Loss: 0.2679 Acc: 0.9114\n",
      "val Loss: 0.8148 Acc: 0.8162\n",
      "Epoch 168/299\n",
      "----------\n",
      "train Loss: 0.2737 Acc: 0.9143\n",
      "val Loss: 0.7404 Acc: 0.8269\n",
      "Epoch 169/299\n",
      "----------\n",
      "train Loss: 0.2673 Acc: 0.9121\n",
      "val Loss: 0.7932 Acc: 0.8073\n",
      "Epoch 170/299\n",
      "----------\n",
      "train Loss: 0.2698 Acc: 0.9106\n",
      "val Loss: 0.7847 Acc: 0.8073\n",
      "Epoch 171/299\n",
      "----------\n",
      "train Loss: 0.2612 Acc: 0.9147\n",
      "val Loss: 0.7486 Acc: 0.8257\n",
      "Epoch 172/299\n",
      "----------\n",
      "train Loss: 0.2537 Acc: 0.9189\n",
      "val Loss: 0.7914 Acc: 0.8193\n",
      "Epoch 173/299\n",
      "----------\n",
      "train Loss: 0.2681 Acc: 0.9128\n",
      "val Loss: 0.8549 Acc: 0.8081\n",
      "Epoch 174/299\n",
      "----------\n",
      "train Loss: 0.2645 Acc: 0.9165\n",
      "val Loss: 0.7965 Acc: 0.8180\n",
      "Epoch 175/299\n",
      "----------\n",
      "train Loss: 0.2529 Acc: 0.9152\n",
      "val Loss: 0.9205 Acc: 0.7992\n",
      "Epoch 176/299\n",
      "----------\n",
      "train Loss: 0.2529 Acc: 0.9166\n",
      "val Loss: 0.8561 Acc: 0.8030\n",
      "Epoch 177/299\n",
      "----------\n",
      "train Loss: 0.2559 Acc: 0.9176\n",
      "val Loss: 0.7979 Acc: 0.8188\n",
      "Epoch 178/299\n",
      "----------\n",
      "train Loss: 0.2540 Acc: 0.9165\n",
      "val Loss: 0.8270 Acc: 0.8160\n",
      "Epoch 179/299\n",
      "----------\n",
      "train Loss: 0.2699 Acc: 0.9135\n",
      "val Loss: 0.7744 Acc: 0.8157\n",
      "Epoch 180/299\n",
      "----------\n",
      "train Loss: 0.2566 Acc: 0.9137\n",
      "val Loss: 0.8031 Acc: 0.8229\n",
      "Epoch 181/299\n",
      "----------\n",
      "train Loss: 0.2626 Acc: 0.9118\n",
      "val Loss: 0.7851 Acc: 0.8162\n",
      "Epoch 182/299\n",
      "----------\n",
      "train Loss: 0.2490 Acc: 0.9184\n",
      "val Loss: 0.7726 Acc: 0.8193\n",
      "Epoch 183/299\n",
      "----------\n",
      "train Loss: 0.2690 Acc: 0.9119\n",
      "val Loss: 0.8451 Acc: 0.8167\n",
      "Epoch 184/299\n",
      "----------\n",
      "train Loss: 0.2552 Acc: 0.9173\n",
      "val Loss: 0.8081 Acc: 0.8279\n",
      "Epoch 185/299\n",
      "----------\n",
      "train Loss: 0.2535 Acc: 0.9163\n",
      "val Loss: 0.8178 Acc: 0.8315\n",
      "Epoch 186/299\n",
      "----------\n",
      "train Loss: 0.2561 Acc: 0.9149\n",
      "val Loss: 0.8729 Acc: 0.8071\n",
      "Epoch 187/299\n",
      "----------\n",
      "train Loss: 0.2700 Acc: 0.9095\n",
      "val Loss: 0.8484 Acc: 0.8076\n",
      "Epoch 188/299\n",
      "----------\n",
      "train Loss: 0.2583 Acc: 0.9115\n",
      "val Loss: 0.8412 Acc: 0.8165\n",
      "Epoch 189/299\n",
      "----------\n",
      "train Loss: 0.2428 Acc: 0.9201\n",
      "val Loss: 0.8143 Acc: 0.8234\n",
      "Epoch 190/299\n",
      "----------\n",
      "train Loss: 0.2571 Acc: 0.9157\n",
      "val Loss: 0.7691 Acc: 0.8277\n",
      "Epoch 191/299\n",
      "----------\n",
      "train Loss: 0.2510 Acc: 0.9194\n",
      "val Loss: 0.7849 Acc: 0.8109\n",
      "Epoch 192/299\n",
      "----------\n",
      "train Loss: 0.2497 Acc: 0.9157\n",
      "val Loss: 0.8351 Acc: 0.8206\n",
      "Epoch 193/299\n",
      "----------\n",
      "train Loss: 0.2420 Acc: 0.9207\n",
      "val Loss: 0.7821 Acc: 0.8274\n",
      "Epoch 194/299\n",
      "----------\n",
      "train Loss: 0.2487 Acc: 0.9173\n",
      "val Loss: 0.8028 Acc: 0.8234\n",
      "Epoch 195/299\n",
      "----------\n",
      "train Loss: 0.2369 Acc: 0.9217\n",
      "val Loss: 0.7998 Acc: 0.8180\n",
      "Epoch 196/299\n",
      "----------\n",
      "train Loss: 0.2472 Acc: 0.9176\n",
      "val Loss: 0.7557 Acc: 0.8315\n",
      "Epoch 197/299\n",
      "----------\n",
      "train Loss: 0.2340 Acc: 0.9193\n",
      "val Loss: 0.7731 Acc: 0.8302\n",
      "Epoch 198/299\n",
      "----------\n",
      "train Loss: 0.2573 Acc: 0.9169\n",
      "val Loss: 0.8334 Acc: 0.8173\n",
      "Epoch 199/299\n",
      "----------\n",
      "train Loss: 0.2469 Acc: 0.9199\n",
      "val Loss: 0.8236 Acc: 0.8180\n",
      "Epoch 200/299\n",
      "----------\n",
      "train Loss: 0.2406 Acc: 0.9227\n",
      "val Loss: 0.8415 Acc: 0.8254\n",
      "Epoch 201/299\n",
      "----------\n",
      "train Loss: 0.2337 Acc: 0.9234\n",
      "val Loss: 0.8011 Acc: 0.8211\n",
      "Epoch 202/299\n",
      "----------\n",
      "train Loss: 0.2557 Acc: 0.9149\n",
      "val Loss: 0.7233 Acc: 0.8325\n",
      "Epoch 203/299\n",
      "----------\n",
      "train Loss: 0.2387 Acc: 0.9201\n",
      "val Loss: 0.8347 Acc: 0.8231\n",
      "Epoch 204/299\n",
      "----------\n",
      "train Loss: 0.2415 Acc: 0.9199\n",
      "val Loss: 0.8436 Acc: 0.8244\n",
      "Epoch 205/299\n",
      "----------\n",
      "train Loss: 0.2385 Acc: 0.9211\n",
      "val Loss: 0.8057 Acc: 0.8292\n",
      "Epoch 206/299\n",
      "----------\n",
      "train Loss: 0.2354 Acc: 0.9200\n",
      "val Loss: 0.8590 Acc: 0.8083\n",
      "Epoch 207/299\n",
      "----------\n",
      "train Loss: 0.2416 Acc: 0.9204\n",
      "val Loss: 0.8269 Acc: 0.8167\n",
      "Epoch 208/299\n",
      "----------\n",
      "train Loss: 0.2446 Acc: 0.9182\n",
      "val Loss: 0.8543 Acc: 0.8302\n",
      "Epoch 209/299\n",
      "----------\n",
      "train Loss: 0.2261 Acc: 0.9258\n",
      "val Loss: 0.7835 Acc: 0.8234\n",
      "Epoch 210/299\n",
      "----------\n",
      "train Loss: 0.2322 Acc: 0.9243\n",
      "val Loss: 0.7807 Acc: 0.8231\n",
      "Epoch 211/299\n",
      "----------\n",
      "train Loss: 0.2461 Acc: 0.9176\n",
      "val Loss: 0.7847 Acc: 0.8241\n",
      "Epoch 212/299\n",
      "----------\n",
      "train Loss: 0.2299 Acc: 0.9239\n",
      "val Loss: 0.8388 Acc: 0.8236\n",
      "Epoch 213/299\n",
      "----------\n",
      "train Loss: 0.2475 Acc: 0.9190\n",
      "val Loss: 0.8606 Acc: 0.8236\n",
      "Epoch 214/299\n",
      "----------\n",
      "train Loss: 0.2268 Acc: 0.9238\n",
      "val Loss: 0.8805 Acc: 0.8129\n",
      "Epoch 215/299\n",
      "----------\n",
      "train Loss: 0.2433 Acc: 0.9213\n",
      "val Loss: 0.7804 Acc: 0.8244\n",
      "Epoch 216/299\n",
      "----------\n",
      "train Loss: 0.2206 Acc: 0.9275\n",
      "val Loss: 0.8881 Acc: 0.8033\n",
      "Epoch 217/299\n",
      "----------\n",
      "train Loss: 0.2300 Acc: 0.9262\n",
      "val Loss: 0.8167 Acc: 0.8269\n",
      "Epoch 218/299\n",
      "----------\n",
      "train Loss: 0.2213 Acc: 0.9295\n",
      "val Loss: 0.8156 Acc: 0.8173\n",
      "Epoch 219/299\n",
      "----------\n",
      "train Loss: 0.2266 Acc: 0.9240\n",
      "val Loss: 0.8655 Acc: 0.8259\n",
      "Epoch 220/299\n",
      "----------\n",
      "train Loss: 0.2284 Acc: 0.9253\n",
      "val Loss: 0.8319 Acc: 0.8203\n",
      "Epoch 221/299\n",
      "----------\n",
      "train Loss: 0.2425 Acc: 0.9162\n",
      "val Loss: 0.7856 Acc: 0.8203\n",
      "Epoch 222/299\n",
      "----------\n",
      "train Loss: 0.2323 Acc: 0.9225\n",
      "val Loss: 0.9169 Acc: 0.8083\n",
      "Epoch 223/299\n",
      "----------\n",
      "train Loss: 0.2464 Acc: 0.9179\n",
      "val Loss: 0.8218 Acc: 0.8229\n",
      "Epoch 224/299\n",
      "----------\n",
      "train Loss: 0.2331 Acc: 0.9233\n",
      "val Loss: 0.7889 Acc: 0.8348\n",
      "Epoch 225/299\n",
      "----------\n",
      "train Loss: 0.2170 Acc: 0.9314\n",
      "val Loss: 0.9107 Acc: 0.8170\n",
      "Epoch 226/299\n",
      "----------\n",
      "train Loss: 0.2332 Acc: 0.9233\n",
      "val Loss: 0.9681 Acc: 0.8165\n",
      "Epoch 227/299\n",
      "----------\n",
      "train Loss: 0.2534 Acc: 0.9191\n",
      "val Loss: 0.8468 Acc: 0.8160\n",
      "Epoch 228/299\n",
      "----------\n",
      "train Loss: 0.2249 Acc: 0.9305\n",
      "val Loss: 0.8111 Acc: 0.8246\n",
      "Epoch 229/299\n",
      "----------\n",
      "train Loss: 0.2145 Acc: 0.9294\n",
      "val Loss: 0.8630 Acc: 0.8264\n",
      "Epoch 230/299\n",
      "----------\n",
      "train Loss: 0.2203 Acc: 0.9276\n",
      "val Loss: 0.8054 Acc: 0.8333\n",
      "Epoch 231/299\n",
      "----------\n",
      "train Loss: 0.2323 Acc: 0.9243\n",
      "val Loss: 0.8648 Acc: 0.8246\n",
      "Epoch 232/299\n",
      "----------\n",
      "train Loss: 0.2214 Acc: 0.9264\n",
      "val Loss: 0.7786 Acc: 0.8267\n",
      "Epoch 233/299\n",
      "----------\n",
      "train Loss: 0.2205 Acc: 0.9276\n",
      "val Loss: 0.8222 Acc: 0.8310\n",
      "Epoch 234/299\n",
      "----------\n",
      "train Loss: 0.2229 Acc: 0.9263\n",
      "val Loss: 0.8221 Acc: 0.8262\n",
      "Epoch 235/299\n",
      "----------\n",
      "train Loss: 0.2253 Acc: 0.9253\n",
      "val Loss: 0.8168 Acc: 0.8285\n",
      "Epoch 236/299\n",
      "----------\n",
      "train Loss: 0.2273 Acc: 0.9260\n",
      "val Loss: 0.8093 Acc: 0.8267\n",
      "Epoch 237/299\n",
      "----------\n",
      "train Loss: 0.2079 Acc: 0.9312\n",
      "val Loss: 0.8609 Acc: 0.8234\n",
      "Epoch 238/299\n",
      "----------\n",
      "train Loss: 0.2249 Acc: 0.9280\n",
      "val Loss: 0.7681 Acc: 0.8313\n",
      "Epoch 239/299\n",
      "----------\n",
      "train Loss: 0.2314 Acc: 0.9242\n",
      "val Loss: 0.8169 Acc: 0.8272\n",
      "Epoch 240/299\n",
      "----------\n",
      "train Loss: 0.2284 Acc: 0.9245\n",
      "val Loss: 0.8152 Acc: 0.8292\n",
      "Epoch 241/299\n",
      "----------\n",
      "train Loss: 0.2225 Acc: 0.9241\n",
      "val Loss: 0.8475 Acc: 0.8290\n",
      "Epoch 242/299\n",
      "----------\n",
      "train Loss: 0.2154 Acc: 0.9317\n",
      "val Loss: 0.9793 Acc: 0.8068\n",
      "Epoch 243/299\n",
      "----------\n",
      "train Loss: 0.2415 Acc: 0.9223\n",
      "val Loss: 0.9283 Acc: 0.8167\n",
      "Epoch 244/299\n",
      "----------\n",
      "train Loss: 0.2118 Acc: 0.9301\n",
      "val Loss: 0.8561 Acc: 0.8249\n",
      "Epoch 245/299\n",
      "----------\n",
      "train Loss: 0.2163 Acc: 0.9279\n",
      "val Loss: 0.8316 Acc: 0.8371\n",
      "Epoch 246/299\n",
      "----------\n",
      "train Loss: 0.2141 Acc: 0.9293\n",
      "val Loss: 0.7899 Acc: 0.8267\n",
      "Epoch 247/299\n",
      "----------\n",
      "train Loss: 0.2090 Acc: 0.9290\n",
      "val Loss: 0.8790 Acc: 0.8218\n",
      "Epoch 248/299\n",
      "----------\n",
      "train Loss: 0.2208 Acc: 0.9270\n",
      "val Loss: 0.8497 Acc: 0.8142\n",
      "Epoch 249/299\n",
      "----------\n",
      "train Loss: 0.2215 Acc: 0.9288\n",
      "val Loss: 0.8804 Acc: 0.8251\n",
      "Epoch 250/299\n",
      "----------\n",
      "train Loss: 0.2142 Acc: 0.9304\n",
      "val Loss: 0.9859 Acc: 0.7994\n",
      "Epoch 251/299\n",
      "----------\n",
      "train Loss: 0.2348 Acc: 0.9245\n",
      "val Loss: 0.8288 Acc: 0.8282\n",
      "Epoch 252/299\n",
      "----------\n",
      "train Loss: 0.2342 Acc: 0.9263\n",
      "val Loss: 0.7879 Acc: 0.8363\n",
      "Epoch 253/299\n",
      "----------\n",
      "train Loss: 0.2143 Acc: 0.9275\n",
      "val Loss: 0.8097 Acc: 0.8208\n",
      "Epoch 254/299\n",
      "----------\n",
      "train Loss: 0.2308 Acc: 0.9255\n",
      "val Loss: 0.7701 Acc: 0.8318\n",
      "Epoch 255/299\n",
      "----------\n",
      "train Loss: 0.2036 Acc: 0.9339\n",
      "val Loss: 0.7827 Acc: 0.8257\n",
      "Epoch 256/299\n",
      "----------\n",
      "train Loss: 0.2259 Acc: 0.9259\n",
      "val Loss: 0.7914 Acc: 0.8320\n",
      "Epoch 257/299\n",
      "----------\n",
      "train Loss: 0.2053 Acc: 0.9339\n",
      "val Loss: 0.8035 Acc: 0.8246\n",
      "Epoch 258/299\n",
      "----------\n",
      "train Loss: 0.2215 Acc: 0.9283\n",
      "val Loss: 0.8263 Acc: 0.8272\n",
      "Epoch 259/299\n",
      "----------\n",
      "train Loss: 0.2177 Acc: 0.9310\n",
      "val Loss: 0.8406 Acc: 0.8307\n",
      "Epoch 260/299\n",
      "----------\n",
      "train Loss: 0.2157 Acc: 0.9292\n",
      "val Loss: 0.7950 Acc: 0.8348\n",
      "Epoch 261/299\n",
      "----------\n",
      "train Loss: 0.2120 Acc: 0.9319\n",
      "val Loss: 0.8786 Acc: 0.8239\n",
      "Epoch 262/299\n",
      "----------\n",
      "train Loss: 0.2007 Acc: 0.9337\n",
      "val Loss: 0.8356 Acc: 0.8338\n",
      "Epoch 263/299\n",
      "----------\n",
      "train Loss: 0.2166 Acc: 0.9285\n",
      "val Loss: 0.8085 Acc: 0.8328\n",
      "Epoch 264/299\n",
      "----------\n",
      "train Loss: 0.1920 Acc: 0.9380\n",
      "val Loss: 0.8531 Acc: 0.8277\n",
      "Epoch 265/299\n",
      "----------\n",
      "train Loss: 0.2256 Acc: 0.9285\n",
      "val Loss: 0.7867 Acc: 0.8267\n",
      "Epoch 266/299\n",
      "----------\n",
      "train Loss: 0.2115 Acc: 0.9311\n",
      "val Loss: 0.8336 Acc: 0.8185\n",
      "Epoch 267/299\n",
      "----------\n",
      "train Loss: 0.2107 Acc: 0.9341\n",
      "val Loss: 0.7503 Acc: 0.8341\n",
      "Epoch 268/299\n",
      "----------\n",
      "train Loss: 0.2089 Acc: 0.9300\n",
      "val Loss: 0.8662 Acc: 0.8173\n",
      "Epoch 269/299\n",
      "----------\n",
      "train Loss: 0.2155 Acc: 0.9293\n",
      "val Loss: 0.8209 Acc: 0.8353\n",
      "Epoch 270/299\n",
      "----------\n",
      "train Loss: 0.2122 Acc: 0.9291\n",
      "val Loss: 0.7750 Acc: 0.8300\n",
      "Epoch 271/299\n",
      "----------\n",
      "train Loss: 0.2080 Acc: 0.9331\n",
      "val Loss: 0.8832 Acc: 0.8208\n",
      "Epoch 272/299\n",
      "----------\n",
      "train Loss: 0.1975 Acc: 0.9350\n",
      "val Loss: 0.8091 Acc: 0.8234\n",
      "Epoch 273/299\n",
      "----------\n",
      "train Loss: 0.2120 Acc: 0.9322\n",
      "val Loss: 0.8422 Acc: 0.8241\n",
      "Epoch 274/299\n",
      "----------\n",
      "train Loss: 0.2090 Acc: 0.9311\n",
      "val Loss: 0.7911 Acc: 0.8325\n",
      "Epoch 275/299\n",
      "----------\n",
      "train Loss: 0.2066 Acc: 0.9316\n",
      "val Loss: 0.8636 Acc: 0.8287\n",
      "Epoch 276/299\n",
      "----------\n",
      "train Loss: 0.2059 Acc: 0.9307\n",
      "val Loss: 0.8585 Acc: 0.8305\n",
      "Epoch 277/299\n",
      "----------\n",
      "train Loss: 0.2284 Acc: 0.9283\n",
      "val Loss: 0.7868 Acc: 0.8335\n",
      "Epoch 278/299\n",
      "----------\n",
      "train Loss: 0.2123 Acc: 0.9298\n",
      "val Loss: 0.7661 Acc: 0.8287\n",
      "Epoch 279/299\n",
      "----------\n",
      "train Loss: 0.2053 Acc: 0.9320\n",
      "val Loss: 0.8365 Acc: 0.8251\n",
      "Epoch 280/299\n",
      "----------\n",
      "train Loss: 0.2172 Acc: 0.9326\n",
      "val Loss: 0.8342 Acc: 0.8313\n",
      "Epoch 281/299\n",
      "----------\n",
      "train Loss: 0.2084 Acc: 0.9304\n",
      "val Loss: 0.8483 Acc: 0.8170\n",
      "Epoch 282/299\n",
      "----------\n",
      "train Loss: 0.2153 Acc: 0.9305\n",
      "val Loss: 0.8920 Acc: 0.8290\n",
      "Epoch 283/299\n",
      "----------\n",
      "train Loss: 0.2019 Acc: 0.9346\n",
      "val Loss: 0.8158 Acc: 0.8251\n",
      "Epoch 284/299\n",
      "----------\n",
      "train Loss: 0.2177 Acc: 0.9292\n",
      "val Loss: 0.7974 Acc: 0.8341\n",
      "Epoch 285/299\n",
      "----------\n",
      "train Loss: 0.1922 Acc: 0.9354\n",
      "val Loss: 0.8449 Acc: 0.8249\n",
      "Epoch 286/299\n",
      "----------\n",
      "train Loss: 0.2134 Acc: 0.9286\n",
      "val Loss: 0.8455 Acc: 0.8300\n",
      "Epoch 287/299\n",
      "----------\n",
      "train Loss: 0.1927 Acc: 0.9368\n",
      "val Loss: 0.9173 Acc: 0.8155\n",
      "Epoch 288/299\n",
      "----------\n",
      "train Loss: 0.1966 Acc: 0.9352\n",
      "val Loss: 0.8623 Acc: 0.8190\n",
      "Epoch 289/299\n",
      "----------\n",
      "train Loss: 0.2072 Acc: 0.9307\n",
      "val Loss: 0.8749 Acc: 0.8223\n",
      "Epoch 290/299\n",
      "----------\n",
      "train Loss: 0.2049 Acc: 0.9327\n",
      "val Loss: 0.8528 Acc: 0.8305\n",
      "Epoch 291/299\n",
      "----------\n",
      "train Loss: 0.1903 Acc: 0.9378\n",
      "val Loss: 0.8075 Acc: 0.8335\n",
      "Epoch 292/299\n",
      "----------\n",
      "train Loss: 0.1897 Acc: 0.9371\n",
      "val Loss: 0.8464 Acc: 0.8249\n",
      "Epoch 293/299\n",
      "----------\n",
      "train Loss: 0.1972 Acc: 0.9352\n",
      "val Loss: 0.8703 Acc: 0.8325\n",
      "Epoch 294/299\n",
      "----------\n",
      "train Loss: 0.2040 Acc: 0.9343\n",
      "val Loss: 0.7617 Acc: 0.8353\n",
      "Epoch 295/299\n",
      "----------\n",
      "train Loss: 0.2023 Acc: 0.9344\n",
      "val Loss: 0.8755 Acc: 0.8213\n",
      "Epoch 296/299\n",
      "----------\n",
      "train Loss: 0.1970 Acc: 0.9363\n",
      "val Loss: 0.8487 Acc: 0.8328\n",
      "Epoch 297/299\n",
      "----------\n",
      "train Loss: 0.1985 Acc: 0.9327\n",
      "val Loss: 0.9952 Acc: 0.8157\n",
      "Epoch 298/299\n",
      "----------\n",
      "train Loss: 0.1908 Acc: 0.9368\n",
      "val Loss: 0.8774 Acc: 0.8264\n",
      "Epoch 299/299\n",
      "----------\n",
      "train Loss: 0.1957 Acc: 0.9366\n",
      "val Loss: 0.8462 Acc: 0.8218\n",
      "Training complete in 139m 41s\n",
      "Best val Acc: 0.837109\n"
     ]
    }
   ],
   "source": [
    "final_model = models.resnet18(pretrained=use_pretrained)\n",
    "num_ftrs = final_model.fc.in_features\n",
    "final_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "final_model = final_model.to(device)\n",
    "\n",
    "optimizer_ft = optim.Adam(final_model.parameters(), lr=0.003)\n",
    "final_model, hist = train_model(final_model, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)\n",
    "torch.save(final_model.state_dict(), \"/app/18.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa8d44-695f-4945-9153-11ee1faf5dd2",
   "metadata": {},
   "source": [
    "## Create requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "739ae255-8a20-434c-9968-ff461037c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f1baef-a193-43ae-9f48-3984c4f7d753",
   "metadata": {},
   "source": [
    "### Prepare model for deploing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a392a08-4c58-447d-90c7-c360a5d55f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=use_pretrained)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "model.load_state_dict(torch.load(\"/app/50.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ceb5a00-8b91-4d1b-b256-0f0740c4aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.quantization\n",
    "quantized_model = torch.quantization.quantize_dynamic(model.cpu(), {torch.nn.Linear}, dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cb5dcdc-6737-4915-80e1-6ff1cd4246f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchscript_model = torch.jit.script(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6974622-dad4-470b-9029-0c427616da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torchscript_model.state_dict(), \"/app/50_torchscript.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c767ad-4efe-4d1b-8986-38557aaecb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchscript_model(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
